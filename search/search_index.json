{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to SwarmRL","text":"<p>SwarmRL is a state-of-the-art reinforcement learning framework designed to empower both researchers and hobbyists in the field of artificial intelligence. Our package facilitates the development, testing, and deployment of complex RL algorithms in various environments.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>User-Friendly: Designed with simplicity and ease of use in mind.</li> <li>Flexibility: Supports a wide range of RL algorithms and environments.</li> <li>Performance-Oriented: Optimized for efficiency and speed.</li> <li>Community-Driven: Open-source and welcoming contributions.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Dive into the world of reinforcement learning with SwarmRL:</p> <ul> <li>Introduction: Learn more about what SwarmRL offers and its applications.</li> <li>Installation: Get SwarmRL up and running on your machine.</li> <li>Quick Start: Jump straight into using SwarmRL with these simple examples.</li> </ul>"},{"location":"#contribute","title":"Contribute","text":"<p>SwarmRL is an open-source project, and we welcome contributions from the community! Whether it's improving the code, adding new features, or enhancing the documentation, your input is valuable.</p>"},{"location":"#stay-connected","title":"Stay Connected","text":"<p>Join our community and stay updated with the latest developments in SwarmRL:</p> <ul> <li>GitHub: SwarmRL/SwarmRL</li> </ul> <p>We're excited to see what you'll build with SwarmRL!</p>"},{"location":"pages/getting_started/","title":"Getting Started with SwarmRL","text":"<p>Welcome to the first steps of using SwarmRL! This guide will walk you through the basics of setting up a simple reinforcement learning scenario using SwarmRL. </p>"},{"location":"pages/getting_started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have:</p> <ul> <li>Successfully installed SwarmRL.</li> <li>Basic understanding of Python programming.</li> <li>Familiarity with reinforcement learning concepts is helpful but not required.</li> </ul>"},{"location":"pages/installation/","title":"Installation Guide for SwarmRL","text":"<p>Getting started with SwarmRL is straightforward. Follow these steps to set up SwarmRL on your system.</p>"},{"location":"pages/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing SwarmRL, ensure you have the following prerequisites:</p> <ul> <li>Python 3.10 or later.</li> <li>pip (Python package manager).</li> </ul>"},{"location":"pages/installation/#installation-steps","title":"Installation Steps","text":"<ol> <li>Install SwarmRL:    Use pip to install the latest version of SwarmRL:    <code>bash    pip install swarmrl</code></li> </ol>"},{"location":"pages/introduction/","title":"Introduction to SwarmRL","text":"<p>Welcome to SwarmRL, an innovative reinforcement learning package designed for researchers and enthusiasts alike. SwarmRL simplifies the process of implementing and experimenting with various reinforcement learning algorithms in a cohesive and intuitive manner.</p>"},{"location":"pages/introduction/#what-is-swarmrl","title":"What is SwarmRL?","text":"<p>SwarmRL is a comprehensive framework that provides a suite of tools and functionalities for reinforcement learning (RL) applications. Our goal is to streamline the development process in RL, making it more accessible and efficient for both beginners and experienced users.</p>"},{"location":"pages/introduction/#features","title":"Features","text":"<ul> <li>Modular Design: Easily plug in different algorithms and components.</li> <li>Pre-built Algorithms: Includes a variety of standard RL algorithms.</li> <li>Customizable Environments: Test algorithms in a range of environments.</li> <li>Visualization Tools: Intuitive interfaces for monitoring and analyzing agent performance.</li> <li>Community-Driven: Open to contributions and improvements from the RL community.</li> </ul> <p>Stay tuned as we dive deeper into the world of SwarmRL and explore its capabilities!</p>"},{"location":"pages/introduction/#next-installation","title":"Next: Installation","text":""},{"location":"pages/api/swarmrl.actions.actions/","title":"swarmrl.actions.actions Module API Reference","text":"<p>Main module for actions.</p>"},{"location":"pages/api/swarmrl.actions.actions/#swarmrl.actions.actions.Action","title":"<code>Action</code>  <code>dataclass</code>","text":"<p>Holds the 3 quantities that are applied to the colloid plus an identifier</p> Source code in <code>swarmrl/actions/actions.py</code> <pre><code>@dataclasses.dataclass\nclass Action:\n    \"\"\"\n    Holds the 3 quantities that are applied to the colloid plus an identifier\n    \"\"\"\n\n    id = 0\n    force: float = 0.0\n    torque: np.ndarray = None\n    new_direction: np.ndarray = None\n</code></pre>"},{"location":"pages/api/swarmrl.agents.actor_critic/","title":"swarmrl.agents.actor_critic Module API Reference","text":"<p>Module for the Actor-Critic RL protocol.</p>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent","title":"<code>ActorCriticAgent</code>","text":"<p>             Bases: <code>Agent</code></p> <p>Class to handle the actor-critic RL Protocol.</p> Source code in <code>swarmrl/agents/actor_critic.py</code> <pre><code>class ActorCriticAgent(Agent):\n    \"\"\"\n    Class to handle the actor-critic RL Protocol.\n    \"\"\"\n\n    def __init__(\n        self,\n        particle_type: int,\n        network: Network,\n        task: Task,\n        observable: Observable,\n        actions: dict,\n        loss: Loss = ProximalPolicyLoss(),\n        train: bool = True,\n    ):\n        \"\"\"\n        Constructor for the actor-critic protocol.\n\n        Parameters\n        ----------\n        particle_type : int\n                Particle ID this RL protocol applies to.\n        observable : Observable\n                Observable for this particle type and network input\n        task : Task\n                Task for this particle type to perform.\n        actions : dict\n                Actions allowed for the particle.\n        loss : Loss (default=ProximalPolicyLoss)\n                Loss function to use to update the networks.\n        train : bool (default=True)\n                Flag to indicate if the agent is training.\n        \"\"\"\n        # Properties of the agent.\n        self.network = network\n        self.particle_type = particle_type\n        self.task = task\n        self.observable = observable\n        self.actions = actions\n        self.train = train\n        self.loss = loss\n\n        # Trajectory to be updated.\n        self.trajectory = TrajectoryInformation(particle_type=self.particle_type)\n\n    def __name__(self) -&gt; str:\n        \"\"\"\n        Give the class a name.\n\n        Return\n        ------\n        name : str\n            Name of the class.\n        \"\"\"\n        return \"ActorCriticAgent\"\n\n    def update_agent(self) -&gt; tuple:\n        \"\"\"\n        Update the agents network.\n\n        Returns\n        -------\n        rewards : float\n                Net reward for the agent.\n        killed : bool\n                Whether or not this agent killed the\n                simulation.\n        \"\"\"\n        # Collect data for returns.\n        rewards = self.trajectory.rewards\n        killed = self.trajectory.killed\n\n        # Compute loss for actor and critic.\n        self.loss.compute_loss(\n            network=self.network,\n            episode_data=self.trajectory,\n        )\n\n        # Reset the trajectory storage.\n        self.reset_trajectory()\n\n        return rewards, killed\n\n    def reset_agent(self, colloids: typing.List[Colloid]):\n        \"\"\"\n        Reset several properties of the agent.\n\n        Reset the observables and tasks for the agent.\n\n        Parameters\n        ----------\n        colloids : typing.List[Colloid]\n                Colloids to use in the initialization.\n        \"\"\"\n        self.observable.initialize(colloids)\n        self.task.initialize(colloids)\n\n    def reset_trajectory(self):\n        \"\"\"\n        Set all trajectory data to None.\n        \"\"\"\n        self.task.kill_switch = False  # Reset here.\n        self.trajectory = TrajectoryInformation(particle_type=self.particle_type)\n\n    def initialize_network(self):\n        \"\"\"\n        Initialize all of the models in the gym.\n        \"\"\"\n        self.network.reinitialize_network()\n\n    def save_agent(self, directory: str):\n        \"\"\"\n        Save the agent network state.\n\n        Parameters\n        ----------\n        directory : str\n                Location to save the models.\n        \"\"\"\n        self.network.export_model(\n            filename=f\"{self.__name__()}_{self.particle_type}\", directory=directory\n        )\n\n    def restore_agent(self, directory: str):\n        \"\"\"\n        Restore the agent state from a directory.\n        \"\"\"\n        self.network.restore_model_state(\n            filename=f\"{self.__name__()}_{self.particle_type}\", directory=directory\n        )\n\n    def calc_action(self, colloids: typing.List[Colloid]) -&gt; typing.List[Action]:\n        \"\"\"\n        Copmute the new state for the agent.\n\n        Returns the chosen actions to the force function which\n        talks to the espresso engine.\n\n        Parameters\n        ----------\n        colloids : List[Colloid]\n                List of colloids in the system.\n        \"\"\"\n        state_description = self.observable.compute_observable(colloids)\n        action_indices, log_probs = self.network.compute_action(\n            observables=state_description\n        )\n        chosen_actions = np.take(list(self.actions.values()), action_indices, axis=-1)\n\n        # Update the trajectory information.\n        if self.train:\n            self.trajectory.features.append(state_description)\n            self.trajectory.actions.append(action_indices)\n            self.trajectory.log_probs.append(log_probs)\n            self.trajectory.rewards.append(self.task(colloids))\n            self.trajectory.killed = self.task.kill_switch\n\n        self.kill_switch = self.task.kill_switch\n\n        return chosen_actions\n</code></pre>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.__init__","title":"<code>__init__(particle_type, network, task, observable, actions, loss=ProximalPolicyLoss(), train=True)</code>","text":"<p>Constructor for the actor-critic protocol.</p>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.__init__--parameters","title":"Parameters","text":"<p>particle_type : int         Particle ID this RL protocol applies to. observable : Observable         Observable for this particle type and network input task : Task         Task for this particle type to perform. actions : dict         Actions allowed for the particle. loss : Loss (default=ProximalPolicyLoss)         Loss function to use to update the networks. train : bool (default=True)         Flag to indicate if the agent is training.</p> Source code in <code>swarmrl/agents/actor_critic.py</code> <pre><code>def __init__(\n    self,\n    particle_type: int,\n    network: Network,\n    task: Task,\n    observable: Observable,\n    actions: dict,\n    loss: Loss = ProximalPolicyLoss(),\n    train: bool = True,\n):\n    \"\"\"\n    Constructor for the actor-critic protocol.\n\n    Parameters\n    ----------\n    particle_type : int\n            Particle ID this RL protocol applies to.\n    observable : Observable\n            Observable for this particle type and network input\n    task : Task\n            Task for this particle type to perform.\n    actions : dict\n            Actions allowed for the particle.\n    loss : Loss (default=ProximalPolicyLoss)\n            Loss function to use to update the networks.\n    train : bool (default=True)\n            Flag to indicate if the agent is training.\n    \"\"\"\n    # Properties of the agent.\n    self.network = network\n    self.particle_type = particle_type\n    self.task = task\n    self.observable = observable\n    self.actions = actions\n    self.train = train\n    self.loss = loss\n\n    # Trajectory to be updated.\n    self.trajectory = TrajectoryInformation(particle_type=self.particle_type)\n</code></pre>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.__name__","title":"<code>__name__()</code>","text":"<p>Give the class a name.</p>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.__name__--return","title":"Return","text":"<p>name : str     Name of the class.</p> Source code in <code>swarmrl/agents/actor_critic.py</code> <pre><code>def __name__(self) -&gt; str:\n    \"\"\"\n    Give the class a name.\n\n    Return\n    ------\n    name : str\n        Name of the class.\n    \"\"\"\n    return \"ActorCriticAgent\"\n</code></pre>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.calc_action","title":"<code>calc_action(colloids)</code>","text":"<p>Copmute the new state for the agent.</p> <p>Returns the chosen actions to the force function which talks to the espresso engine.</p>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.calc_action--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids in the system.</p> Source code in <code>swarmrl/agents/actor_critic.py</code> <pre><code>def calc_action(self, colloids: typing.List[Colloid]) -&gt; typing.List[Action]:\n    \"\"\"\n    Copmute the new state for the agent.\n\n    Returns the chosen actions to the force function which\n    talks to the espresso engine.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids in the system.\n    \"\"\"\n    state_description = self.observable.compute_observable(colloids)\n    action_indices, log_probs = self.network.compute_action(\n        observables=state_description\n    )\n    chosen_actions = np.take(list(self.actions.values()), action_indices, axis=-1)\n\n    # Update the trajectory information.\n    if self.train:\n        self.trajectory.features.append(state_description)\n        self.trajectory.actions.append(action_indices)\n        self.trajectory.log_probs.append(log_probs)\n        self.trajectory.rewards.append(self.task(colloids))\n        self.trajectory.killed = self.task.kill_switch\n\n    self.kill_switch = self.task.kill_switch\n\n    return chosen_actions\n</code></pre>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.initialize_network","title":"<code>initialize_network()</code>","text":"<p>Initialize all of the models in the gym.</p> Source code in <code>swarmrl/agents/actor_critic.py</code> <pre><code>def initialize_network(self):\n    \"\"\"\n    Initialize all of the models in the gym.\n    \"\"\"\n    self.network.reinitialize_network()\n</code></pre>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.reset_agent","title":"<code>reset_agent(colloids)</code>","text":"<p>Reset several properties of the agent.</p> <p>Reset the observables and tasks for the agent.</p>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.reset_agent--parameters","title":"Parameters","text":"<p>colloids : typing.List[Colloid]         Colloids to use in the initialization.</p> Source code in <code>swarmrl/agents/actor_critic.py</code> <pre><code>def reset_agent(self, colloids: typing.List[Colloid]):\n    \"\"\"\n    Reset several properties of the agent.\n\n    Reset the observables and tasks for the agent.\n\n    Parameters\n    ----------\n    colloids : typing.List[Colloid]\n            Colloids to use in the initialization.\n    \"\"\"\n    self.observable.initialize(colloids)\n    self.task.initialize(colloids)\n</code></pre>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.reset_trajectory","title":"<code>reset_trajectory()</code>","text":"<p>Set all trajectory data to None.</p> Source code in <code>swarmrl/agents/actor_critic.py</code> <pre><code>def reset_trajectory(self):\n    \"\"\"\n    Set all trajectory data to None.\n    \"\"\"\n    self.task.kill_switch = False  # Reset here.\n    self.trajectory = TrajectoryInformation(particle_type=self.particle_type)\n</code></pre>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.restore_agent","title":"<code>restore_agent(directory)</code>","text":"<p>Restore the agent state from a directory.</p> Source code in <code>swarmrl/agents/actor_critic.py</code> <pre><code>def restore_agent(self, directory: str):\n    \"\"\"\n    Restore the agent state from a directory.\n    \"\"\"\n    self.network.restore_model_state(\n        filename=f\"{self.__name__()}_{self.particle_type}\", directory=directory\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.save_agent","title":"<code>save_agent(directory)</code>","text":"<p>Save the agent network state.</p>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.save_agent--parameters","title":"Parameters","text":"<p>directory : str         Location to save the models.</p> Source code in <code>swarmrl/agents/actor_critic.py</code> <pre><code>def save_agent(self, directory: str):\n    \"\"\"\n    Save the agent network state.\n\n    Parameters\n    ----------\n    directory : str\n            Location to save the models.\n    \"\"\"\n    self.network.export_model(\n        filename=f\"{self.__name__()}_{self.particle_type}\", directory=directory\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.update_agent","title":"<code>update_agent()</code>","text":"<p>Update the agents network.</p>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.ActorCriticAgent.update_agent--returns","title":"Returns","text":"<p>rewards : float         Net reward for the agent. killed : bool         Whether or not this agent killed the         simulation.</p> Source code in <code>swarmrl/agents/actor_critic.py</code> <pre><code>def update_agent(self) -&gt; tuple:\n    \"\"\"\n    Update the agents network.\n\n    Returns\n    -------\n    rewards : float\n            Net reward for the agent.\n    killed : bool\n            Whether or not this agent killed the\n            simulation.\n    \"\"\"\n    # Collect data for returns.\n    rewards = self.trajectory.rewards\n    killed = self.trajectory.killed\n\n    # Compute loss for actor and critic.\n    self.loss.compute_loss(\n        network=self.network,\n        episode_data=self.trajectory,\n    )\n\n    # Reset the trajectory storage.\n    self.reset_trajectory()\n\n    return rewards, killed\n</code></pre>"},{"location":"pages/api/swarmrl.agents.actor_critic/#swarmrl.agents.actor_critic.TrajectoryInformation","title":"<code>TrajectoryInformation</code>  <code>dataclass</code>","text":"<p>Helper dataclass for training RL models.</p> Source code in <code>swarmrl/agents/actor_critic.py</code> <pre><code>@dataclass\nclass TrajectoryInformation:\n    \"\"\"\n    Helper dataclass for training RL models.\n    \"\"\"\n\n    particle_type: int\n    features: list = field(default_factory=list)\n    actions: list = field(default_factory=list)\n    log_probs: list = field(default_factory=list)\n    rewards: list = field(default_factory=list)\n    killed: bool = False\n</code></pre>"},{"location":"pages/api/swarmrl.agents.agent/","title":"swarmrl.agents.agent Module API Reference","text":"<p>Parent class for all agents</p>"},{"location":"pages/api/swarmrl.agents.agent/#swarmrl.agents.agent.Agent","title":"<code>Agent</code>","text":"<p>Parent class for a SwarmRL Agent.</p> Source code in <code>swarmrl/agents/agent.py</code> <pre><code>class Agent:\n    \"\"\"\n    Parent class for a SwarmRL Agent.\n    \"\"\"\n\n    _killed = False\n\n    @property\n    def kill_switch(self):\n        \"\"\"\n        If true, kill the simulation.\n        \"\"\"\n        return self._killed\n\n    @kill_switch.setter\n    def kill_switch(self, value):\n        \"\"\"\n        Set the kill switch.\n        \"\"\"\n        self._killed = value\n\n    def calc_action(\n        self, colloids: typing.List[Colloid]\n    ) -&gt; typing.Tuple[typing.List[Action]]:\n        \"\"\"\n        Compute the state of the system based on the current colloid position.\n\n        Returns\n        -------\n        actions: typing.List[Action]\n                Return the action the colloid should take.\n        kill_switch : bool\n                Flag capable of ending simulation.\n        \"\"\"\n        raise NotImplementedError(\"Implemented in Child class.\")\n</code></pre>"},{"location":"pages/api/swarmrl.agents.agent/#swarmrl.agents.agent.Agent.kill_switch","title":"<code>kill_switch</code>  <code>property</code> <code>writable</code>","text":"<p>If true, kill the simulation.</p>"},{"location":"pages/api/swarmrl.agents.agent/#swarmrl.agents.agent.Agent.calc_action","title":"<code>calc_action(colloids)</code>","text":"<p>Compute the state of the system based on the current colloid position.</p>"},{"location":"pages/api/swarmrl.agents.agent/#swarmrl.agents.agent.Agent.calc_action--returns","title":"Returns","text":"<p>actions: typing.List[Action]         Return the action the colloid should take. kill_switch : bool         Flag capable of ending simulation.</p> Source code in <code>swarmrl/agents/agent.py</code> <pre><code>def calc_action(\n    self, colloids: typing.List[Colloid]\n) -&gt; typing.Tuple[typing.List[Action]]:\n    \"\"\"\n    Compute the state of the system based on the current colloid position.\n\n    Returns\n    -------\n    actions: typing.List[Action]\n            Return the action the colloid should take.\n    kill_switch : bool\n            Flag capable of ending simulation.\n    \"\"\"\n    raise NotImplementedError(\"Implemented in Child class.\")\n</code></pre>"},{"location":"pages/api/swarmrl.agents.bechinger_models/","title":"swarmrl.agents.bechinger_models Module API Reference","text":""},{"location":"pages/api/swarmrl.agents.bechinger_models/#swarmrl.agents.bechinger_models.Baeuerle2020","title":"<code>Baeuerle2020</code>","text":"<p>             Bases: <code>ClassicalAgent</code></p> <p>See https://doi.org/10.1038/s41467-020-16161-4</p> Source code in <code>swarmrl/agents/bechinger_models.py</code> <pre><code>class Baeuerle2020(ClassicalAgent):\n    \"\"\"\n    See https://doi.org/10.1038/s41467-020-16161-4\n    \"\"\"\n\n    def __init__(\n        self,\n        act_force=1.0,\n        act_torque=1,\n        detection_radius_position=1.0,\n        detection_radius_orientation=1.0,\n        vision_half_angle=np.pi / 2.0,\n        angular_deviation=1,\n        acts_on_types: typing.List[int] = None,\n    ):\n        self.act_force = act_force\n        self.act_torque = act_torque\n        self.detection_radius_position = detection_radius_position\n        self.detection_radius_orientation = detection_radius_orientation\n        self.vision_half_angle = vision_half_angle\n        self.angular_deviation = angular_deviation\n        if acts_on_types is None:\n            acts_on_types = [0]\n        self.acts_on_types = acts_on_types\n\n    def calc_action(self, colloids) -&gt; typing.List[Action]:\n        # get vector to center of mass\n        actions = []\n        for colloid in colloids:\n            if colloid.type not in self.acts_on_types:\n                actions.append(Action())\n                continue\n            other_colloids = [c for c in colloids if c is not colloid]\n            colls_in_vision_pos = get_colloids_in_vision(\n                colloid,\n                other_colloids,\n                vision_half_angle=self.vision_half_angle,\n                vision_range=self.detection_radius_position,\n            )\n            if len(colls_in_vision_pos) == 0:\n                # not detailed in the paper. take from previous model\n                actions.append(Action())\n                continue\n\n            com = np.mean(\n                np.stack([col.pos for col in colls_in_vision_pos], axis=0), axis=0\n            )\n            to_com = com - colloid.pos\n            to_com_angle = angle_from_vector(to_com)\n\n            # get average orientation of neighbours\n            colls_in_vision_orientation = get_colloids_in_vision(\n                colloid,\n                other_colloids,\n                vision_half_angle=self.vision_half_angle,\n                vision_range=self.detection_radius_orientation,\n            )\n\n            if len(colls_in_vision_orientation) == 0:\n                # not detailed in paper\n                actions.append(Action())\n                continue\n\n            colls_in_vision_orientation.append(colloid)\n\n            mean_orientation_in_vision = np.mean(\n                np.stack([col.director for col in colls_in_vision_orientation], axis=0),\n                axis=0,\n            )\n            mean_orientation_in_vision /= np.linalg.norm(mean_orientation_in_vision)\n\n            # choose target orientation based on self.angular_deviation\n            target_angle_choices = [\n                to_com_angle + self.angular_deviation,\n                to_com_angle - self.angular_deviation,\n            ]\n            target_orientation_choices = [\n                vector_from_angle(ang) for ang in target_angle_choices\n            ]\n\n            angle_deviations = [\n                np.arccos(np.dot(orient, mean_orientation_in_vision))\n                for orient in target_orientation_choices\n            ]\n            target_angle = target_angle_choices[np.argmin(angle_deviations)]\n            current_angle = angle_from_vector(colloid.director)\n            angle_diff = target_angle - current_angle\n\n            # take care of angle wraparound and bring difference to [-pi, pi]\n            if angle_diff &gt;= np.pi:\n                angle_diff -= 2 * np.pi\n            if angle_diff &lt;= -np.pi:\n                angle_diff += 2 * np.pi\n            torque_z = np.sin(angle_diff) * self.act_torque\n\n            actions.append(\n                Action(force=self.act_force, torque=np.array([0, 0, torque_z]))\n            )\n\n        return actions\n</code></pre>"},{"location":"pages/api/swarmrl.agents.bechinger_models/#swarmrl.agents.bechinger_models.Lavergne2019","title":"<code>Lavergne2019</code>","text":"<p>             Bases: <code>ClassicalAgent</code></p> <p>See doi/10.1126/science.aau5347</p> Source code in <code>swarmrl/agents/bechinger_models.py</code> <pre><code>class Lavergne2019(ClassicalAgent):\n    \"\"\"\n    See doi/10.1126/science.aau5347\n    \"\"\"\n\n    def __init__(\n        self,\n        vision_half_angle=np.pi / 2.0,\n        act_force=1,\n        perception_threshold=1,\n        acts_on_types: typing.List[int] = None,\n    ):\n        self.vision_half_angle = vision_half_angle\n        self.act_force = act_force\n        self.perception_threshold = perception_threshold\n        if acts_on_types is None:\n            acts_on_types = [0]\n        self.acts_on_types = acts_on_types\n\n    def calc_action(self, colloids) -&gt; typing.List[Action]:\n        # determine perception value\n        actions = []\n        for colloid in colloids:\n            if colloid.type not in self.acts_on_types:\n                actions.append(Action())\n                continue\n            other_colloids = [c for c in colloids if c is not colloid]\n            colls_in_vision = get_colloids_in_vision(\n                colloid, other_colloids, vision_half_angle=self.vision_half_angle\n            )\n            perception = 0\n            my_pos = np.copy(colloid.pos)\n            for coll in colls_in_vision:\n                dist = np.linalg.norm(my_pos - coll.pos)\n                perception += 1 / (2 * np.pi * dist)\n\n            # set activity on/off\n            if perception &gt;= self.perception_threshold:\n                actions.append(Action(force=self.act_force))\n            else:\n                actions.append(Action())\n\n        return actions\n</code></pre>"},{"location":"pages/api/swarmrl.agents.classical_agent/","title":"swarmrl.agents.classical_agent Module API Reference","text":"<p>Class for classical agents. These are agents not controlled by machine learning. They should also not be trainable.</p>"},{"location":"pages/api/swarmrl.agents.classical_agent/#swarmrl.agents.classical_agent.ClassicalAgent","title":"<code>ClassicalAgent</code>","text":"<p>             Bases: <code>Agent</code></p> <p>Class to handle the actor-critic RL Protocol.</p> Source code in <code>swarmrl/agents/classical_agent.py</code> <pre><code>class ClassicalAgent(Agent):\n    \"\"\"\n    Class to handle the actor-critic RL Protocol.\n    \"\"\"\n\n    def __init__(\n        self,\n        particle_type: int,\n        actions: dict,\n        task: Task = None,\n        observable: Observable = None,\n    ):\n        \"\"\"\n        Constructor for the actor-critic protocol.\n\n        Parameters\n        ----------\n        network : Network\n                Shared Actor-Critic Network for the RL protocol. The apply function\n                should return a tuple of (logits, value).\n        particle_type : int\n                Particle ID this RL protocol applies to.\n        observable : Observable\n                Observable for this particle type and network input\n        task : Task\n                Task for this particle type to perform.\n        actions : dict\n                Actions allowed for the particle.\n        \"\"\"\n        self.particle_type = particle_type\n        self.task = task\n        self.observable = observable\n        self.actions = actions\n\n    def calc_action(self, colloids: typing.List[Colloid]) -&gt; typing.List[Action]:\n        \"\"\"\n        Copmute the new state for the agent.\n\n        Returns the chosen actions to the force function which\n        talks to the espresso engine.\n\n        Parameters\n        ----------\n        colloids : List[Colloid]\n                List of colloids in the system.\n        \"\"\"\n        raise NotImplementedError(\"Implement in subclass\")\n</code></pre>"},{"location":"pages/api/swarmrl.agents.classical_agent/#swarmrl.agents.classical_agent.ClassicalAgent.__init__","title":"<code>__init__(particle_type, actions, task=None, observable=None)</code>","text":"<p>Constructor for the actor-critic protocol.</p>"},{"location":"pages/api/swarmrl.agents.classical_agent/#swarmrl.agents.classical_agent.ClassicalAgent.__init__--parameters","title":"Parameters","text":"<p>network : Network         Shared Actor-Critic Network for the RL protocol. The apply function         should return a tuple of (logits, value). particle_type : int         Particle ID this RL protocol applies to. observable : Observable         Observable for this particle type and network input task : Task         Task for this particle type to perform. actions : dict         Actions allowed for the particle.</p> Source code in <code>swarmrl/agents/classical_agent.py</code> <pre><code>def __init__(\n    self,\n    particle_type: int,\n    actions: dict,\n    task: Task = None,\n    observable: Observable = None,\n):\n    \"\"\"\n    Constructor for the actor-critic protocol.\n\n    Parameters\n    ----------\n    network : Network\n            Shared Actor-Critic Network for the RL protocol. The apply function\n            should return a tuple of (logits, value).\n    particle_type : int\n            Particle ID this RL protocol applies to.\n    observable : Observable\n            Observable for this particle type and network input\n    task : Task\n            Task for this particle type to perform.\n    actions : dict\n            Actions allowed for the particle.\n    \"\"\"\n    self.particle_type = particle_type\n    self.task = task\n    self.observable = observable\n    self.actions = actions\n</code></pre>"},{"location":"pages/api/swarmrl.agents.classical_agent/#swarmrl.agents.classical_agent.ClassicalAgent.calc_action","title":"<code>calc_action(colloids)</code>","text":"<p>Copmute the new state for the agent.</p> <p>Returns the chosen actions to the force function which talks to the espresso engine.</p>"},{"location":"pages/api/swarmrl.agents.classical_agent/#swarmrl.agents.classical_agent.ClassicalAgent.calc_action--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids in the system.</p> Source code in <code>swarmrl/agents/classical_agent.py</code> <pre><code>def calc_action(self, colloids: typing.List[Colloid]) -&gt; typing.List[Action]:\n    \"\"\"\n    Copmute the new state for the agent.\n\n    Returns the chosen actions to the force function which\n    talks to the espresso engine.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids in the system.\n    \"\"\"\n    raise NotImplementedError(\"Implement in subclass\")\n</code></pre>"},{"location":"pages/api/swarmrl.agents.dummy_models/","title":"swarmrl.agents.dummy_models Module API Reference","text":""},{"location":"pages/api/swarmrl.agents.find_point/","title":"swarmrl.agents.find_point Module API Reference","text":""},{"location":"pages/api/swarmrl.components.colloid/","title":"swarmrl.components.colloid Module API Reference","text":"<p>Data class for the colloid agent.</p>"},{"location":"pages/api/swarmrl.components.colloid/#swarmrl.components.colloid.Colloid","title":"<code>Colloid</code>  <code>dataclass</code>","text":"<p>Wrapper class for a colloid object.</p> Source code in <code>swarmrl/components/colloid.py</code> <pre><code>@register_pytree_node_class\n@dataclasses.dataclass(frozen=True)\nclass Colloid:\n    \"\"\"\n    Wrapper class for a colloid object.\n    \"\"\"\n\n    pos: np.ndarray\n    director: np.ndarray\n    id: int\n    velocity: np.ndarray = None\n    type: int = 0\n\n    def __repr__(self):\n        \"\"\"\n        Return a string representation of the colloid.\n        \"\"\"\n        return (\n            f\"Colloid(pos={self.pos}, director={self.director}, id={self.id},\"\n            f\" velocity={self.velocity}, type={self.type})\"\n        )\n\n    def __eq__(self, other):\n        return self.id == other.id\n\n    def tree_flatten(self):\n        \"\"\"\n        Flatten the PyTree.\n        \"\"\"\n        children = (self.pos, self.director, self.id, self.velocity, self.type)\n        aux_data = None\n        return (children, aux_data)\n\n    @classmethod\n    def tree_unflatten(cls, aux_data, children):\n        \"\"\"\n        Unflatten the PyTree.\n        \"\"\"\n        return cls(*children)\n</code></pre>"},{"location":"pages/api/swarmrl.components.colloid/#swarmrl.components.colloid.Colloid.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the colloid.</p> Source code in <code>swarmrl/components/colloid.py</code> <pre><code>def __repr__(self):\n    \"\"\"\n    Return a string representation of the colloid.\n    \"\"\"\n    return (\n        f\"Colloid(pos={self.pos}, director={self.director}, id={self.id},\"\n        f\" velocity={self.velocity}, type={self.type})\"\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.components.colloid/#swarmrl.components.colloid.Colloid.tree_flatten","title":"<code>tree_flatten()</code>","text":"<p>Flatten the PyTree.</p> Source code in <code>swarmrl/components/colloid.py</code> <pre><code>def tree_flatten(self):\n    \"\"\"\n    Flatten the PyTree.\n    \"\"\"\n    children = (self.pos, self.director, self.id, self.velocity, self.type)\n    aux_data = None\n    return (children, aux_data)\n</code></pre>"},{"location":"pages/api/swarmrl.components.colloid/#swarmrl.components.colloid.Colloid.tree_unflatten","title":"<code>tree_unflatten(aux_data, children)</code>  <code>classmethod</code>","text":"<p>Unflatten the PyTree.</p> Source code in <code>swarmrl/components/colloid.py</code> <pre><code>@classmethod\ndef tree_unflatten(cls, aux_data, children):\n    \"\"\"\n    Unflatten the PyTree.\n    \"\"\"\n    return cls(*children)\n</code></pre>"},{"location":"pages/api/swarmrl.components.swarm/","title":"swarmrl.components.swarm Module API Reference","text":"<p>Class for the Swarm Pytree Agent</p>"},{"location":"pages/api/swarmrl.components.swarm/#swarmrl.components.swarm.Swarm","title":"<code>Swarm</code>  <code>dataclass</code>","text":"<p>Wrapper class for a colloid object.</p> Source code in <code>swarmrl/components/swarm.py</code> <pre><code>@register_pytree_node_class\n@dataclasses.dataclass(frozen=True)\nclass Swarm:\n    \"\"\"\n    Wrapper class for a colloid object.\n    \"\"\"\n\n    # Colloid attributes\n    pos: np.ndarray\n    director: np.ndarray\n    id: int\n    velocity: np.ndarray = None\n    type: int = 0\n\n    # Swarm attributes\n    type_indices: dict = None\n\n    def __repr__(self) -&gt; str:\n        \"\"\"\n        Return a string representation of the colloid.\n        \"\"\"\n        return (\n            f\"Colloid(pos={self.pos}, director={self.director}, id={self.id},\"\n            f\" velocity={self.velocity}, type={self.type})\"\n        )\n\n    def __eq__(self, other):\n        return self.id == other.id\n\n    def tree_flatten(self) -&gt; tuple:\n        \"\"\"\n        Flatten the PyTree.\n        \"\"\"\n        children = (\n            self.pos,\n            self.director,\n            self.id,\n            self.velocity,\n            self.type,\n            self.type_indices,\n        )\n        aux_data = None\n        return (children, aux_data)\n\n    def get_species_swarm(self, species: int) -&gt; Swarm:\n        \"\"\"\n        Get a swarm of one species.\n\n        Parameters\n        ----------\n        species : int\n            Species index.\n\n        Returns\n        -------\n        partitioned_swarm : Swarm\n            Swarm of one species.\n        \"\"\"\n        indices = self.type_indices[species]\n        return Swarm(\n            pos=np.take(self.pos, indices, axis=0),\n            director=np.take(self.director, indices, axis=0),\n            id=np.take(self.id, indices, axis=0),\n            velocity=np.take(self.velocity, indices, axis=0),\n            type=np.take(self.type, indices, axis=0),\n            type_indices=None,\n        )\n\n    @classmethod\n    def tree_unflatten(cls, aux_data, children) -&gt; Swarm:\n        \"\"\"\n        Unflatten the PyTree.\n\n        This method is required by Pytrees in Jax.\n\n        Parameters\n        ----------\n        aux_data : None\n            Auxiliary data. Not used in this class.\n        children : tuple\n            Tuple of children to be unflattened.\n        \"\"\"\n        return cls(*children)\n</code></pre>"},{"location":"pages/api/swarmrl.components.swarm/#swarmrl.components.swarm.Swarm.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the colloid.</p> Source code in <code>swarmrl/components/swarm.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"\n    Return a string representation of the colloid.\n    \"\"\"\n    return (\n        f\"Colloid(pos={self.pos}, director={self.director}, id={self.id},\"\n        f\" velocity={self.velocity}, type={self.type})\"\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.components.swarm/#swarmrl.components.swarm.Swarm.get_species_swarm","title":"<code>get_species_swarm(species)</code>","text":"<p>Get a swarm of one species.</p>"},{"location":"pages/api/swarmrl.components.swarm/#swarmrl.components.swarm.Swarm.get_species_swarm--parameters","title":"Parameters","text":"<p>species : int     Species index.</p>"},{"location":"pages/api/swarmrl.components.swarm/#swarmrl.components.swarm.Swarm.get_species_swarm--returns","title":"Returns","text":"<p>partitioned_swarm : Swarm     Swarm of one species.</p> Source code in <code>swarmrl/components/swarm.py</code> <pre><code>def get_species_swarm(self, species: int) -&gt; Swarm:\n    \"\"\"\n    Get a swarm of one species.\n\n    Parameters\n    ----------\n    species : int\n        Species index.\n\n    Returns\n    -------\n    partitioned_swarm : Swarm\n        Swarm of one species.\n    \"\"\"\n    indices = self.type_indices[species]\n    return Swarm(\n        pos=np.take(self.pos, indices, axis=0),\n        director=np.take(self.director, indices, axis=0),\n        id=np.take(self.id, indices, axis=0),\n        velocity=np.take(self.velocity, indices, axis=0),\n        type=np.take(self.type, indices, axis=0),\n        type_indices=None,\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.components.swarm/#swarmrl.components.swarm.Swarm.tree_flatten","title":"<code>tree_flatten()</code>","text":"<p>Flatten the PyTree.</p> Source code in <code>swarmrl/components/swarm.py</code> <pre><code>def tree_flatten(self) -&gt; tuple:\n    \"\"\"\n    Flatten the PyTree.\n    \"\"\"\n    children = (\n        self.pos,\n        self.director,\n        self.id,\n        self.velocity,\n        self.type,\n        self.type_indices,\n    )\n    aux_data = None\n    return (children, aux_data)\n</code></pre>"},{"location":"pages/api/swarmrl.components.swarm/#swarmrl.components.swarm.Swarm.tree_unflatten","title":"<code>tree_unflatten(aux_data, children)</code>  <code>classmethod</code>","text":"<p>Unflatten the PyTree.</p> <p>This method is required by Pytrees in Jax.</p>"},{"location":"pages/api/swarmrl.components.swarm/#swarmrl.components.swarm.Swarm.tree_unflatten--parameters","title":"Parameters","text":"<p>aux_data : None     Auxiliary data. Not used in this class. children : tuple     Tuple of children to be unflattened.</p> Source code in <code>swarmrl/components/swarm.py</code> <pre><code>@classmethod\ndef tree_unflatten(cls, aux_data, children) -&gt; Swarm:\n    \"\"\"\n    Unflatten the PyTree.\n\n    This method is required by Pytrees in Jax.\n\n    Parameters\n    ----------\n    aux_data : None\n        Auxiliary data. Not used in this class.\n    children : tuple\n        Tuple of children to be unflattened.\n    \"\"\"\n    return cls(*children)\n</code></pre>"},{"location":"pages/api/swarmrl.components.swarm/#swarmrl.components.swarm.create_swarm","title":"<code>create_swarm(colloids)</code>","text":"<p>Create a swarm from a list of colloid objects.</p>"},{"location":"pages/api/swarmrl.components.swarm/#swarmrl.components.swarm.create_swarm--parameters","title":"Parameters","text":"<p>colloid : List[Colloid]     List of colloid objects.</p>"},{"location":"pages/api/swarmrl.components.swarm/#swarmrl.components.swarm.create_swarm--returns","title":"Returns","text":"<p>Swarm     Swarm object full of all colloids</p> Source code in <code>swarmrl/components/swarm.py</code> <pre><code>def create_swarm(colloids: List[Colloid]) -&gt; Swarm:\n    \"\"\"\n    Create a swarm from a list of colloid objects.\n\n    Parameters\n    ----------\n    colloid : List[Colloid]\n        List of colloid objects.\n\n    Returns\n    -------\n    Swarm\n        Swarm object full of all colloids\n    \"\"\"\n    # standard colloid attributes\n    pos = np.array([c.pos for c in colloids]).reshape(-1, colloids[0].pos.shape[0])\n    director = np.array([c.director for c in colloids]).reshape(\n        -1, colloids[0].director.shape[0]\n    )\n    id = np.array([c.id for c in colloids]).reshape(-1, 1)\n    velocity = np.array([c.velocity for c in colloids]).reshape(\n        -1, colloids[0].velocity.shape[0]\n    )\n    type = np.array([c.type for c in colloids]).reshape(-1, 1)\n\n    # add species indices to the colloid types.\n    type_indices = {}\n    types = onp.unique(type)\n    for t in types:\n        type_indices[t] = np.array(get_colloid_indices(colloids, t))\n\n    return Swarm(pos, director, id, velocity, type, type_indices)\n</code></pre>"},{"location":"pages/api/swarmrl.engine.engine/","title":"swarmrl.engine.engine Module API Reference","text":"<p>Parent class for the engine.</p>"},{"location":"pages/api/swarmrl.engine.engine/#swarmrl.engine.engine.Engine","title":"<code>Engine</code>","text":"<p>Parent class for an engine.</p> <p>An engine is an object that can generate data for the environment. Currently we have only an espresso model but this should be kept generic to allow for an experimental interface.</p> Source code in <code>swarmrl/engine/engine.py</code> <pre><code>class Engine:\n    \"\"\"\n    Parent class for an engine.\n\n    An engine is an object that can generate data for the environment. Currently we\n    have only an espresso model but this should be kept generic to allow for an\n    experimental interface.\n    \"\"\"\n\n    def integrate(\n        self,\n        n_slices: int,\n        force_model: ForceFunction,\n    ) -&gt; None:\n        \"\"\"\n\n        Parameters\n        ----------\n        n_slices: int\n            Number of time slices to integrate\n        force_model\n            A an instance of ForceFunction\n        \"\"\"\n        raise NotImplementedError\n\n    def get_particle_data(self) -&gt; dict:\n        \"\"\"\n        Get type, id, position, velocity and director of the particles\n        as a dict of np.array\n        \"\"\"\n        raise NotImplementedError\n\n    def finalize(self):\n        \"\"\"\n        Optional: to clean up after finishing the simulation (e.g. writing the last\n        chunks of trajectory)\n        \"\"\"\n        pass\n</code></pre>"},{"location":"pages/api/swarmrl.engine.engine/#swarmrl.engine.engine.Engine.finalize","title":"<code>finalize()</code>","text":"<p>Optional: to clean up after finishing the simulation (e.g. writing the last chunks of trajectory)</p> Source code in <code>swarmrl/engine/engine.py</code> <pre><code>def finalize(self):\n    \"\"\"\n    Optional: to clean up after finishing the simulation (e.g. writing the last\n    chunks of trajectory)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"pages/api/swarmrl.engine.engine/#swarmrl.engine.engine.Engine.get_particle_data","title":"<code>get_particle_data()</code>","text":"<p>Get type, id, position, velocity and director of the particles as a dict of np.array</p> Source code in <code>swarmrl/engine/engine.py</code> <pre><code>def get_particle_data(self) -&gt; dict:\n    \"\"\"\n    Get type, id, position, velocity and director of the particles\n    as a dict of np.array\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"pages/api/swarmrl.engine.engine/#swarmrl.engine.engine.Engine.integrate","title":"<code>integrate(n_slices, force_model)</code>","text":""},{"location":"pages/api/swarmrl.engine.engine/#swarmrl.engine.engine.Engine.integrate--parameters","title":"Parameters","text":"<p>n_slices: int     Number of time slices to integrate force_model     A an instance of ForceFunction</p> Source code in <code>swarmrl/engine/engine.py</code> <pre><code>def integrate(\n    self,\n    n_slices: int,\n    force_model: ForceFunction,\n) -&gt; None:\n    \"\"\"\n\n    Parameters\n    ----------\n    n_slices: int\n        Number of time slices to integrate\n    force_model\n        A an instance of ForceFunction\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/","title":"swarmrl.engine.espresso Module API Reference","text":"<p>Module for the espressoMD simulations.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD","title":"<code>EspressoMD</code>","text":"<p>             Bases: <code>Engine</code></p> <p>A class to manage the espressoMD environment.</p> <p>Methods are allowed to add particles until the first call to integrate().</p> <p>Dev Note: These methods need to register the new particles in self.colloid_radius_register The first call to integrate() will then setup the interactions and database output.</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>class EspressoMD(Engine):\n    \"\"\"\n    A class to manage the espressoMD environment.\n\n    Methods are allowed to add particles until the first call to integrate().\n\n    Dev Note: These methods need to register the new particles\n    in self.colloid_radius_register\n    The first call to integrate() will then setup the interactions and database output.\n    \"\"\"\n\n    def __init__(\n        self,\n        md_params,\n        n_dims=3,\n        seed=42,\n        out_folder=\".\",\n        write_chunk_size=100,\n        system=None,\n    ):\n        \"\"\"\n        Constructor for the espressoMD engine.\n\n        Parameters\n        ----------\n        md_params : espresso.MDParams\n                Parameter class for the espresso simulation.\n        n_dims : int (default = 3)\n                Number of dimensions to consider in the simulation\n        seed : int\n                Seed number for any generators.\n        out_folder : str or pathlib.Path\n                Path to an output folder to store data in. This file should have a\n                reasonable amount of free space.\n        write_chunk_size : int\n                Chunk size to use in the hdf5 writing.\n        system : espressomd.System (optional)\n                Espresso system to use in this engine.\n                If not provided, a new system will be created.\n                Note: We try to clear the passed system of any previous contents,\n                but do not guarantee that everything is reset completely. Use at\n                own risk.\n        \"\"\"\n        self.params: MDParams = md_params\n        self.out_folder = pathlib.Path(out_folder).resolve()\n        self.seed = seed\n        self.rng = np.random.default_rng(self.seed)\n        if n_dims not in [2, 3]:\n            raise ValueError(\"Only 2d and 3d are allowed\")\n        self.n_dims = n_dims\n\n        self._init_unit_system()\n        self.write_chunk_size = write_chunk_size\n\n        if system is None:\n            self.system = espressomd.System(box_l=3 * [1.0])\n        else:\n            self.system = _reset_system(system)\n        self._init_system()\n\n        self.colloids = list()\n        self.lbf: espressomd.lb.LBFluidWalberla = None\n\n        # register to lookup which type has which radius\n        self.colloid_radius_register = {}\n\n        # after the first call to integrate, no more changes to the engine are allowed\n        self.integration_initialised = False\n\n        espressomd.assert_features(\n            [\"ROTATION\", \"EXTERNAL_FORCES\", \"THERMOSTAT_PER_PARTICLE\"]\n        )\n\n    def _init_unit_system(self):\n        \"\"\"\n        Initialize the unit registry managed by pint.\n\n        Returns\n        -------\n        Updates the class state.\n        \"\"\"\n        self.ureg = self.params.ureg\n\n        # three basis units chosen arbitrarily\n        self.ureg.define(\"sim_length = 1e-6 meter\")\n        self.ureg.define(\"sim_time = 1 second\")\n        self.ureg.define(\"sim_energy = 293 kelvin * boltzmann_constant\")\n\n        # derived units\n        self.ureg.define(\"sim_velocity = sim_length / sim_time\")\n        self.ureg.define(\"sim_angular_velocity = 1 / sim_time\")\n        self.ureg.define(\"sim_mass = sim_energy / sim_velocity**2\")\n        self.ureg.define(\"sim_rinertia = sim_length**2 * sim_mass\")\n        self.ureg.define(\"sim_dyn_viscosity = sim_mass / (sim_length * sim_time)\")\n        self.ureg.define(\"sim_kin_viscosity = sim_length**2 / sim_time\")\n        self.ureg.define(\"sim_force = sim_mass * sim_length / sim_time**2\")\n        self.ureg.define(\"sim_torque = sim_length * sim_force\")\n\n    def _init_system(self):\n        \"\"\"\n        Prepare the simulation box with the given parameters.\n\n        Returns\n        -------\n        Update the class state.\n        \"\"\"\n        # parameter unit conversion\n        time_step = self.params.time_step.m_as(\"sim_time\")\n        # time slice: the amount of time the integrator runs before we look at the\n        # configuration and change forces\n        time_slice = self.params.time_slice.m_as(\"sim_time\")\n\n        write_interval = self.params.write_interval.m_as(\"sim_time\")\n\n        box_l = np.array(self.params.box_length.m_as(\"sim_length\"))\n        if np.isscalar(box_l):\n            raise ValueError(\n                \"box_length must be a 3d vector (or 2d if you have a 2d system)\"\n            )\n        if self.n_dims == 2 and len(box_l) == 2:\n            # if a 2d system is simulated, the third dimension does not\n            # matter but must still be set\n            box_l = np.array([box_l[0], box_l[1], box_l[0]])\n        if len(box_l) != 3:\n            raise ValueError(\n                f\"box_length must be a 3d vector. You gave {self.params.box_length}\"\n            )\n\n        # system setup. Skin is a verlet list parameter that has to be set, but only\n        # affects performance\n        self.system.box_l = box_l\n        self.system.time_step = time_step\n        self.system.cell_system.skin = 0.4\n        self.system.periodicity = 3 * [self.params.periodic]\n\n        # set writer params\n        steps_per_write_interval = int(round(write_interval / time_step))\n        self.params.steps_per_write_interval = steps_per_write_interval\n        if abs(steps_per_write_interval - write_interval / time_step) &gt; 1e-10:\n            raise ValueError(\n                \"inconsistent parameters: write_interval must be integer multiple of\"\n                \" time_step\"\n            )\n\n        # set integrator params\n        steps_per_slice = int(round(time_slice / time_step))\n        self.params.steps_per_slice = steps_per_slice\n        if abs(steps_per_slice - time_slice / time_step) &gt; 1e-10:\n            raise ValueError(\n                \"inconsistent parameters: time_slice must be integer multiple of\"\n                \" time_step\"\n            )\n\n    def _rotate_colloid_to_2d(self, colloid, theta):\n        # rotate around the y-axis by 90 degrees\n        colloid.rotate(axis=[0, 1, 0], angle=np.pi / 2.0)\n        # now the particle points along the x-axis. The lab-z axis is the\n        # body-frame (-x) -axis. We only allow rotation around the\n        # labframe-z-axis from now on\n        colloid.rotation = [True, False, False]\n        # now rotate in-plane\n        colloid.rotate(axis=[0, 0, 1], angle=theta)\n\n    def _check_already_initialised(self):\n        if self.integration_initialised:\n            raise RuntimeError(\n                \"You cannot change the system configuration \"\n                \"after the first call to integrate()\"\n            )\n\n    def add_colloid_on_point(\n        self,\n        radius_colloid: pint.Quantity = None,\n        init_position: pint.Quantity = None,\n        init_direction: np.array = np.array([1, 0, 0]),\n        type_colloid=0,\n        gamma_translation: pint.Quantity = None,\n        gamma_rotation: pint.Quantity = None,\n        aspect_ratio: float = 1.0,\n        mass: pint.Quantity = None,\n        rinertia: pint.Quantity = None,\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        radius_colloid\n            default: 1 micrometer\n        init_position\n            default: center of the box\n        init_direction\n            default: along x\n        type_colloid\n            The colloids created from this method call will have this type.\n            Multiple calls can be made with the same type_colloid.\n            Interaction models need to be made aware if there are different types\n            of colloids in the system if specific behaviour is desired.\n        gamma_translation, gamma_rotation: pint.Quantity[np.array], optional\n            If None, calculate these quantities from the radius and the fluid viscosity.\n            You can provide friction coefficients as scalars or a 3-vector\n            (the diagonal elements of the friction tensor).\n        aspect_ratio: float, optional\n            If you provide a value != 1, a gay-berne interaction will be set up\n            instead of purely repulsive lennard jones.\n            aspect_ratio &gt; 1 will produce a cigar, aspect_ratio &lt; 0 a disk\n            (both swimming in the direction of symmetry).\n        mass: optional\n            Particle mass. Only relevant for Langevin integrator.\n        rinertia: optional\n            Diagonal elements of the rotational moment of inertia tensor\n            of the particle, assuming the particle is oriented along z.\n\n        Returns\n        -------\n        colloid.\n\n        \"\"\"\n\n        self._check_already_initialised()\n\n        if radius_colloid is None:\n            radius_colloid = self.ureg.Quantity(1, \"micrometer\")\n        if init_position is None:\n            init_position = 0.5 * self.params.box_length\n\n        if type_colloid in self.colloid_radius_register.keys():\n            if self.colloid_radius_register[type_colloid][\n                \"radius\"\n            ] != radius_colloid.m_as(\"sim_length\"):\n                raise ValueError(\n                    f\"The chosen type {type_colloid} is already taken and used with a\"\n                    \" different radius\"\n                    f\" {self.colloid_radius_register[type_colloid]['radius']}. Choose a\"\n                    \" new combination\"\n                )\n\n        radius_simunits = radius_colloid.m_as(\"sim_length\")\n        init_pos = init_position.m_as(\"sim_length\")\n        init_direction = init_direction / np.linalg.norm(init_direction)\n\n        (\n            gamma_translation_sphere,\n            gamma_rotation_sphere,\n        ) = _calc_friction_coefficients(\n            self.params.fluid_dyn_viscosity.m_as(\"sim_dyn_viscosity\"), radius_simunits\n        )\n        if gamma_translation is None:\n            gamma_translation = gamma_translation_sphere\n        else:\n            gamma_translation = gamma_translation.m_as(\"sim_force/sim_velocity\")\n        if gamma_rotation is None:\n            gamma_rotation = gamma_rotation_sphere\n        else:\n            gamma_rotation = gamma_rotation.m_as(\"sim_torque/sim_angular_velocity\")\n\n        if self.params.thermostat_type == \"langevin\":\n            if mass is None:\n                raise ValueError(\n                    \"If you use the Langevin thermostat, you must set a particle mass\"\n                )\n            if rinertia is None:\n                raise ValueError(\n                    \"If you use the Langevin thermostat, you must set a particle\"\n                    \" rotational inertia\"\n                )\n        else:\n            # mass and moment of inertia can still be relevant when calculating\n            # the stochastic part of the particle velocity, see\n            # https://espressomd.github.io/doc/integration.html#brownian-thermostat.\n            # Provide defaults in case the user didn't set the values.\n            water_dens = self.params.ureg.Quantity(1000, \"kg/meter**3\")\n            if mass is None:\n                mass = water_dens * 4.0 / 3.0 * np.pi * radius_colloid**3\n            if rinertia is None:\n                rinertia = 2.0 / 5.0 * mass * radius_colloid**2\n                rinertia = utils.convert_array_of_pint_to_pint_of_array(\n                    3 * [rinertia], self.params.ureg\n                )\n\n        if self.n_dims == 3:\n            colloid = self.system.part.add(\n                pos=init_pos,\n                director=init_direction,\n                rotation=3 * [True],\n                gamma=gamma_translation,\n                gamma_rot=gamma_rotation,\n                fix=3 * [False],\n                type=type_colloid,\n                mass=mass.m_as(\"sim_mass\"),\n                rinertia=rinertia.m_as(\"sim_rinertia\"),\n            )\n        else:\n            # initialize with body-frame = lab-frame to set correct rotation flags\n            # allow all rotations to bring the particle to correct state\n            init_pos[2] = 0  # get rid of z-coordinate in 2D coordinates\n            colloid = self.system.part.add(\n                pos=init_pos,\n                fix=[False, False, True],\n                rotation=3 * [True],\n                gamma=gamma_translation,\n                gamma_rot=gamma_rotation,\n                quat=[1, 0, 0, 0],\n                type=type_colloid,\n                mass=mass.m_as(\"sim_mass\"),\n                rinertia=rinertia.m_as(\"sim_rinertia\"),\n            )\n            theta, phi = utils.angles_from_vector(init_direction)\n            if abs(theta - np.pi / 2) &gt; 10e-6:\n                raise ValueError(\n                    \"It seems like you want to have a 2D simulation\"\n                    \" with colloids that point some amount in Z-direction.\"\n                    \" Change something in your colloid setup.\"\n                )\n            self._rotate_colloid_to_2d(colloid, phi)\n\n        self.colloids.append(colloid)\n\n        self.colloid_radius_register.update(\n            {type_colloid: {\"radius\": radius_simunits, \"aspect_ratio\": aspect_ratio}}\n        )\n\n        return colloid\n\n    def add_colloids(\n        self,\n        n_colloids: int,\n        radius_colloid: pint.Quantity = None,\n        random_placement_center: pint.Quantity = None,\n        random_placement_radius: pint.Quantity = None,\n        type_colloid: int = 0,\n        gamma_translation: pint.Quantity = None,\n        gamma_rotation: pint.Quantity = None,\n        aspect_ratio: float = 1.0,\n        mass: pint.Quantity = None,\n        rinertia: pint.Quantity = None,\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        n_colloids\n        radius_colloid\n            default: 1 micrometer\n        random_placement_center\n            default: center of the box\n        random_placement_radius\n            default: half the box dimension\n        type_colloid\n            The colloids created from this method call will have this type.\n            Multiple calls can be made with the same type_colloid.\n            Interaction models need to be made aware if there are different types\n            of colloids in the system if specific behaviour is desired.\n        gamma_translation, gamma_rotation: optional\n            If None, calculate these quantities from the radius and the fluid viscosity.\n            You can provide friction coefficients as scalars or a 3-vector\n            (the diagonal elements of the friction tensor)\n        aspect_ratio\n            If you provide a value != 1, a gay-berne interaction will be set up\n            instead of purely repulsive lennard jones.\n            aspect_ratio &gt; 1 will produce a cigar, aspect_ratio &lt; 0 a disk\n            (both swimming in the direction of symmetry).\n            The radius_colloid gives the radius perpendicular to the symmetry axis.\n        mass: optional\n            Particle mass. Only relevant for Langevin integrator.\n        rinertia: optional\n            Diagonal elements of the rotational moment of inertia tensor\n            of the particle, assuming the particle is oriented along z.\n\n\n        Returns\n        -------\n\n        \"\"\"\n\n        self._check_already_initialised()\n\n        if random_placement_center is None:\n            random_placement_center = self.ureg.Quantity(\n                0.5 * self.params.box_length.m_as(\"sim_length\"), \"sim_length\"\n            )\n        if random_placement_radius is None:\n            random_placement_radius = 0.5 * min(self.params.box_length)\n\n        init_center = random_placement_center.m_as(\"sim_length\")\n        init_rad = random_placement_radius.m_as(\"sim_length\")\n\n        for i in range(n_colloids):\n            start_pos = (\n                _get_random_start_pos(init_rad, init_center, self.n_dims, self.rng)\n                * self.ureg.sim_length\n            )\n\n            if self.n_dims == 3:\n                init_direction = utils.vector_from_angles(\n                    *utils.get_random_angles(self.rng)\n                )\n            else:\n                start_angle = 2 * np.pi * self.rng.random()\n                init_direction = utils.vector_from_angles(np.pi / 2, start_angle)\n            self.add_colloid_on_point(\n                radius_colloid=radius_colloid,\n                init_position=start_pos,\n                init_direction=init_direction,\n                type_colloid=type_colloid,\n                gamma_translation=gamma_translation,\n                gamma_rotation=gamma_rotation,\n                aspect_ratio=aspect_ratio,\n                mass=mass,\n                rinertia=rinertia,\n            )\n\n    def add_rod(\n        self,\n        rod_center: pint.Quantity = None,\n        rod_length: pint.Quantity = None,\n        rod_thickness: pint.Quantity = None,\n        rod_start_angle: float = None,\n        n_particles: int = None,\n        friction_trans: pint.Quantity = None,\n        friction_rot: pint.Quantity = None,\n        rod_particle_type: int = None,\n        fixed: bool = True,\n    ):\n        \"\"\"\n        Add a rod to the system.\n        A rod consists of n_particles point particles that are rigidly connected\n        and rotate/move as a whole\n        Parameters\n        ----------\n        rod_center\n            default: center of the box\n        rod_length\n            default: 100 micrometer\n        rod_thickness\n            default: 5 micrometer\n            Make sure there are enough particles.\n            If the thickness is too thin, the rod might get holes\n        rod_start_angle\n            default: 0\n        n_particles\n            default: 101\n            Must be uneven number such that there always is a central particle\n        friction_trans\n            Irrelevant if fixed==True\n            must be provided\n        friction_rot\n            must be provided\n        rod_particle_type\n            The rod is made out of points so they get their own type.\n        fixed\n            Fixes the central particle of the rod.\n\n        Returns\n        -------\n        The espresso handle to the central particle. For debugging purposes only\n        \"\"\"\n        self._check_already_initialised()\n\n        if rod_center is None:\n            rod_center = self.params.box_length / 2.0\n        if rod_length is None:\n            rod_length = self.ureg.Quantity(100, \"micrometer\")\n        if rod_thickness is None:\n            rod_thickness = self.ureg.Quantity(5, \"micrometer\")\n        if rod_start_angle is None:\n            rod_start_angle = 0\n        if n_particles is None:\n            n_particles = 101\n        if friction_trans is None and not fixed:\n            raise ValueError(\n                \"If you want the rod to move, you must provide a friction coefficient\"\n            )\n        if friction_rot is None:\n            raise ValueError(\"You must provide a rotational friction coefficient\")\n        if rod_particle_type is None:\n            raise ValueError(\"You must provide a particle type for the rod\")\n\n        if self.n_dims != 2:\n            raise ValueError(\"Rod can only be added in 2d\")\n        if rod_center[2].magnitude != 0:\n            raise ValueError(f\"Rod center z-component must be 0. You gave {rod_center}\")\n        if n_particles % 2 != 1:\n            raise ValueError(f\"n_particles must be uneven. You gave {n_particles}\")\n\n        espressomd.assert_features([\"VIRTUAL_SITES_RELATIVE\"])\n        import espressomd.virtual_sites as evs\n\n        self.system.virtual_sites = evs.VirtualSitesRelative(have_quaternion=True)\n\n        center_pos = rod_center.m_as(\"sim_length\")\n        fric_trans = friction_trans.m_as(\"sim_force/sim_velocity\")  # [F / v]\n        fric_rot = friction_rot.m_as(\n            \"sim_force * sim_length *  sim_time\"\n        )  # [M / omega]\n        partcl_radius = rod_thickness.m_as(\"sim_length\") / 2\n\n        # place the real particle\n        center_part = self.system.part.add(\n            pos=center_pos,\n            quat=[1, 0, 0, 0],\n            rotation=3 * [True],\n            fix=[fixed, fixed, True],\n            gamma=fric_trans,\n            gamma_rot=fric_rot,\n            type=rod_particle_type,\n        )\n        self._rotate_colloid_to_2d(center_part, rod_start_angle)\n        self.colloids.append(center_part)\n\n        # place virtual\n        point_span = rod_length.m_as(\"sim_length\") - 2 * partcl_radius\n        point_dist = point_span / (n_particles - 1)\n        if point_dist &gt; 2 * partcl_radius:\n            logger.warning(\n                \"your rod has holes. \"\n                f\"Particle radius {partcl_radius} \"\n                f\"particle_distance {point_dist} \"\n                \"(both in simulation units)\"\n            )\n\n        director = utils.vector_from_angles(np.pi / 2, rod_start_angle)\n\n        for k in range(n_particles - 1):\n            dist_to_center = (-1) ** k * (k // 2 + 1) * point_dist\n            pos_virt = center_pos + dist_to_center * director\n            virtual_partcl = self.system.part.add(\n                pos=pos_virt, director=director, virtual=True, type=rod_particle_type\n            )\n            virtual_partcl.vs_auto_relate_to(center_part)\n            self.colloids.append(virtual_partcl)\n\n        self.colloid_radius_register.update(\n            {rod_particle_type: {\"radius\": partcl_radius, \"aspect_ratio\": 1.0}}\n        )\n        return center_part\n\n    def add_confining_walls(self, wall_type: int):\n        \"\"\"\n        Walls on the edges of the box, will interact with particles through WCA.\n        Is NOT communicated to the interaction models, though.\n\n        Parameters\n        ----------\n        wall_type : int\n            Wall interacts with particles, so it needs its own type.\n\n        Returns\n        -------\n        \"\"\"\n        self._check_already_initialised()\n        if wall_type in self.colloid_radius_register.keys():\n            raise ValueError(\n                f\"wall type {wall_type} is already taken \"\n                \"by other system component. Choose a new one\"\n            )\n\n        wall_shapes = []\n        wall_shapes.append(espressomd.shapes.Wall(dist=0, normal=[1, 0, 0]))\n        wall_shapes.append(\n            espressomd.shapes.Wall(dist=-self.system.box_l[0], normal=[-1, 0, 0])\n        )\n        wall_shapes.append(espressomd.shapes.Wall(dist=0, normal=[0, 1, 0]))\n        wall_shapes.append(\n            espressomd.shapes.Wall(dist=-self.system.box_l[1], normal=[0, -1, 0])\n        )\n        if self.n_dims == 3:\n            wall_shapes.append(espressomd.shapes.Wall(dist=0, normal=[0, 0, 1]))\n            wall_shapes.append(\n                espressomd.shapes.Wall(dist=-self.system.box_l[2], normal=[0, 0, -1])\n            )\n\n        for wall_shape in wall_shapes:\n            constr = espressomd.constraints.ShapeBasedConstraint(\n                shape=wall_shape, particle_type=wall_type, penetrable=False\n            )\n            self.system.constraints.add(constr)\n\n        # the wall itself has no radius, only the particle radius counts\n        self.colloid_radius_register.update(\n            {wall_type: {\"radius\": 0.0, \"aspect_ratio\": 1.0}}\n        )\n\n    def add_walls(\n        self,\n        wall_start_point: pint.Quantity,\n        wall_end_point: pint.Quantity,\n        wall_type: int,\n        wall_thickness: pint.Quantity,\n    ):\n        \"\"\"\n        User defined walls will interact with particles through WCA.\n        Is NOT communicated to the interaction models, though.\n        The walls have a large height resulting in 2D-walls in a 2D-simulation.\n        The actual height adapts to the chosen box size.\n        The shape of the underlying constraint is a square.\n\n        Parameters\n        ----------\n        wall_start_point : pint.Quantity\n        np.array (n,2) with wall coordinates\n             [x_begin, y_begin]\n        wall_end_point : pint.Quantity\n        np.array (n,2) with wall coordinates\n             [x_end, y_end]\n        wall_type : int\n            Wall interacts with particles, so it needs its own type.\n        wall_thickness: pint.Quantity\n            wall thickness\n\n        Returns\n        -------\n        \"\"\"\n\n        wall_start_point = wall_start_point.m_as(\"sim_length\")\n        wall_end_point = wall_end_point.m_as(\"sim_length\")\n        wall_thickness = wall_thickness.m_as(\"sim_length\")\n\n        if len(wall_start_point) != len(wall_end_point):\n            raise ValueError(\n                \" Please double check your walls. There are more or less \"\n                f\" starting points {len(wall_start_point)} than \"\n                f\" end points {len(wall_end_point)}. They should be equal.\"\n            )\n\n        self._check_already_initialised()\n        if wall_type in self.colloid_radius_register.keys():\n            if self.colloid_radius_register[wall_type] != 0.0:\n                raise ValueError(\n                    f\" The chosen type {wall_type} is already taken\"\n                    \"and used with a different radius \"\n                    f\"{self.colloid_radius_register[wall_type]['radius']}.\"\n                    \" Choose a new combination\"\n                )\n\n        z_height = self.system.box_l[2]\n        wall_shapes = []\n\n        for wall_index in range(len(wall_start_point)):\n            a = [\n                wall_end_point[wall_index, 0] - wall_start_point[wall_index, 0],\n                wall_end_point[wall_index, 1] - wall_start_point[wall_index, 1],\n                0,\n            ]  # direction along lengthy wall\n            c = [0, 0, z_height]  # direction along third axis of 2D simulation\n            norm_a = np.linalg.norm(a)  # is also the norm of b\n            norm_c = np.linalg.norm(c)\n            b = (\n                np.cross(a / norm_a, c / norm_c) * wall_thickness\n            )  # direction along second axis\n            # i.e along wall_thickness of lengthy wall\n            corner = [\n                wall_start_point[wall_index, 0] - b[0] / 2,\n                wall_start_point[wall_index, 1] - b[1] / 2,\n                0,\n            ]  # anchor point of wall shifted by wall_thickness*1/2\n\n            wall_shapes.append(\n                espressomd.shapes.Rhomboid(corner=corner, a=a, b=b, c=c, direction=1)\n            )\n\n        for wall_shape in wall_shapes:\n            constr = espressomd.constraints.ShapeBasedConstraint(\n                shape=wall_shape, particle_type=wall_type, penetrable=False\n            )\n            self.system.constraints.add(constr)\n\n        # the wall itself has no radius, only the particle radius counts\n        self.colloid_radius_register.update(\n            {wall_type: {\"radius\": 0.0, \"aspect_ratio\": 1.0}}\n        )\n\n    def _setup_interactions(self):\n        aspect_ratios = [\n            d[\"aspect_ratio\"] for d in self.colloid_radius_register.values()\n        ]\n        if len(np.unique(aspect_ratios)) &gt; 1:\n            raise ValueError(\n                \"All particles in the system must have the same aspect ratio.\"\n            )\n        for type_0, prop_dict_0 in self.colloid_radius_register.items():\n            for type_1, prop_dict_1 in self.colloid_radius_register.items():\n                if type_0 &gt; type_1:\n                    continue\n                if prop_dict_0[\"aspect_ratio\"] == 1.0:\n                    self.system.non_bonded_inter[type_0, type_1].wca.set_params(\n                        sigma=(prop_dict_0[\"radius\"] + prop_dict_1[\"radius\"])\n                        * 2 ** (-1 / 6),\n                        epsilon=self.params.WCA_epsilon.m_as(\"sim_energy\"),\n                    )\n                else:\n                    espressomd.assert_features([\"GAY_BERNE\"])\n                    aspect = prop_dict_0[\"aspect_ratio\"]\n                    self.system.non_bonded_inter[type_0, type_1].gay_berne.set_params(\n                        sig=(prop_dict_0[\"radius\"] + prop_dict_1[\"radius\"])\n                        * 2 ** (-1 / 6),\n                        k1=prop_dict_0[\"aspect_ratio\"],\n                        k2=1.0,\n                        nu=1,\n                        mu=2,\n                        cut=2 * prop_dict_0[\"radius\"] * max([aspect, 1 / aspect]) * 2,\n                        eps=self.params.WCA_epsilon.m_as(\"sim_energy\"),\n                    )\n\n    def add_const_force_to_colloids(self, force: pint.Quantity, type: int):\n        \"\"\"\n        Parameters\n        ----------\n        force: pint.Quantity\n            A Quantity of numpy array, e.g. f = Quantity(np.array([1,2,3]), \"newton\")\n        type: int\n            The type of colloid that gets the force.\n            Needs to be already added to the engine\n        \"\"\"\n        force_simunits = force.m_as(\"sim_force\")\n        parts = self.system.part.select(type=type)\n        if len(parts) == 0:\n            raise ValueError(\n                f\"Particles of type {type} not added to engine. \"\n                f\"You currently have {self.colloid_radius_register.keys()}\"\n            )\n        parts.ext_force = force_simunits\n\n    def add_lattice_boltzmann(\n        self,\n        agrid: pint.Quantity = None,\n        lb_time_step: pint.Quantity = None,\n        dynamic_viscosity: pint.Quantity = None,\n        fluid_density: pint.Quantity = None,\n        boundary_mask: np.array = None,\n        ext_force_density: pint.Quantity = None,\n        use_GPU: bool = False,\n    ):\n        \"\"\"\n        Add a lattice boltzmann fluid to the simulation.\n\n        Parameters:\n        -----------\n\n        agrid: pint.Quantity, scalar\n            The uniform grid spacing in all 3 dimensions.\n            Must be compatible with params.box_length.\n        lb_time_step: pint.Quantity, scalar, optional\n            Lb time step, must be integer multiple of params.time_step.\n            Default: params.time_step\n        dynamic_viscosity: pint.Quantity, scalar, optional\n            default: self.params.fluid_dyn_viscosity\n            only change if you know what you are doing\n        fluid_density: pint.Quantity, scalar, optional\n            default: 1000kg/m**3\n        boundary_mask: np.array, optional:\n            A 3D boolean array that defines the no-slip boundary cells of the fluid.\n            Must be compatible with the grid that gets generated\n            from params.box_length and agrid.\n        ext_force_density: pint.Quantity, 3d vector, optional.\n            default: [0,0,0] N/m**3\n        \"\"\"\n        if not self.params.thermostat_type == \"langevin\":\n            raise RuntimeError(\n                \"Coupling to lattice boltzmann does not work with a Brownian\"\n                \" thermostat. Use 'langevin'.\"\n            )\n\n        if agrid is None:\n            raise ValueError(\"agrid must be provided\")\n        if lb_time_step is None:\n            lb_time_step = self.params.time_step\n        if dynamic_viscosity is None:\n            dynamic_viscosity = self.params.fluid_dyn_viscosity\n        if fluid_density is None:\n            fluid_density = self.ureg.Quantity(1000, \"kg/m**3\")\n        if ext_force_density is None:\n            ext_force_density = self.ureg.Quantity(np.zeros(3), \"N/m**3\")\n        if use_GPU:\n            raise NotImplementedError(\n                \"GPU support is not yet implemented. Stay tuned tho\"\n            )\n\n        lbf = espressomd.lb.LBFluidWalberla(\n            tau=lb_time_step.m_as(\"sim_time\"),\n            kT=(self.params.temperature * self.ureg.boltzmann_constant).m_as(\n                \"sim_energy\"\n            ),\n            density=fluid_density.m_as(\"sim_mass/sim_length**3\"),\n            kinematic_viscosity=(dynamic_viscosity / fluid_density).m_as(\n                \"sim_kin_viscosity\"\n            ),\n            agrid=agrid.m_as(\"sim_length\"),\n            seed=self.seed,\n            ext_force_density=ext_force_density.m_as(\"sim_force/sim_length**3\"),\n        )\n\n        if boundary_mask is not None:\n            from espressomd.script_interface import array_variant\n\n            if not np.all(lbf.shape == boundary_mask.shape):\n                raise ValueError(\n                    \"boundary_mask must have the same shape as the fluid grid\"\n                )\n\n            lbf.call_method(\n                \"add_boundary_from_shape\",\n                raster=array_variant(boundary_mask.astype(int).flatten()),\n                values=array_variant(np.zeros(3, dtype=float).flatten()),\n            )\n\n        self.lbf = lbf\n\n        return lbf\n\n    def add_flowfield(\n        self,\n        flowfield: pint.Quantity,\n        friction_coeff: pint.Quantity,\n        grid_spacings: pint.Quantity,\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        flowfield: pint.Quantity[np.array]\n            The flowfield to add, given as a pint Quantity of a numpy array\n            with units of velocity.\n            Must have shape (n_cells_x, n_cells_y, n_cells_z, 3)\n            The velocity values must be centered in the corresponding grid,\n            e.g. the [idx_x,idx_y,idx_z, :] value of the array contains the velocity at\n            np.dot([idx_x+0.5,idx_y+0.5,idx_z+0.5],[agrid_x,agrid_y,agrid_z]).\n            From these points, the velocity is interpolated to the particle positions.\n        friction_coeff: pint.Quantity[float]\n            The friction coefficient in units of mass/time.\n            Espresso does not yet support particle-specific or anisotropic\n            friction coefficients for flow coupling, so one scalar value has to be\n            provided here which will be used for all particles.\n        grid_spacings: pint.Quantity[np.array]\n            This grid spacing will be used to fit the flowfield into the simulation box.\n            If you run a 2d-simulation, choose grid_spacings[2]=box_l.\n        \"\"\"\n\n        if not self.params.thermostat_type == \"langevin\":\n            raise RuntimeError(\n                \"Coupling to a flowfield does not work with a Brownian thermostat. Use\"\n                \" 'langevin'.\"\n            )\n\n        flow = flowfield.m_as(\"sim_velocity\")\n        gamma = friction_coeff.m_as(\"sim_mass/sim_time\")\n        agrids = grid_spacings.m_as(\"sim_length\")\n\n        if not flow.ndim == 4:\n            raise ValueError(\n                \"flowfield must have shape (n_cells_x, n_cells_y, n_cells_z, 3)\"\n            )\n        if not len(grid_spacings) == 3:\n            raise ValueError(\"Grid spacings must have length of 3\")\n\n        # espresso constraint field must be one grid larger in all directions\n        # for interpolation. Apply periodic boundary conditions\n        flow_padded = np.stack(\n            [np.pad(flow[:, :, :, i], mode=\"wrap\", pad_width=1) for i in range(3)],\n            axis=3,\n        )\n        flow_constraint = espressomd.constraints.FlowField(\n            field=flow_padded, gamma=gamma, grid_spacing=agrids\n        )\n        self.system.constraints.add(flow_constraint)\n\n    def add_external_potential(\n        self, potential: pint.Quantity, grid_spacings: pint.Quantity\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        potential: pint.Quantity[np.array]\n            The flowfield to add, given as a pint Quantity of a numpy array\n            with units of energy.\n            Must have shape (n_cells_x, n_cells_y, n_cells_z)\n            The potential values must be centered in the corresponding grid,\n            e.g. the [idx_x,idx_y,idx_z, :] value of the array contains the potential at\n            np.dot([idx_x+0.5, idx_y+0.5, idx_z+0.5], [agrid_x, agrid_y, agrid_z]).\n            From these points, the potential is interpolated to the particle positions.\n        grid_spacings: pint.Quantity[np.array]\n            This grid spacing will be used to fit the potential into the simulation box.\n            If you run a 2d-simulation, choose grid_spacings[2]=box_l.\n        \"\"\"\n\n        pot = potential.m_as(\"sim_energy\")\n        agrids = grid_spacings.m_as(\"sim_length\")\n\n        if not pot.ndim == 3:\n            raise ValueError(\n                \"potential must have shape (n_cells_x, n_cells_y, n_cells_z)\"\n            )\n        if not len(grid_spacings) == 3:\n            raise ValueError(\"Grid spacings must have length of 3\")\n\n        # Espresso constraint field must be one cell larger in all directions\n        # for interpolation. Apply periodic boundary conditions.\n        pot_padded = np.pad(\n            pot,\n            pad_width=1,\n            mode=\"wrap\",\n        )\n        pot_constraint = espressomd.constraints.PotentialField(\n            field=pot_padded[:, :, :, np.newaxis],\n            grid_spacing=agrids,\n            default_scale=1.0,\n        )\n        self.system.constraints.add(pot_constraint)\n\n    def get_friction_coefficients(self, type: int):\n        \"\"\"\n        Returns both the translational and the rotational friction coefficient\n        of the desired type in simulation units\n        \"\"\"\n        property_dict = self.colloid_radius_register.get(type, None)\n        if property_dict is None:\n            raise ValueError(\n                f\"cannot get friction coefficient for type {type}. Did you actually add\"\n                \" that particle type?\"\n            )\n        return _calc_friction_coefficients(\n            self.params.fluid_dyn_viscosity.m_as(\"sim_dyn_viscosity\"),\n            property_dict[\"radius\"],\n        )\n\n    def _init_h5_output(self):\n        \"\"\"\n        Initialize the hdf5 output.\n\n        This method will create a directory for the data to be stored within. Follwing\n        this, a hdf5 database is constructed for storing of the simulation data.\n\n\n        Returns\n        -------\n        Creates hdf5 database and updates class state.\n        \"\"\"\n        self.h5_filename = self.out_folder / \"trajectory.hdf5\"\n        self.out_folder.mkdir(parents=True, exist_ok=True)\n        self.traj_holder = {\n            \"Times\": list(),\n            \"Ids\": list(),\n            \"Types\": list(),\n            \"Unwrapped_Positions\": list(),\n            \"Velocities\": list(),\n            \"Directors\": list(),\n        }\n\n        n_colloids = len(self.colloids)\n\n        with h5py.File(self.h5_filename.as_posix(), \"a\") as h5_outfile:\n            part_group = h5_outfile.require_group(\"colloids\")\n            dataset_kwargs = dict(compression=\"gzip\")\n            traj_len = self.write_chunk_size\n\n            part_group.require_dataset(\n                \"Times\",\n                shape=(traj_len, 1, 1),\n                maxshape=(None, 1, 1),\n                dtype=float,\n                **dataset_kwargs,\n            )\n            for name in [\"Ids\", \"Types\"]:\n                part_group.require_dataset(\n                    name,\n                    shape=(traj_len, n_colloids, 1),\n                    maxshape=(None, n_colloids, 1),\n                    dtype=int,\n                    **dataset_kwargs,\n                )\n            for name in [\"Unwrapped_Positions\", \"Velocities\", \"Directors\"]:\n                part_group.require_dataset(\n                    name,\n                    shape=(traj_len, n_colloids, 3),\n                    maxshape=(None, n_colloids, 3),\n                    dtype=float,\n                    **dataset_kwargs,\n                )\n        self.write_idx = 0\n        self.h5_time_steps_written = 0\n\n    def _update_traj_holder(self):\n        if len(self.colloids) == 0:\n            logger.warning(\"No colloids in the system. Not writing to hdf5\")\n            return\n        # need to add axes on the non-vectorial quantities\n        self.traj_holder[\"Times\"].append(np.array([self.system.time])[:, np.newaxis])\n        self.traj_holder[\"Ids\"].append(\n            np.array([c.id for c in self.colloids])[:, np.newaxis]\n        )\n        self.traj_holder[\"Types\"].append(\n            np.array([c.type for c in self.colloids])[:, np.newaxis]\n        )\n        self.traj_holder[\"Unwrapped_Positions\"].append(\n            np.stack([c.pos for c in self.colloids], axis=0)\n        )\n        self.traj_holder[\"Velocities\"].append(\n            np.stack([c.v for c in self.colloids], axis=0)\n        )\n        self.traj_holder[\"Directors\"].append(\n            np.stack([c.director for c in self.colloids], axis=0)\n        )\n\n    def _write_traj_chunk_to_file(self):\n        \"\"\"\n        Write a chunk of data to the HDF5 database\n\n        Returns\n        -------\n        Adds data to the database and updates the class state.\n        \"\"\"\n        n_new_timesteps = len(self.traj_holder[\"Times\"])\n        if n_new_timesteps == 0:\n            return\n\n        with h5py.File(self.h5_filename, \"a\") as h5_outfile:\n            part_group = h5_outfile[\"colloids\"]\n            for key in self.traj_holder.keys():\n                dataset = part_group[key]\n                values = np.stack(self.traj_holder[key], axis=0)\n                # save in format (time_step, n_particles, dimension)\n                dataset.resize(self.h5_time_steps_written + n_new_timesteps, axis=0)\n                dataset[\n                    self.h5_time_steps_written : self.h5_time_steps_written\n                    + n_new_timesteps,\n                    ...,\n                ] = values\n\n        logger.debug(f\"wrote {n_new_timesteps} time steps to hdf5 file\")\n        self.h5_time_steps_written += n_new_timesteps\n\n    def _remove_overlap(self):\n        # remove overlap\n        self.system.integrator.set_steepest_descent(\n            f_max=0.0, gamma=0.1, max_displacement=0.1\n        )\n        self.system.integrator.run(1000)\n\n        # set the thermostat\n        kT = (self.params.temperature * self.ureg.boltzmann_constant).m_as(\"sim_energy\")\n\n        allowed_integrators = [\"brownian\", \"langevin\"]\n        if self.params.thermostat_type not in allowed_integrators:\n            raise ValueError(f\"integrator_type must be one of {allowed_integrators}\")\n\n        # Dummy gamma values, we set them for each particle separately.\n        # If we forget to do so, the simulation will explode as a gentle reminder\n        if self.params.thermostat_type == \"brownian\":\n            self.system.thermostat.set_brownian(\n                kT=kT,\n                gamma=1e-20,\n                gamma_rotation=1e-20,\n                seed=self.seed,\n                act_on_virtual=False,\n            )\n            self.system.integrator.set_brownian_dynamics()\n        elif self.params.thermostat_type == \"langevin\":\n            if self.lbf is None:\n                self.system.thermostat.set_langevin(\n                    kT=kT,\n                    gamma=1e-20,\n                    gamma_rotation=1e-20,\n                    seed=self.seed,\n                    act_on_virtual=False,\n                )\n            else:\n                self.system.lb = self.lbf\n                self.system.thermostat.set_lb(\n                    LB_fluid=self.lbf, gamma=1e300, seed=self.seed\n                )\n\n            self.system.integrator.set_vv()\n\n    def manage_forces(self, force_model: ForceFunction = None) -&gt; bool:\n        \"\"\"\n        Manage external forces.\n\n        Collect the forces from the force function and apply them to the colloids.\n\n        Parameters\n        ----------\n        force_model : ForceFunction\n            Model with which to compute external forces.\n        \"\"\"\n        swarmrl_colloids = []\n        if force_model is not None:\n            for col in self.colloids:\n                swarmrl_colloids.append(\n                    Colloid(\n                        pos=col.pos,\n                        velocity=col.v,\n                        director=col.director,\n                        id=col.id,\n                        type=col.type,\n                    )\n                )\n            actions = force_model.calc_action(swarmrl_colloids)\n            for action, coll in zip(actions, self.colloids):\n                coll.swimming = {\"f_swim\": action.force}\n                coll.ext_torque = (\n                    action.torque\n                    if action.torque is not None\n                    else np.zeros(\n                        3,\n                    )\n                )\n                new_direction = action.new_direction\n                if new_direction is not None:\n                    if self.n_dims == 3:\n                        coll.director = new_direction\n                    else:\n                        old_direction = coll.director\n                        rotation_angle = np.arccos(np.dot(new_direction, old_direction))\n                        if rotation_angle &gt; 1e-6:\n                            rotation_axis = np.cross(old_direction, new_direction)\n                            rotation_axis /= np.linalg.norm(rotation_axis)\n                            # only values of [0,0,1], [0,0,-1] can come out here,\n                            # plusminus numerical errors\n                            rotation_axis = [0, 0, round(rotation_axis[2])]\n                            coll.rotate(axis=rotation_axis, angle=rotation_angle)\n\n    def integrate(self, n_slices, force_model: ForceFunction = None):\n        \"\"\"\n        Integrate the system for n_slices steps.\n\n        Parameters\n        ----------\n        n_slices : int\n                Number of integration steps to run.\n        force_model : ForceFunction\n                A SwarmRL interaction model to decide particle interaction rules.\n\n        Returns\n        -------\n        Runs the simulation environment.\n        \"\"\"\n\n        if not self.integration_initialised:\n            self.slice_idx = 0\n            self.step_idx = 0\n            self._setup_interactions()\n            self._remove_overlap()\n            self._init_h5_output()\n            self.integration_initialised = True\n\n        old_slice_idx = self.slice_idx\n\n        while self.step_idx &lt; self.params.steps_per_slice * (old_slice_idx + n_slices):\n            if self.step_idx == self.params.steps_per_write_interval * self.write_idx:\n                self._update_traj_holder()\n                self.write_idx += 1\n\n                if len(self.traj_holder[\"Times\"]) &gt;= self.write_chunk_size:\n                    self._write_traj_chunk_to_file()\n                    for val in self.traj_holder.values():\n                        val.clear()\n\n            # Break the simulaion if the kill switch is engaged.\n            if force_model is not None:\n                if force_model.kill_switch:\n                    break\n\n            if self.step_idx == self.params.steps_per_slice * self.slice_idx:\n                self.slice_idx += 1\n                self.manage_forces(force_model)\n\n            steps_to_next_write = (\n                self.params.steps_per_write_interval * self.write_idx - self.step_idx\n            )\n            steps_to_next_slice = (\n                self.params.steps_per_slice * self.slice_idx - self.step_idx\n            )\n            steps_to_next = min(steps_to_next_write, steps_to_next_slice)\n\n            self.system.integrator.run(\n                steps_to_next, reuse_forces=True, recalc_forces=False\n            )\n            self.step_idx += steps_to_next\n\n    def finalize(self):\n        \"\"\"\n        Method to clean up after finishing the simulation\n\n        Method will write the last chunks of trajectory\n        \"\"\"\n        self._write_traj_chunk_to_file()\n\n    def get_particle_data(self):\n        \"\"\"\n        Collect specific particle information from the colloids.\n\n        Returns\n        -------\n        information : dict\n                A dict of information for all of the colloids in the system including\n                unwrapped positions, velocities, and the directors of the colloids.\n        \"\"\"\n        return {\n            \"Id\": np.array([c.id for c in self.colloids]),\n            \"Type\": np.array([c.type for c in self.colloids]),\n            \"Unwrapped_Positions\": np.stack([c.pos for c in self.colloids]),\n            \"Velocities\": np.stack([c.v for c in self.colloids]),\n            \"Directors\": np.stack([c.director for c in self.colloids]),\n        }\n\n    def get_unit_system(self):\n        \"\"\"\n        Collect the pin unit registry.\n\n        Returns\n        -------\n        unit_registry: object\n                The class unit registry.\n        \"\"\"\n        return self.ureg\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.__init__","title":"<code>__init__(md_params, n_dims=3, seed=42, out_folder='.', write_chunk_size=100, system=None)</code>","text":"<p>Constructor for the espressoMD engine.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.__init__--parameters","title":"Parameters","text":"<p>md_params : espresso.MDParams         Parameter class for the espresso simulation. n_dims : int (default = 3)         Number of dimensions to consider in the simulation seed : int         Seed number for any generators. out_folder : str or pathlib.Path         Path to an output folder to store data in. This file should have a         reasonable amount of free space. write_chunk_size : int         Chunk size to use in the hdf5 writing. system : espressomd.System (optional)         Espresso system to use in this engine.         If not provided, a new system will be created.         Note: We try to clear the passed system of any previous contents,         but do not guarantee that everything is reset completely. Use at         own risk.</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def __init__(\n    self,\n    md_params,\n    n_dims=3,\n    seed=42,\n    out_folder=\".\",\n    write_chunk_size=100,\n    system=None,\n):\n    \"\"\"\n    Constructor for the espressoMD engine.\n\n    Parameters\n    ----------\n    md_params : espresso.MDParams\n            Parameter class for the espresso simulation.\n    n_dims : int (default = 3)\n            Number of dimensions to consider in the simulation\n    seed : int\n            Seed number for any generators.\n    out_folder : str or pathlib.Path\n            Path to an output folder to store data in. This file should have a\n            reasonable amount of free space.\n    write_chunk_size : int\n            Chunk size to use in the hdf5 writing.\n    system : espressomd.System (optional)\n            Espresso system to use in this engine.\n            If not provided, a new system will be created.\n            Note: We try to clear the passed system of any previous contents,\n            but do not guarantee that everything is reset completely. Use at\n            own risk.\n    \"\"\"\n    self.params: MDParams = md_params\n    self.out_folder = pathlib.Path(out_folder).resolve()\n    self.seed = seed\n    self.rng = np.random.default_rng(self.seed)\n    if n_dims not in [2, 3]:\n        raise ValueError(\"Only 2d and 3d are allowed\")\n    self.n_dims = n_dims\n\n    self._init_unit_system()\n    self.write_chunk_size = write_chunk_size\n\n    if system is None:\n        self.system = espressomd.System(box_l=3 * [1.0])\n    else:\n        self.system = _reset_system(system)\n    self._init_system()\n\n    self.colloids = list()\n    self.lbf: espressomd.lb.LBFluidWalberla = None\n\n    # register to lookup which type has which radius\n    self.colloid_radius_register = {}\n\n    # after the first call to integrate, no more changes to the engine are allowed\n    self.integration_initialised = False\n\n    espressomd.assert_features(\n        [\"ROTATION\", \"EXTERNAL_FORCES\", \"THERMOSTAT_PER_PARTICLE\"]\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_colloid_on_point","title":"<code>add_colloid_on_point(radius_colloid=None, init_position=None, init_direction=np.array([1, 0, 0]), type_colloid=0, gamma_translation=None, gamma_rotation=None, aspect_ratio=1.0, mass=None, rinertia=None)</code>","text":""},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_colloid_on_point--parameters","title":"Parameters","text":"<p>radius_colloid     default: 1 micrometer init_position     default: center of the box init_direction     default: along x type_colloid     The colloids created from this method call will have this type.     Multiple calls can be made with the same type_colloid.     Interaction models need to be made aware if there are different types     of colloids in the system if specific behaviour is desired. gamma_translation, gamma_rotation: pint.Quantity[np.array], optional     If None, calculate these quantities from the radius and the fluid viscosity.     You can provide friction coefficients as scalars or a 3-vector     (the diagonal elements of the friction tensor). aspect_ratio: float, optional     If you provide a value != 1, a gay-berne interaction will be set up     instead of purely repulsive lennard jones.     aspect_ratio &gt; 1 will produce a cigar, aspect_ratio &lt; 0 a disk     (both swimming in the direction of symmetry). mass: optional     Particle mass. Only relevant for Langevin integrator. rinertia: optional     Diagonal elements of the rotational moment of inertia tensor     of the particle, assuming the particle is oriented along z.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_colloid_on_point--returns","title":"Returns","text":"<p>colloid.</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def add_colloid_on_point(\n    self,\n    radius_colloid: pint.Quantity = None,\n    init_position: pint.Quantity = None,\n    init_direction: np.array = np.array([1, 0, 0]),\n    type_colloid=0,\n    gamma_translation: pint.Quantity = None,\n    gamma_rotation: pint.Quantity = None,\n    aspect_ratio: float = 1.0,\n    mass: pint.Quantity = None,\n    rinertia: pint.Quantity = None,\n):\n    \"\"\"\n    Parameters\n    ----------\n    radius_colloid\n        default: 1 micrometer\n    init_position\n        default: center of the box\n    init_direction\n        default: along x\n    type_colloid\n        The colloids created from this method call will have this type.\n        Multiple calls can be made with the same type_colloid.\n        Interaction models need to be made aware if there are different types\n        of colloids in the system if specific behaviour is desired.\n    gamma_translation, gamma_rotation: pint.Quantity[np.array], optional\n        If None, calculate these quantities from the radius and the fluid viscosity.\n        You can provide friction coefficients as scalars or a 3-vector\n        (the diagonal elements of the friction tensor).\n    aspect_ratio: float, optional\n        If you provide a value != 1, a gay-berne interaction will be set up\n        instead of purely repulsive lennard jones.\n        aspect_ratio &gt; 1 will produce a cigar, aspect_ratio &lt; 0 a disk\n        (both swimming in the direction of symmetry).\n    mass: optional\n        Particle mass. Only relevant for Langevin integrator.\n    rinertia: optional\n        Diagonal elements of the rotational moment of inertia tensor\n        of the particle, assuming the particle is oriented along z.\n\n    Returns\n    -------\n    colloid.\n\n    \"\"\"\n\n    self._check_already_initialised()\n\n    if radius_colloid is None:\n        radius_colloid = self.ureg.Quantity(1, \"micrometer\")\n    if init_position is None:\n        init_position = 0.5 * self.params.box_length\n\n    if type_colloid in self.colloid_radius_register.keys():\n        if self.colloid_radius_register[type_colloid][\n            \"radius\"\n        ] != radius_colloid.m_as(\"sim_length\"):\n            raise ValueError(\n                f\"The chosen type {type_colloid} is already taken and used with a\"\n                \" different radius\"\n                f\" {self.colloid_radius_register[type_colloid]['radius']}. Choose a\"\n                \" new combination\"\n            )\n\n    radius_simunits = radius_colloid.m_as(\"sim_length\")\n    init_pos = init_position.m_as(\"sim_length\")\n    init_direction = init_direction / np.linalg.norm(init_direction)\n\n    (\n        gamma_translation_sphere,\n        gamma_rotation_sphere,\n    ) = _calc_friction_coefficients(\n        self.params.fluid_dyn_viscosity.m_as(\"sim_dyn_viscosity\"), radius_simunits\n    )\n    if gamma_translation is None:\n        gamma_translation = gamma_translation_sphere\n    else:\n        gamma_translation = gamma_translation.m_as(\"sim_force/sim_velocity\")\n    if gamma_rotation is None:\n        gamma_rotation = gamma_rotation_sphere\n    else:\n        gamma_rotation = gamma_rotation.m_as(\"sim_torque/sim_angular_velocity\")\n\n    if self.params.thermostat_type == \"langevin\":\n        if mass is None:\n            raise ValueError(\n                \"If you use the Langevin thermostat, you must set a particle mass\"\n            )\n        if rinertia is None:\n            raise ValueError(\n                \"If you use the Langevin thermostat, you must set a particle\"\n                \" rotational inertia\"\n            )\n    else:\n        # mass and moment of inertia can still be relevant when calculating\n        # the stochastic part of the particle velocity, see\n        # https://espressomd.github.io/doc/integration.html#brownian-thermostat.\n        # Provide defaults in case the user didn't set the values.\n        water_dens = self.params.ureg.Quantity(1000, \"kg/meter**3\")\n        if mass is None:\n            mass = water_dens * 4.0 / 3.0 * np.pi * radius_colloid**3\n        if rinertia is None:\n            rinertia = 2.0 / 5.0 * mass * radius_colloid**2\n            rinertia = utils.convert_array_of_pint_to_pint_of_array(\n                3 * [rinertia], self.params.ureg\n            )\n\n    if self.n_dims == 3:\n        colloid = self.system.part.add(\n            pos=init_pos,\n            director=init_direction,\n            rotation=3 * [True],\n            gamma=gamma_translation,\n            gamma_rot=gamma_rotation,\n            fix=3 * [False],\n            type=type_colloid,\n            mass=mass.m_as(\"sim_mass\"),\n            rinertia=rinertia.m_as(\"sim_rinertia\"),\n        )\n    else:\n        # initialize with body-frame = lab-frame to set correct rotation flags\n        # allow all rotations to bring the particle to correct state\n        init_pos[2] = 0  # get rid of z-coordinate in 2D coordinates\n        colloid = self.system.part.add(\n            pos=init_pos,\n            fix=[False, False, True],\n            rotation=3 * [True],\n            gamma=gamma_translation,\n            gamma_rot=gamma_rotation,\n            quat=[1, 0, 0, 0],\n            type=type_colloid,\n            mass=mass.m_as(\"sim_mass\"),\n            rinertia=rinertia.m_as(\"sim_rinertia\"),\n        )\n        theta, phi = utils.angles_from_vector(init_direction)\n        if abs(theta - np.pi / 2) &gt; 10e-6:\n            raise ValueError(\n                \"It seems like you want to have a 2D simulation\"\n                \" with colloids that point some amount in Z-direction.\"\n                \" Change something in your colloid setup.\"\n            )\n        self._rotate_colloid_to_2d(colloid, phi)\n\n    self.colloids.append(colloid)\n\n    self.colloid_radius_register.update(\n        {type_colloid: {\"radius\": radius_simunits, \"aspect_ratio\": aspect_ratio}}\n    )\n\n    return colloid\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_colloids","title":"<code>add_colloids(n_colloids, radius_colloid=None, random_placement_center=None, random_placement_radius=None, type_colloid=0, gamma_translation=None, gamma_rotation=None, aspect_ratio=1.0, mass=None, rinertia=None)</code>","text":""},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_colloids--parameters","title":"Parameters","text":"<p>n_colloids radius_colloid     default: 1 micrometer random_placement_center     default: center of the box random_placement_radius     default: half the box dimension type_colloid     The colloids created from this method call will have this type.     Multiple calls can be made with the same type_colloid.     Interaction models need to be made aware if there are different types     of colloids in the system if specific behaviour is desired. gamma_translation, gamma_rotation: optional     If None, calculate these quantities from the radius and the fluid viscosity.     You can provide friction coefficients as scalars or a 3-vector     (the diagonal elements of the friction tensor) aspect_ratio     If you provide a value != 1, a gay-berne interaction will be set up     instead of purely repulsive lennard jones.     aspect_ratio &gt; 1 will produce a cigar, aspect_ratio &lt; 0 a disk     (both swimming in the direction of symmetry).     The radius_colloid gives the radius perpendicular to the symmetry axis. mass: optional     Particle mass. Only relevant for Langevin integrator. rinertia: optional     Diagonal elements of the rotational moment of inertia tensor     of the particle, assuming the particle is oriented along z.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_colloids--returns","title":"Returns","text":"Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def add_colloids(\n    self,\n    n_colloids: int,\n    radius_colloid: pint.Quantity = None,\n    random_placement_center: pint.Quantity = None,\n    random_placement_radius: pint.Quantity = None,\n    type_colloid: int = 0,\n    gamma_translation: pint.Quantity = None,\n    gamma_rotation: pint.Quantity = None,\n    aspect_ratio: float = 1.0,\n    mass: pint.Quantity = None,\n    rinertia: pint.Quantity = None,\n):\n    \"\"\"\n    Parameters\n    ----------\n    n_colloids\n    radius_colloid\n        default: 1 micrometer\n    random_placement_center\n        default: center of the box\n    random_placement_radius\n        default: half the box dimension\n    type_colloid\n        The colloids created from this method call will have this type.\n        Multiple calls can be made with the same type_colloid.\n        Interaction models need to be made aware if there are different types\n        of colloids in the system if specific behaviour is desired.\n    gamma_translation, gamma_rotation: optional\n        If None, calculate these quantities from the radius and the fluid viscosity.\n        You can provide friction coefficients as scalars or a 3-vector\n        (the diagonal elements of the friction tensor)\n    aspect_ratio\n        If you provide a value != 1, a gay-berne interaction will be set up\n        instead of purely repulsive lennard jones.\n        aspect_ratio &gt; 1 will produce a cigar, aspect_ratio &lt; 0 a disk\n        (both swimming in the direction of symmetry).\n        The radius_colloid gives the radius perpendicular to the symmetry axis.\n    mass: optional\n        Particle mass. Only relevant for Langevin integrator.\n    rinertia: optional\n        Diagonal elements of the rotational moment of inertia tensor\n        of the particle, assuming the particle is oriented along z.\n\n\n    Returns\n    -------\n\n    \"\"\"\n\n    self._check_already_initialised()\n\n    if random_placement_center is None:\n        random_placement_center = self.ureg.Quantity(\n            0.5 * self.params.box_length.m_as(\"sim_length\"), \"sim_length\"\n        )\n    if random_placement_radius is None:\n        random_placement_radius = 0.5 * min(self.params.box_length)\n\n    init_center = random_placement_center.m_as(\"sim_length\")\n    init_rad = random_placement_radius.m_as(\"sim_length\")\n\n    for i in range(n_colloids):\n        start_pos = (\n            _get_random_start_pos(init_rad, init_center, self.n_dims, self.rng)\n            * self.ureg.sim_length\n        )\n\n        if self.n_dims == 3:\n            init_direction = utils.vector_from_angles(\n                *utils.get_random_angles(self.rng)\n            )\n        else:\n            start_angle = 2 * np.pi * self.rng.random()\n            init_direction = utils.vector_from_angles(np.pi / 2, start_angle)\n        self.add_colloid_on_point(\n            radius_colloid=radius_colloid,\n            init_position=start_pos,\n            init_direction=init_direction,\n            type_colloid=type_colloid,\n            gamma_translation=gamma_translation,\n            gamma_rotation=gamma_rotation,\n            aspect_ratio=aspect_ratio,\n            mass=mass,\n            rinertia=rinertia,\n        )\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_confining_walls","title":"<code>add_confining_walls(wall_type)</code>","text":"<p>Walls on the edges of the box, will interact with particles through WCA. Is NOT communicated to the interaction models, though.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_confining_walls--parameters","title":"Parameters","text":"<p>wall_type : int     Wall interacts with particles, so it needs its own type.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_confining_walls--returns","title":"Returns","text":"Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def add_confining_walls(self, wall_type: int):\n    \"\"\"\n    Walls on the edges of the box, will interact with particles through WCA.\n    Is NOT communicated to the interaction models, though.\n\n    Parameters\n    ----------\n    wall_type : int\n        Wall interacts with particles, so it needs its own type.\n\n    Returns\n    -------\n    \"\"\"\n    self._check_already_initialised()\n    if wall_type in self.colloid_radius_register.keys():\n        raise ValueError(\n            f\"wall type {wall_type} is already taken \"\n            \"by other system component. Choose a new one\"\n        )\n\n    wall_shapes = []\n    wall_shapes.append(espressomd.shapes.Wall(dist=0, normal=[1, 0, 0]))\n    wall_shapes.append(\n        espressomd.shapes.Wall(dist=-self.system.box_l[0], normal=[-1, 0, 0])\n    )\n    wall_shapes.append(espressomd.shapes.Wall(dist=0, normal=[0, 1, 0]))\n    wall_shapes.append(\n        espressomd.shapes.Wall(dist=-self.system.box_l[1], normal=[0, -1, 0])\n    )\n    if self.n_dims == 3:\n        wall_shapes.append(espressomd.shapes.Wall(dist=0, normal=[0, 0, 1]))\n        wall_shapes.append(\n            espressomd.shapes.Wall(dist=-self.system.box_l[2], normal=[0, 0, -1])\n        )\n\n    for wall_shape in wall_shapes:\n        constr = espressomd.constraints.ShapeBasedConstraint(\n            shape=wall_shape, particle_type=wall_type, penetrable=False\n        )\n        self.system.constraints.add(constr)\n\n    # the wall itself has no radius, only the particle radius counts\n    self.colloid_radius_register.update(\n        {wall_type: {\"radius\": 0.0, \"aspect_ratio\": 1.0}}\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_const_force_to_colloids","title":"<code>add_const_force_to_colloids(force, type)</code>","text":""},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_const_force_to_colloids--parameters","title":"Parameters","text":"<p>force: pint.Quantity     A Quantity of numpy array, e.g. f = Quantity(np.array([1,2,3]), \"newton\") type: int     The type of colloid that gets the force.     Needs to be already added to the engine</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def add_const_force_to_colloids(self, force: pint.Quantity, type: int):\n    \"\"\"\n    Parameters\n    ----------\n    force: pint.Quantity\n        A Quantity of numpy array, e.g. f = Quantity(np.array([1,2,3]), \"newton\")\n    type: int\n        The type of colloid that gets the force.\n        Needs to be already added to the engine\n    \"\"\"\n    force_simunits = force.m_as(\"sim_force\")\n    parts = self.system.part.select(type=type)\n    if len(parts) == 0:\n        raise ValueError(\n            f\"Particles of type {type} not added to engine. \"\n            f\"You currently have {self.colloid_radius_register.keys()}\"\n        )\n    parts.ext_force = force_simunits\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_external_potential","title":"<code>add_external_potential(potential, grid_spacings)</code>","text":""},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_external_potential--parameters","title":"Parameters","text":"<p>potential: pint.Quantity[np.array]     The flowfield to add, given as a pint Quantity of a numpy array     with units of energy.     Must have shape (n_cells_x, n_cells_y, n_cells_z)     The potential values must be centered in the corresponding grid,     e.g. the [idx_x,idx_y,idx_z, :] value of the array contains the potential at     np.dot([idx_x+0.5, idx_y+0.5, idx_z+0.5], [agrid_x, agrid_y, agrid_z]).     From these points, the potential is interpolated to the particle positions. grid_spacings: pint.Quantity[np.array]     This grid spacing will be used to fit the potential into the simulation box.     If you run a 2d-simulation, choose grid_spacings[2]=box_l.</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def add_external_potential(\n    self, potential: pint.Quantity, grid_spacings: pint.Quantity\n):\n    \"\"\"\n    Parameters\n    ----------\n    potential: pint.Quantity[np.array]\n        The flowfield to add, given as a pint Quantity of a numpy array\n        with units of energy.\n        Must have shape (n_cells_x, n_cells_y, n_cells_z)\n        The potential values must be centered in the corresponding grid,\n        e.g. the [idx_x,idx_y,idx_z, :] value of the array contains the potential at\n        np.dot([idx_x+0.5, idx_y+0.5, idx_z+0.5], [agrid_x, agrid_y, agrid_z]).\n        From these points, the potential is interpolated to the particle positions.\n    grid_spacings: pint.Quantity[np.array]\n        This grid spacing will be used to fit the potential into the simulation box.\n        If you run a 2d-simulation, choose grid_spacings[2]=box_l.\n    \"\"\"\n\n    pot = potential.m_as(\"sim_energy\")\n    agrids = grid_spacings.m_as(\"sim_length\")\n\n    if not pot.ndim == 3:\n        raise ValueError(\n            \"potential must have shape (n_cells_x, n_cells_y, n_cells_z)\"\n        )\n    if not len(grid_spacings) == 3:\n        raise ValueError(\"Grid spacings must have length of 3\")\n\n    # Espresso constraint field must be one cell larger in all directions\n    # for interpolation. Apply periodic boundary conditions.\n    pot_padded = np.pad(\n        pot,\n        pad_width=1,\n        mode=\"wrap\",\n    )\n    pot_constraint = espressomd.constraints.PotentialField(\n        field=pot_padded[:, :, :, np.newaxis],\n        grid_spacing=agrids,\n        default_scale=1.0,\n    )\n    self.system.constraints.add(pot_constraint)\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_flowfield","title":"<code>add_flowfield(flowfield, friction_coeff, grid_spacings)</code>","text":""},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_flowfield--parameters","title":"Parameters","text":"<p>flowfield: pint.Quantity[np.array]     The flowfield to add, given as a pint Quantity of a numpy array     with units of velocity.     Must have shape (n_cells_x, n_cells_y, n_cells_z, 3)     The velocity values must be centered in the corresponding grid,     e.g. the [idx_x,idx_y,idx_z, :] value of the array contains the velocity at     np.dot([idx_x+0.5,idx_y+0.5,idx_z+0.5],[agrid_x,agrid_y,agrid_z]).     From these points, the velocity is interpolated to the particle positions. friction_coeff: pint.Quantity[float]     The friction coefficient in units of mass/time.     Espresso does not yet support particle-specific or anisotropic     friction coefficients for flow coupling, so one scalar value has to be     provided here which will be used for all particles. grid_spacings: pint.Quantity[np.array]     This grid spacing will be used to fit the flowfield into the simulation box.     If you run a 2d-simulation, choose grid_spacings[2]=box_l.</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def add_flowfield(\n    self,\n    flowfield: pint.Quantity,\n    friction_coeff: pint.Quantity,\n    grid_spacings: pint.Quantity,\n):\n    \"\"\"\n    Parameters\n    ----------\n    flowfield: pint.Quantity[np.array]\n        The flowfield to add, given as a pint Quantity of a numpy array\n        with units of velocity.\n        Must have shape (n_cells_x, n_cells_y, n_cells_z, 3)\n        The velocity values must be centered in the corresponding grid,\n        e.g. the [idx_x,idx_y,idx_z, :] value of the array contains the velocity at\n        np.dot([idx_x+0.5,idx_y+0.5,idx_z+0.5],[agrid_x,agrid_y,agrid_z]).\n        From these points, the velocity is interpolated to the particle positions.\n    friction_coeff: pint.Quantity[float]\n        The friction coefficient in units of mass/time.\n        Espresso does not yet support particle-specific or anisotropic\n        friction coefficients for flow coupling, so one scalar value has to be\n        provided here which will be used for all particles.\n    grid_spacings: pint.Quantity[np.array]\n        This grid spacing will be used to fit the flowfield into the simulation box.\n        If you run a 2d-simulation, choose grid_spacings[2]=box_l.\n    \"\"\"\n\n    if not self.params.thermostat_type == \"langevin\":\n        raise RuntimeError(\n            \"Coupling to a flowfield does not work with a Brownian thermostat. Use\"\n            \" 'langevin'.\"\n        )\n\n    flow = flowfield.m_as(\"sim_velocity\")\n    gamma = friction_coeff.m_as(\"sim_mass/sim_time\")\n    agrids = grid_spacings.m_as(\"sim_length\")\n\n    if not flow.ndim == 4:\n        raise ValueError(\n            \"flowfield must have shape (n_cells_x, n_cells_y, n_cells_z, 3)\"\n        )\n    if not len(grid_spacings) == 3:\n        raise ValueError(\"Grid spacings must have length of 3\")\n\n    # espresso constraint field must be one grid larger in all directions\n    # for interpolation. Apply periodic boundary conditions\n    flow_padded = np.stack(\n        [np.pad(flow[:, :, :, i], mode=\"wrap\", pad_width=1) for i in range(3)],\n        axis=3,\n    )\n    flow_constraint = espressomd.constraints.FlowField(\n        field=flow_padded, gamma=gamma, grid_spacing=agrids\n    )\n    self.system.constraints.add(flow_constraint)\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_lattice_boltzmann","title":"<code>add_lattice_boltzmann(agrid=None, lb_time_step=None, dynamic_viscosity=None, fluid_density=None, boundary_mask=None, ext_force_density=None, use_GPU=False)</code>","text":"<p>Add a lattice boltzmann fluid to the simulation.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_lattice_boltzmann--parameters","title":"Parameters:","text":"pint.Quantity, scalar <p>The uniform grid spacing in all 3 dimensions. Must be compatible with params.box_length.</p> <p>lb_time_step: pint.Quantity, scalar, optional     Lb time step, must be integer multiple of params.time_step.     Default: params.time_step dynamic_viscosity: pint.Quantity, scalar, optional     default: self.params.fluid_dyn_viscosity     only change if you know what you are doing fluid_density: pint.Quantity, scalar, optional     default: 1000kg/m3 boundary_mask: np.array, optional:     A 3D boolean array that defines the no-slip boundary cells of the fluid.     Must be compatible with the grid that gets generated     from params.box_length and agrid. ext_force_density: pint.Quantity, 3d vector, optional.     default: [0,0,0] N/m3</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def add_lattice_boltzmann(\n    self,\n    agrid: pint.Quantity = None,\n    lb_time_step: pint.Quantity = None,\n    dynamic_viscosity: pint.Quantity = None,\n    fluid_density: pint.Quantity = None,\n    boundary_mask: np.array = None,\n    ext_force_density: pint.Quantity = None,\n    use_GPU: bool = False,\n):\n    \"\"\"\n    Add a lattice boltzmann fluid to the simulation.\n\n    Parameters:\n    -----------\n\n    agrid: pint.Quantity, scalar\n        The uniform grid spacing in all 3 dimensions.\n        Must be compatible with params.box_length.\n    lb_time_step: pint.Quantity, scalar, optional\n        Lb time step, must be integer multiple of params.time_step.\n        Default: params.time_step\n    dynamic_viscosity: pint.Quantity, scalar, optional\n        default: self.params.fluid_dyn_viscosity\n        only change if you know what you are doing\n    fluid_density: pint.Quantity, scalar, optional\n        default: 1000kg/m**3\n    boundary_mask: np.array, optional:\n        A 3D boolean array that defines the no-slip boundary cells of the fluid.\n        Must be compatible with the grid that gets generated\n        from params.box_length and agrid.\n    ext_force_density: pint.Quantity, 3d vector, optional.\n        default: [0,0,0] N/m**3\n    \"\"\"\n    if not self.params.thermostat_type == \"langevin\":\n        raise RuntimeError(\n            \"Coupling to lattice boltzmann does not work with a Brownian\"\n            \" thermostat. Use 'langevin'.\"\n        )\n\n    if agrid is None:\n        raise ValueError(\"agrid must be provided\")\n    if lb_time_step is None:\n        lb_time_step = self.params.time_step\n    if dynamic_viscosity is None:\n        dynamic_viscosity = self.params.fluid_dyn_viscosity\n    if fluid_density is None:\n        fluid_density = self.ureg.Quantity(1000, \"kg/m**3\")\n    if ext_force_density is None:\n        ext_force_density = self.ureg.Quantity(np.zeros(3), \"N/m**3\")\n    if use_GPU:\n        raise NotImplementedError(\n            \"GPU support is not yet implemented. Stay tuned tho\"\n        )\n\n    lbf = espressomd.lb.LBFluidWalberla(\n        tau=lb_time_step.m_as(\"sim_time\"),\n        kT=(self.params.temperature * self.ureg.boltzmann_constant).m_as(\n            \"sim_energy\"\n        ),\n        density=fluid_density.m_as(\"sim_mass/sim_length**3\"),\n        kinematic_viscosity=(dynamic_viscosity / fluid_density).m_as(\n            \"sim_kin_viscosity\"\n        ),\n        agrid=agrid.m_as(\"sim_length\"),\n        seed=self.seed,\n        ext_force_density=ext_force_density.m_as(\"sim_force/sim_length**3\"),\n    )\n\n    if boundary_mask is not None:\n        from espressomd.script_interface import array_variant\n\n        if not np.all(lbf.shape == boundary_mask.shape):\n            raise ValueError(\n                \"boundary_mask must have the same shape as the fluid grid\"\n            )\n\n        lbf.call_method(\n            \"add_boundary_from_shape\",\n            raster=array_variant(boundary_mask.astype(int).flatten()),\n            values=array_variant(np.zeros(3, dtype=float).flatten()),\n        )\n\n    self.lbf = lbf\n\n    return lbf\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_rod","title":"<code>add_rod(rod_center=None, rod_length=None, rod_thickness=None, rod_start_angle=None, n_particles=None, friction_trans=None, friction_rot=None, rod_particle_type=None, fixed=True)</code>","text":"<p>Add a rod to the system. A rod consists of n_particles point particles that are rigidly connected and rotate/move as a whole Parameters</p> <p>rod_center     default: center of the box rod_length     default: 100 micrometer rod_thickness     default: 5 micrometer     Make sure there are enough particles.     If the thickness is too thin, the rod might get holes rod_start_angle     default: 0 n_particles     default: 101     Must be uneven number such that there always is a central particle friction_trans     Irrelevant if fixed==True     must be provided friction_rot     must be provided rod_particle_type     The rod is made out of points so they get their own type. fixed     Fixes the central particle of the rod.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_rod--returns","title":"Returns","text":"<p>The espresso handle to the central particle. For debugging purposes only</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def add_rod(\n    self,\n    rod_center: pint.Quantity = None,\n    rod_length: pint.Quantity = None,\n    rod_thickness: pint.Quantity = None,\n    rod_start_angle: float = None,\n    n_particles: int = None,\n    friction_trans: pint.Quantity = None,\n    friction_rot: pint.Quantity = None,\n    rod_particle_type: int = None,\n    fixed: bool = True,\n):\n    \"\"\"\n    Add a rod to the system.\n    A rod consists of n_particles point particles that are rigidly connected\n    and rotate/move as a whole\n    Parameters\n    ----------\n    rod_center\n        default: center of the box\n    rod_length\n        default: 100 micrometer\n    rod_thickness\n        default: 5 micrometer\n        Make sure there are enough particles.\n        If the thickness is too thin, the rod might get holes\n    rod_start_angle\n        default: 0\n    n_particles\n        default: 101\n        Must be uneven number such that there always is a central particle\n    friction_trans\n        Irrelevant if fixed==True\n        must be provided\n    friction_rot\n        must be provided\n    rod_particle_type\n        The rod is made out of points so they get their own type.\n    fixed\n        Fixes the central particle of the rod.\n\n    Returns\n    -------\n    The espresso handle to the central particle. For debugging purposes only\n    \"\"\"\n    self._check_already_initialised()\n\n    if rod_center is None:\n        rod_center = self.params.box_length / 2.0\n    if rod_length is None:\n        rod_length = self.ureg.Quantity(100, \"micrometer\")\n    if rod_thickness is None:\n        rod_thickness = self.ureg.Quantity(5, \"micrometer\")\n    if rod_start_angle is None:\n        rod_start_angle = 0\n    if n_particles is None:\n        n_particles = 101\n    if friction_trans is None and not fixed:\n        raise ValueError(\n            \"If you want the rod to move, you must provide a friction coefficient\"\n        )\n    if friction_rot is None:\n        raise ValueError(\"You must provide a rotational friction coefficient\")\n    if rod_particle_type is None:\n        raise ValueError(\"You must provide a particle type for the rod\")\n\n    if self.n_dims != 2:\n        raise ValueError(\"Rod can only be added in 2d\")\n    if rod_center[2].magnitude != 0:\n        raise ValueError(f\"Rod center z-component must be 0. You gave {rod_center}\")\n    if n_particles % 2 != 1:\n        raise ValueError(f\"n_particles must be uneven. You gave {n_particles}\")\n\n    espressomd.assert_features([\"VIRTUAL_SITES_RELATIVE\"])\n    import espressomd.virtual_sites as evs\n\n    self.system.virtual_sites = evs.VirtualSitesRelative(have_quaternion=True)\n\n    center_pos = rod_center.m_as(\"sim_length\")\n    fric_trans = friction_trans.m_as(\"sim_force/sim_velocity\")  # [F / v]\n    fric_rot = friction_rot.m_as(\n        \"sim_force * sim_length *  sim_time\"\n    )  # [M / omega]\n    partcl_radius = rod_thickness.m_as(\"sim_length\") / 2\n\n    # place the real particle\n    center_part = self.system.part.add(\n        pos=center_pos,\n        quat=[1, 0, 0, 0],\n        rotation=3 * [True],\n        fix=[fixed, fixed, True],\n        gamma=fric_trans,\n        gamma_rot=fric_rot,\n        type=rod_particle_type,\n    )\n    self._rotate_colloid_to_2d(center_part, rod_start_angle)\n    self.colloids.append(center_part)\n\n    # place virtual\n    point_span = rod_length.m_as(\"sim_length\") - 2 * partcl_radius\n    point_dist = point_span / (n_particles - 1)\n    if point_dist &gt; 2 * partcl_radius:\n        logger.warning(\n            \"your rod has holes. \"\n            f\"Particle radius {partcl_radius} \"\n            f\"particle_distance {point_dist} \"\n            \"(both in simulation units)\"\n        )\n\n    director = utils.vector_from_angles(np.pi / 2, rod_start_angle)\n\n    for k in range(n_particles - 1):\n        dist_to_center = (-1) ** k * (k // 2 + 1) * point_dist\n        pos_virt = center_pos + dist_to_center * director\n        virtual_partcl = self.system.part.add(\n            pos=pos_virt, director=director, virtual=True, type=rod_particle_type\n        )\n        virtual_partcl.vs_auto_relate_to(center_part)\n        self.colloids.append(virtual_partcl)\n\n    self.colloid_radius_register.update(\n        {rod_particle_type: {\"radius\": partcl_radius, \"aspect_ratio\": 1.0}}\n    )\n    return center_part\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_walls","title":"<code>add_walls(wall_start_point, wall_end_point, wall_type, wall_thickness)</code>","text":"<p>User defined walls will interact with particles through WCA. Is NOT communicated to the interaction models, though. The walls have a large height resulting in 2D-walls in a 2D-simulation. The actual height adapts to the chosen box size. The shape of the underlying constraint is a square.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_walls--parameters","title":"Parameters","text":"<p>wall_start_point : pint.Quantity np.array (n,2) with wall coordinates      [x_begin, y_begin] wall_end_point : pint.Quantity np.array (n,2) with wall coordinates      [x_end, y_end] wall_type : int     Wall interacts with particles, so it needs its own type. wall_thickness: pint.Quantity     wall thickness</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.add_walls--returns","title":"Returns","text":"Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def add_walls(\n    self,\n    wall_start_point: pint.Quantity,\n    wall_end_point: pint.Quantity,\n    wall_type: int,\n    wall_thickness: pint.Quantity,\n):\n    \"\"\"\n    User defined walls will interact with particles through WCA.\n    Is NOT communicated to the interaction models, though.\n    The walls have a large height resulting in 2D-walls in a 2D-simulation.\n    The actual height adapts to the chosen box size.\n    The shape of the underlying constraint is a square.\n\n    Parameters\n    ----------\n    wall_start_point : pint.Quantity\n    np.array (n,2) with wall coordinates\n         [x_begin, y_begin]\n    wall_end_point : pint.Quantity\n    np.array (n,2) with wall coordinates\n         [x_end, y_end]\n    wall_type : int\n        Wall interacts with particles, so it needs its own type.\n    wall_thickness: pint.Quantity\n        wall thickness\n\n    Returns\n    -------\n    \"\"\"\n\n    wall_start_point = wall_start_point.m_as(\"sim_length\")\n    wall_end_point = wall_end_point.m_as(\"sim_length\")\n    wall_thickness = wall_thickness.m_as(\"sim_length\")\n\n    if len(wall_start_point) != len(wall_end_point):\n        raise ValueError(\n            \" Please double check your walls. There are more or less \"\n            f\" starting points {len(wall_start_point)} than \"\n            f\" end points {len(wall_end_point)}. They should be equal.\"\n        )\n\n    self._check_already_initialised()\n    if wall_type in self.colloid_radius_register.keys():\n        if self.colloid_radius_register[wall_type] != 0.0:\n            raise ValueError(\n                f\" The chosen type {wall_type} is already taken\"\n                \"and used with a different radius \"\n                f\"{self.colloid_radius_register[wall_type]['radius']}.\"\n                \" Choose a new combination\"\n            )\n\n    z_height = self.system.box_l[2]\n    wall_shapes = []\n\n    for wall_index in range(len(wall_start_point)):\n        a = [\n            wall_end_point[wall_index, 0] - wall_start_point[wall_index, 0],\n            wall_end_point[wall_index, 1] - wall_start_point[wall_index, 1],\n            0,\n        ]  # direction along lengthy wall\n        c = [0, 0, z_height]  # direction along third axis of 2D simulation\n        norm_a = np.linalg.norm(a)  # is also the norm of b\n        norm_c = np.linalg.norm(c)\n        b = (\n            np.cross(a / norm_a, c / norm_c) * wall_thickness\n        )  # direction along second axis\n        # i.e along wall_thickness of lengthy wall\n        corner = [\n            wall_start_point[wall_index, 0] - b[0] / 2,\n            wall_start_point[wall_index, 1] - b[1] / 2,\n            0,\n        ]  # anchor point of wall shifted by wall_thickness*1/2\n\n        wall_shapes.append(\n            espressomd.shapes.Rhomboid(corner=corner, a=a, b=b, c=c, direction=1)\n        )\n\n    for wall_shape in wall_shapes:\n        constr = espressomd.constraints.ShapeBasedConstraint(\n            shape=wall_shape, particle_type=wall_type, penetrable=False\n        )\n        self.system.constraints.add(constr)\n\n    # the wall itself has no radius, only the particle radius counts\n    self.colloid_radius_register.update(\n        {wall_type: {\"radius\": 0.0, \"aspect_ratio\": 1.0}}\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.finalize","title":"<code>finalize()</code>","text":"<p>Method to clean up after finishing the simulation</p> <p>Method will write the last chunks of trajectory</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def finalize(self):\n    \"\"\"\n    Method to clean up after finishing the simulation\n\n    Method will write the last chunks of trajectory\n    \"\"\"\n    self._write_traj_chunk_to_file()\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.get_friction_coefficients","title":"<code>get_friction_coefficients(type)</code>","text":"<p>Returns both the translational and the rotational friction coefficient of the desired type in simulation units</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def get_friction_coefficients(self, type: int):\n    \"\"\"\n    Returns both the translational and the rotational friction coefficient\n    of the desired type in simulation units\n    \"\"\"\n    property_dict = self.colloid_radius_register.get(type, None)\n    if property_dict is None:\n        raise ValueError(\n            f\"cannot get friction coefficient for type {type}. Did you actually add\"\n            \" that particle type?\"\n        )\n    return _calc_friction_coefficients(\n        self.params.fluid_dyn_viscosity.m_as(\"sim_dyn_viscosity\"),\n        property_dict[\"radius\"],\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.get_particle_data","title":"<code>get_particle_data()</code>","text":"<p>Collect specific particle information from the colloids.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.get_particle_data--returns","title":"Returns","text":"<p>information : dict         A dict of information for all of the colloids in the system including         unwrapped positions, velocities, and the directors of the colloids.</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def get_particle_data(self):\n    \"\"\"\n    Collect specific particle information from the colloids.\n\n    Returns\n    -------\n    information : dict\n            A dict of information for all of the colloids in the system including\n            unwrapped positions, velocities, and the directors of the colloids.\n    \"\"\"\n    return {\n        \"Id\": np.array([c.id for c in self.colloids]),\n        \"Type\": np.array([c.type for c in self.colloids]),\n        \"Unwrapped_Positions\": np.stack([c.pos for c in self.colloids]),\n        \"Velocities\": np.stack([c.v for c in self.colloids]),\n        \"Directors\": np.stack([c.director for c in self.colloids]),\n    }\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.get_unit_system","title":"<code>get_unit_system()</code>","text":"<p>Collect the pin unit registry.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.get_unit_system--returns","title":"Returns","text":"<p>unit_registry: object         The class unit registry.</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def get_unit_system(self):\n    \"\"\"\n    Collect the pin unit registry.\n\n    Returns\n    -------\n    unit_registry: object\n            The class unit registry.\n    \"\"\"\n    return self.ureg\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.integrate","title":"<code>integrate(n_slices, force_model=None)</code>","text":"<p>Integrate the system for n_slices steps.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.integrate--parameters","title":"Parameters","text":"<p>n_slices : int         Number of integration steps to run. force_model : ForceFunction         A SwarmRL interaction model to decide particle interaction rules.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.integrate--returns","title":"Returns","text":"<p>Runs the simulation environment.</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def integrate(self, n_slices, force_model: ForceFunction = None):\n    \"\"\"\n    Integrate the system for n_slices steps.\n\n    Parameters\n    ----------\n    n_slices : int\n            Number of integration steps to run.\n    force_model : ForceFunction\n            A SwarmRL interaction model to decide particle interaction rules.\n\n    Returns\n    -------\n    Runs the simulation environment.\n    \"\"\"\n\n    if not self.integration_initialised:\n        self.slice_idx = 0\n        self.step_idx = 0\n        self._setup_interactions()\n        self._remove_overlap()\n        self._init_h5_output()\n        self.integration_initialised = True\n\n    old_slice_idx = self.slice_idx\n\n    while self.step_idx &lt; self.params.steps_per_slice * (old_slice_idx + n_slices):\n        if self.step_idx == self.params.steps_per_write_interval * self.write_idx:\n            self._update_traj_holder()\n            self.write_idx += 1\n\n            if len(self.traj_holder[\"Times\"]) &gt;= self.write_chunk_size:\n                self._write_traj_chunk_to_file()\n                for val in self.traj_holder.values():\n                    val.clear()\n\n        # Break the simulaion if the kill switch is engaged.\n        if force_model is not None:\n            if force_model.kill_switch:\n                break\n\n        if self.step_idx == self.params.steps_per_slice * self.slice_idx:\n            self.slice_idx += 1\n            self.manage_forces(force_model)\n\n        steps_to_next_write = (\n            self.params.steps_per_write_interval * self.write_idx - self.step_idx\n        )\n        steps_to_next_slice = (\n            self.params.steps_per_slice * self.slice_idx - self.step_idx\n        )\n        steps_to_next = min(steps_to_next_write, steps_to_next_slice)\n\n        self.system.integrator.run(\n            steps_to_next, reuse_forces=True, recalc_forces=False\n        )\n        self.step_idx += steps_to_next\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.manage_forces","title":"<code>manage_forces(force_model=None)</code>","text":"<p>Manage external forces.</p> <p>Collect the forces from the force function and apply them to the colloids.</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.EspressoMD.manage_forces--parameters","title":"Parameters","text":"<p>force_model : ForceFunction     Model with which to compute external forces.</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>def manage_forces(self, force_model: ForceFunction = None) -&gt; bool:\n    \"\"\"\n    Manage external forces.\n\n    Collect the forces from the force function and apply them to the colloids.\n\n    Parameters\n    ----------\n    force_model : ForceFunction\n        Model with which to compute external forces.\n    \"\"\"\n    swarmrl_colloids = []\n    if force_model is not None:\n        for col in self.colloids:\n            swarmrl_colloids.append(\n                Colloid(\n                    pos=col.pos,\n                    velocity=col.v,\n                    director=col.director,\n                    id=col.id,\n                    type=col.type,\n                )\n            )\n        actions = force_model.calc_action(swarmrl_colloids)\n        for action, coll in zip(actions, self.colloids):\n            coll.swimming = {\"f_swim\": action.force}\n            coll.ext_torque = (\n                action.torque\n                if action.torque is not None\n                else np.zeros(\n                    3,\n                )\n            )\n            new_direction = action.new_direction\n            if new_direction is not None:\n                if self.n_dims == 3:\n                    coll.director = new_direction\n                else:\n                    old_direction = coll.director\n                    rotation_angle = np.arccos(np.dot(new_direction, old_direction))\n                    if rotation_angle &gt; 1e-6:\n                        rotation_axis = np.cross(old_direction, new_direction)\n                        rotation_axis /= np.linalg.norm(rotation_axis)\n                        # only values of [0,0,1], [0,0,-1] can come out here,\n                        # plusminus numerical errors\n                        rotation_axis = [0, 0, round(rotation_axis[2])]\n                        coll.rotate(axis=rotation_axis, angle=rotation_angle)\n</code></pre>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.MDParams","title":"<code>MDParams</code>  <code>dataclass</code>","text":"<p>class to hold all information needed to setup and run the MD simulation. Provide in whichever unit you want, all quantities will be converted to simulation units during setup</p>"},{"location":"pages/api/swarmrl.engine.espresso/#swarmrl.engine.espresso.MDParams--non-obvious-attributes","title":"non-obvious attributes","text":"<p>time_slice:     MD runs with internal time step of time_step. The external force/torque from     the force_model will not be updated at every single time step, instead every     time_slice. Therefore, time_slice must be an integer multiple of time_step. periodic: optional     Enable/disable periodic boundary conditions. Default: enabled thermostat_type: optional     One of \"brownian\", \"langevin\",     see https://espressomd.github.io/doc/integration.html     for details of the algorithms.</p> Source code in <code>swarmrl/engine/espresso.py</code> <pre><code>@dataclasses.dataclass()\nclass MDParams:\n    \"\"\"\n    class to hold all information needed to setup and run the MD simulation.\n    Provide in whichever unit you want, all quantities will be converted to simulation\n    units during setup\n\n    non-obvious attributes\n    ----------------------\n    time_slice:\n        MD runs with internal time step of time_step. The external force/torque from\n        the force_model will not be updated at every single time step, instead every\n        time_slice. Therefore, time_slice must be an integer multiple of time_step.\n    periodic: optional\n        Enable/disable periodic boundary conditions. Default: enabled\n    thermostat_type: optional\n        One of \"brownian\", \"langevin\",\n        see https://espressomd.github.io/doc/integration.html\n        for details of the algorithms.\n    \"\"\"\n\n    def __init__(\n        self,\n        ureg: pint.UnitRegistry,\n        box_length: pint.Quantity = None,\n        fluid_dyn_viscosity: pint.Quantity = None,\n        WCA_epsilon: pint.Quantity = None,\n        temperature: pint.Quantity = None,\n        time_step: pint.Quantity = None,\n        time_slice: pint.Quantity = None,\n        write_interval: pint.Quantity = None,\n        periodic: bool = True,\n        thermostat_type: str = \"brownian\",\n    ):\n\n        if box_length is None:\n            box_length = ureg.Quantity(3 * [1000], \"micrometer\")\n        if fluid_dyn_viscosity is None:\n            fluid_dyn_viscosity = ureg.Quantity(1e-3, \"pascal*second\")\n        if WCA_epsilon is None:\n            WCA_epsilon = ureg.Quantity(300, \"kelvin\") * ureg.boltzmann_constant\n        if temperature is None:\n            temperature = ureg.Quantity(300, \"kelvin\")\n        if time_step is None:\n            time_step = ureg.Quantity(1e-3, \"second\")\n        if time_slice is None:\n            time_slice = ureg.Quantity(1e-1, \"second\")\n        if write_interval is None:\n            write_interval = ureg.Quantity(1, \"second\")\n\n        self.ureg: pint.UnitRegistry = ureg\n        self.box_length: pint.Quantity = box_length\n        self.fluid_dyn_viscosity: pint.Quantity = fluid_dyn_viscosity\n        self.WCA_epsilon: pint.Quantity = WCA_epsilon\n        self.temperature: pint.Quantity = temperature\n        self.time_step: pint.Quantity = time_step\n        self.time_slice: pint.Quantity = time_slice\n        self.write_interval: pint.Quantity = write_interval\n        self.periodic: bool = periodic\n        self.thermostat_type: str = thermostat_type\n</code></pre>"},{"location":"pages/api/swarmrl.engine.real_experiment/","title":"swarmrl.engine.real_experiment Module API Reference","text":"<p>Parent class for the engine.</p>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.ConnectionClosedError","title":"<code>ConnectionClosedError</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Exception to capture when Matlab closes the connection</p> Source code in <code>swarmrl/engine/real_experiment.py</code> <pre><code>class ConnectionClosedError(Exception):\n    \"\"\"\n    Exception to capture when Matlab closes the connection\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment","title":"<code>RealExperiment</code>","text":"<p>             Bases: <code>Engine</code></p> <p>Class for the real experiment interface.</p> Source code in <code>swarmrl/engine/real_experiment.py</code> <pre><code>class RealExperiment(swarmrl.engine.engine.Engine):\n    \"\"\"\n    Class for the real experiment interface.\n    \"\"\"\n\n    def __init__(self, connection):\n        \"\"\"\n        Constructor for the experiment.\n\n        Parameters\n        ----------\n        connection : object\n                Communication object to be used to talk to the experiment.\n        \"\"\"\n        self.connection = connection\n\n    def setup_simulation(self) -&gt; None:\n        \"\"\"\n        Method not required in the real experiment.\n        \"\"\"\n        pass\n\n    def receive_colloids(self) -&gt; typing.List[Colloid]:\n        \"\"\"\n        Collect the colloid data from the experiment.\n\n        Returns\n        -------\n        colloids : list\n                A list of colloids.\n        \"\"\"\n        print(\"Waiting for receiving data_size\")\n        data_size = self.connection.recv(8)\n        # break if connection closed\n        if not data_size:\n            print(\"Received connection closed signal\")\n            raise ConnectionClosedError\n\n        data_size_int = struct.unpack(\"I\", data_size)[0]\n        print(f\"Received data_size = {data_size_int}\")\n        print(\"Waiting to receive actual data\")\n        data = self.connection.recv(8 * data_size_int)\n        while data and len(data) &lt; 8 * data_size_int:\n            data.extend(self.connection.recv(8 * data_size_int))\n\n        # cast bytestream to double array and reshape to [x y theta id]\n        data = np.array(struct.unpack(str(len(data) // 8) + \"d\", data)).reshape((-1, 4))\n        print(f\"Received data with shape {np.shape(data)} \\n\")\n        colloids = []\n        for row in data:\n            coll = Colloid(\n                pos=np.array([row[0], row[1], 0]),\n                director=vector_from_angle(row[2]),\n                id=row[3],\n            )\n            colloids.append(coll)\n\n        return colloids\n\n    def get_actions(\n        self,\n        colloids: typing.List[Colloid],\n        force_model: ForceFunction,\n    ) -&gt; np.array:\n        \"\"\"\n        Collect the actions on the particles.\n\n        This method calls the interaction models and collects all of the actions on the\n        colloids.\n\n        Parameters\n        ----------\n        colloids : list\n                List of colloids on which to compute interactions.\n        force_model : swarmrl.models.interaction_model.InteractionModel\n                Interaction model to use in the action computation.\n\n        Returns\n        -------\n        ret : np.ndarray\n                A numpy array of the actions on each colloid.\n        \"\"\"\n        n_colloids = len(colloids)\n        ret = np.zeros((n_colloids, 2))\n        actions = force_model.calc_action(colloids)\n        for idx, coll in enumerate(colloids):\n            action = actions[idx]\n            action.torque = (\n                action.torque\n                if action.torque is not None\n                else np.zeros(\n                    3,\n                )\n            )\n\n            if not action.force == 0.0:\n                action_id = experiment_actions[\"be_active\"]\n            else:\n                action_id = experiment_actions[\"do_nothing\"]\n\n            if not np.all(action.torque == 0):\n                if action.torque[2] &gt; 0:\n                    action_id = experiment_actions[\"rotate_anticlockwise\"]\n                else:\n                    action_id = experiment_actions[\"rotate_clockwise\"]\n\n            ret[idx, 0] = coll.id\n            ret[idx, 1] = action_id\n        return ret\n\n    def send_actions(self, actions: np.ndarray):\n        \"\"\"\n        Send the actions to the experiment apparatus.\n\n        Parameters\n        ----------\n        actions : np.ndarray\n                A numpy array of actions to send to the experiment.\n\n        Returns\n        -------\n        Sends all data to the experiment.\n        \"\"\"\n        # Flatten data in 'Fortran' style\n        data = actions.flatten(\"F\")\n        print(f\"Sending data with shape {np.shape(data)} \\n\")\n\n        data_bytes = struct.pack(str(len(data)) + \"d\", *data)\n        self.connection.sendall(data_bytes)\n\n    def integrate(\n        self,\n        n_slices: int,\n        force_model: ForceFunction,\n    ) -&gt; None:\n        \"\"\"\n        Perform the real-experiment equivalent of an integration step.\n\n        Parameters\n        ----------\n        n_slices : int\n                Number of integration steps to perform.\n        force_model : swarmrl.models.interaction_model.InteractionModel\n                Model to use in the interaction computations.\n\n        Returns\n        -------\n        Sends actions to the experiment.\n\n        Notes\n        -----\n        Can we always refer to real time as discreet? I like it.\n        \"\"\"\n        for _ in range(n_slices):\n            try:\n                colloids = self.receive_colloids()\n            except ConnectionClosedError:\n                # force_model.finalize()\n                self.connection.close()\n                break\n\n            actions = self.get_actions(colloids, force_model)\n            self.send_actions(actions)\n</code></pre>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.__init__","title":"<code>__init__(connection)</code>","text":"<p>Constructor for the experiment.</p>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.__init__--parameters","title":"Parameters","text":"<p>connection : object         Communication object to be used to talk to the experiment.</p> Source code in <code>swarmrl/engine/real_experiment.py</code> <pre><code>def __init__(self, connection):\n    \"\"\"\n    Constructor for the experiment.\n\n    Parameters\n    ----------\n    connection : object\n            Communication object to be used to talk to the experiment.\n    \"\"\"\n    self.connection = connection\n</code></pre>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.get_actions","title":"<code>get_actions(colloids, force_model)</code>","text":"<p>Collect the actions on the particles.</p> <p>This method calls the interaction models and collects all of the actions on the colloids.</p>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.get_actions--parameters","title":"Parameters","text":"<p>colloids : list         List of colloids on which to compute interactions. force_model : swarmrl.models.interaction_model.InteractionModel         Interaction model to use in the action computation.</p>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.get_actions--returns","title":"Returns","text":"<p>ret : np.ndarray         A numpy array of the actions on each colloid.</p> Source code in <code>swarmrl/engine/real_experiment.py</code> <pre><code>def get_actions(\n    self,\n    colloids: typing.List[Colloid],\n    force_model: ForceFunction,\n) -&gt; np.array:\n    \"\"\"\n    Collect the actions on the particles.\n\n    This method calls the interaction models and collects all of the actions on the\n    colloids.\n\n    Parameters\n    ----------\n    colloids : list\n            List of colloids on which to compute interactions.\n    force_model : swarmrl.models.interaction_model.InteractionModel\n            Interaction model to use in the action computation.\n\n    Returns\n    -------\n    ret : np.ndarray\n            A numpy array of the actions on each colloid.\n    \"\"\"\n    n_colloids = len(colloids)\n    ret = np.zeros((n_colloids, 2))\n    actions = force_model.calc_action(colloids)\n    for idx, coll in enumerate(colloids):\n        action = actions[idx]\n        action.torque = (\n            action.torque\n            if action.torque is not None\n            else np.zeros(\n                3,\n            )\n        )\n\n        if not action.force == 0.0:\n            action_id = experiment_actions[\"be_active\"]\n        else:\n            action_id = experiment_actions[\"do_nothing\"]\n\n        if not np.all(action.torque == 0):\n            if action.torque[2] &gt; 0:\n                action_id = experiment_actions[\"rotate_anticlockwise\"]\n            else:\n                action_id = experiment_actions[\"rotate_clockwise\"]\n\n        ret[idx, 0] = coll.id\n        ret[idx, 1] = action_id\n    return ret\n</code></pre>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.integrate","title":"<code>integrate(n_slices, force_model)</code>","text":"<p>Perform the real-experiment equivalent of an integration step.</p>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.integrate--parameters","title":"Parameters","text":"<p>n_slices : int         Number of integration steps to perform. force_model : swarmrl.models.interaction_model.InteractionModel         Model to use in the interaction computations.</p>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.integrate--returns","title":"Returns","text":"<p>Sends actions to the experiment.</p>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.integrate--notes","title":"Notes","text":"<p>Can we always refer to real time as discreet? I like it.</p> Source code in <code>swarmrl/engine/real_experiment.py</code> <pre><code>def integrate(\n    self,\n    n_slices: int,\n    force_model: ForceFunction,\n) -&gt; None:\n    \"\"\"\n    Perform the real-experiment equivalent of an integration step.\n\n    Parameters\n    ----------\n    n_slices : int\n            Number of integration steps to perform.\n    force_model : swarmrl.models.interaction_model.InteractionModel\n            Model to use in the interaction computations.\n\n    Returns\n    -------\n    Sends actions to the experiment.\n\n    Notes\n    -----\n    Can we always refer to real time as discreet? I like it.\n    \"\"\"\n    for _ in range(n_slices):\n        try:\n            colloids = self.receive_colloids()\n        except ConnectionClosedError:\n            # force_model.finalize()\n            self.connection.close()\n            break\n\n        actions = self.get_actions(colloids, force_model)\n        self.send_actions(actions)\n</code></pre>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.receive_colloids","title":"<code>receive_colloids()</code>","text":"<p>Collect the colloid data from the experiment.</p>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.receive_colloids--returns","title":"Returns","text":"<p>colloids : list         A list of colloids.</p> Source code in <code>swarmrl/engine/real_experiment.py</code> <pre><code>def receive_colloids(self) -&gt; typing.List[Colloid]:\n    \"\"\"\n    Collect the colloid data from the experiment.\n\n    Returns\n    -------\n    colloids : list\n            A list of colloids.\n    \"\"\"\n    print(\"Waiting for receiving data_size\")\n    data_size = self.connection.recv(8)\n    # break if connection closed\n    if not data_size:\n        print(\"Received connection closed signal\")\n        raise ConnectionClosedError\n\n    data_size_int = struct.unpack(\"I\", data_size)[0]\n    print(f\"Received data_size = {data_size_int}\")\n    print(\"Waiting to receive actual data\")\n    data = self.connection.recv(8 * data_size_int)\n    while data and len(data) &lt; 8 * data_size_int:\n        data.extend(self.connection.recv(8 * data_size_int))\n\n    # cast bytestream to double array and reshape to [x y theta id]\n    data = np.array(struct.unpack(str(len(data) // 8) + \"d\", data)).reshape((-1, 4))\n    print(f\"Received data with shape {np.shape(data)} \\n\")\n    colloids = []\n    for row in data:\n        coll = Colloid(\n            pos=np.array([row[0], row[1], 0]),\n            director=vector_from_angle(row[2]),\n            id=row[3],\n        )\n        colloids.append(coll)\n\n    return colloids\n</code></pre>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.send_actions","title":"<code>send_actions(actions)</code>","text":"<p>Send the actions to the experiment apparatus.</p>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.send_actions--parameters","title":"Parameters","text":"<p>actions : np.ndarray         A numpy array of actions to send to the experiment.</p>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.send_actions--returns","title":"Returns","text":"<p>Sends all data to the experiment.</p> Source code in <code>swarmrl/engine/real_experiment.py</code> <pre><code>def send_actions(self, actions: np.ndarray):\n    \"\"\"\n    Send the actions to the experiment apparatus.\n\n    Parameters\n    ----------\n    actions : np.ndarray\n            A numpy array of actions to send to the experiment.\n\n    Returns\n    -------\n    Sends all data to the experiment.\n    \"\"\"\n    # Flatten data in 'Fortran' style\n    data = actions.flatten(\"F\")\n    print(f\"Sending data with shape {np.shape(data)} \\n\")\n\n    data_bytes = struct.pack(str(len(data)) + \"d\", *data)\n    self.connection.sendall(data_bytes)\n</code></pre>"},{"location":"pages/api/swarmrl.engine.real_experiment/#swarmrl.engine.real_experiment.RealExperiment.setup_simulation","title":"<code>setup_simulation()</code>","text":"<p>Method not required in the real experiment.</p> Source code in <code>swarmrl/engine/real_experiment.py</code> <pre><code>def setup_simulation(self) -&gt; None:\n    \"\"\"\n    Method not required in the real experiment.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"pages/api/swarmrl.exploration_policies.exploration_policy/","title":"swarmrl.exploration_policies.exploration_policy Module API Reference","text":"<p>Parent class for exploration modules.</p>"},{"location":"pages/api/swarmrl.exploration_policies.exploration_policy/#swarmrl.exploration_policies.exploration_policy.ExplorationPolicy","title":"<code>ExplorationPolicy</code>","text":"<p>Parent class for exploration policies.</p> Source code in <code>swarmrl/exploration_policies/exploration_policy.py</code> <pre><code>class ExplorationPolicy:\n    \"\"\"\n    Parent class for exploration policies.\n    \"\"\"\n\n    def __call__(\n        self, model_actions: np.ndarray, action_space_length: int\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Return an index associated with the chosen action.\n\n        Parameters\n        ----------\n        model_actions : np.ndarray (n_colloids,)\n                Action chosen by the model for each colloid.\n        action_space_length : int\n                Number of possible actions. Should be 1 higher than the actual highest\n                index, i.e if I have actions [0, 1, 2, 3] this number should be 4.\n\n        Returns\n        -------\n        action : np.ndarray\n                Action chosen after the exploration module has operated for\n                each colloid.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"pages/api/swarmrl.exploration_policies.exploration_policy/#swarmrl.exploration_policies.exploration_policy.ExplorationPolicy.__call__","title":"<code>__call__(model_actions, action_space_length)</code>","text":"<p>Return an index associated with the chosen action.</p>"},{"location":"pages/api/swarmrl.exploration_policies.exploration_policy/#swarmrl.exploration_policies.exploration_policy.ExplorationPolicy.__call__--parameters","title":"Parameters","text":"<p>model_actions : np.ndarray (n_colloids,)         Action chosen by the model for each colloid. action_space_length : int         Number of possible actions. Should be 1 higher than the actual highest         index, i.e if I have actions [0, 1, 2, 3] this number should be 4.</p>"},{"location":"pages/api/swarmrl.exploration_policies.exploration_policy/#swarmrl.exploration_policies.exploration_policy.ExplorationPolicy.__call__--returns","title":"Returns","text":"<p>action : np.ndarray         Action chosen after the exploration module has operated for         each colloid.</p> Source code in <code>swarmrl/exploration_policies/exploration_policy.py</code> <pre><code>def __call__(\n    self, model_actions: np.ndarray, action_space_length: int\n) -&gt; np.ndarray:\n    \"\"\"\n    Return an index associated with the chosen action.\n\n    Parameters\n    ----------\n    model_actions : np.ndarray (n_colloids,)\n            Action chosen by the model for each colloid.\n    action_space_length : int\n            Number of possible actions. Should be 1 higher than the actual highest\n            index, i.e if I have actions [0, 1, 2, 3] this number should be 4.\n\n    Returns\n    -------\n    action : np.ndarray\n            Action chosen after the exploration module has operated for\n            each colloid.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"pages/api/swarmrl.exploration_policies.random_exploration/","title":"swarmrl.exploration_policies.random_exploration Module API Reference","text":"<p>Random exploration module.</p>"},{"location":"pages/api/swarmrl.exploration_policies.random_exploration/#swarmrl.exploration_policies.random_exploration.RandomExploration","title":"<code>RandomExploration</code>","text":"<p>             Bases: <code>ExplorationPolicy</code>, <code>ABC</code></p> <p>Perform exploration by random moves.</p> Source code in <code>swarmrl/exploration_policies/random_exploration.py</code> <pre><code>class RandomExploration(ExplorationPolicy, ABC):\n    \"\"\"\n    Perform exploration by random moves.\n    \"\"\"\n\n    def __init__(self, probability: float = 0.1):\n        \"\"\"\n        Constructor for the random exploration module.\n\n        Parameters\n        ----------\n        probability : float\n                Probability that a random action will be chosen.\n                Bound between [0.0, 1.0]\n        \"\"\"\n        self.probability = probability\n\n    @partial(jax.jit, static_argnums=(0,))\n    def __call__(\n        self, model_actions: np.ndarray, action_space_length: int, seed\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Return an index associated with the chosen action.\n\n        Parameters\n        ----------\n        model_actions : np.ndarray (n_colloids,)\n                Action chosen by the model for each colloid.\n        action_space_length : int\n                Number of possible actions. Should be 1 higher than the actual highest\n                index, i.e if I have actions [0, 1, 2, 3] this number should be 4.\n\n        Returns\n        -------\n        action : np.ndarray\n                Action chosen after the exploration module has operated for\n                each colloid.\n        \"\"\"\n        key = jax.random.PRNGKey(seed)\n        sample = jax.random.uniform(key, shape=model_actions.shape)\n\n        to_be_changed = np.clip(sample - self.probability, a_min=0, a_max=1)\n        to_be_changed = np.clip(to_be_changed * 1e6, a_min=0, a_max=1)\n        not_to_be_changed = np.clip(to_be_changed * -10 + 1, 0, 1)\n\n        # Choose random actions\n        key, subkey = jax.random.split(key)\n        exploration_actions = jax.random.randint(\n            subkey,\n            shape=(model_actions.shape[0],),\n            minval=0,\n            maxval=action_space_length,\n        )\n\n        # Put the new actions in.\n        model_actions = (\n            model_actions * to_be_changed + exploration_actions * not_to_be_changed\n        ).astype(np.int16)\n\n        return model_actions\n</code></pre>"},{"location":"pages/api/swarmrl.exploration_policies.random_exploration/#swarmrl.exploration_policies.random_exploration.RandomExploration.__call__","title":"<code>__call__(model_actions, action_space_length, seed)</code>","text":"<p>Return an index associated with the chosen action.</p>"},{"location":"pages/api/swarmrl.exploration_policies.random_exploration/#swarmrl.exploration_policies.random_exploration.RandomExploration.__call__--parameters","title":"Parameters","text":"<p>model_actions : np.ndarray (n_colloids,)         Action chosen by the model for each colloid. action_space_length : int         Number of possible actions. Should be 1 higher than the actual highest         index, i.e if I have actions [0, 1, 2, 3] this number should be 4.</p>"},{"location":"pages/api/swarmrl.exploration_policies.random_exploration/#swarmrl.exploration_policies.random_exploration.RandomExploration.__call__--returns","title":"Returns","text":"<p>action : np.ndarray         Action chosen after the exploration module has operated for         each colloid.</p> Source code in <code>swarmrl/exploration_policies/random_exploration.py</code> <pre><code>@partial(jax.jit, static_argnums=(0,))\ndef __call__(\n    self, model_actions: np.ndarray, action_space_length: int, seed\n) -&gt; np.ndarray:\n    \"\"\"\n    Return an index associated with the chosen action.\n\n    Parameters\n    ----------\n    model_actions : np.ndarray (n_colloids,)\n            Action chosen by the model for each colloid.\n    action_space_length : int\n            Number of possible actions. Should be 1 higher than the actual highest\n            index, i.e if I have actions [0, 1, 2, 3] this number should be 4.\n\n    Returns\n    -------\n    action : np.ndarray\n            Action chosen after the exploration module has operated for\n            each colloid.\n    \"\"\"\n    key = jax.random.PRNGKey(seed)\n    sample = jax.random.uniform(key, shape=model_actions.shape)\n\n    to_be_changed = np.clip(sample - self.probability, a_min=0, a_max=1)\n    to_be_changed = np.clip(to_be_changed * 1e6, a_min=0, a_max=1)\n    not_to_be_changed = np.clip(to_be_changed * -10 + 1, 0, 1)\n\n    # Choose random actions\n    key, subkey = jax.random.split(key)\n    exploration_actions = jax.random.randint(\n        subkey,\n        shape=(model_actions.shape[0],),\n        minval=0,\n        maxval=action_space_length,\n    )\n\n    # Put the new actions in.\n    model_actions = (\n        model_actions * to_be_changed + exploration_actions * not_to_be_changed\n    ).astype(np.int16)\n\n    return model_actions\n</code></pre>"},{"location":"pages/api/swarmrl.exploration_policies.random_exploration/#swarmrl.exploration_policies.random_exploration.RandomExploration.__init__","title":"<code>__init__(probability=0.1)</code>","text":"<p>Constructor for the random exploration module.</p>"},{"location":"pages/api/swarmrl.exploration_policies.random_exploration/#swarmrl.exploration_policies.random_exploration.RandomExploration.__init__--parameters","title":"Parameters","text":"<p>probability : float         Probability that a random action will be chosen.         Bound between [0.0, 1.0]</p> Source code in <code>swarmrl/exploration_policies/random_exploration.py</code> <pre><code>def __init__(self, probability: float = 0.1):\n    \"\"\"\n    Constructor for the random exploration module.\n\n    Parameters\n    ----------\n    probability : float\n            Probability that a random action will be chosen.\n            Bound between [0.0, 1.0]\n    \"\"\"\n    self.probability = probability\n</code></pre>"},{"location":"pages/api/swarmrl.force_functions.force_fn/","title":"swarmrl.force_functions.force_fn Module API Reference","text":"<p>Espresso interaction model capable of handling a neural network as a function.</p>"},{"location":"pages/api/swarmrl.force_functions.force_fn/#swarmrl.force_functions.force_fn.ForceFunction","title":"<code>ForceFunction</code>","text":"<p>Class to bridge agents with an engine.</p> Source code in <code>swarmrl/force_functions/force_fn.py</code> <pre><code>class ForceFunction:\n    \"\"\"\n    Class to bridge agents with an engine.\n    \"\"\"\n\n    _kill_switch: bool = False\n\n    def __init__(\n        self,\n        agents: dict,\n    ):\n        \"\"\"\n        Constructor for the NNModel.\n\n        Parameters\n        ----------\n        agents : dict\n            Agents used in the simulations.\n        \"\"\"\n        super().__init__()\n        self.agents = agents\n\n        # Used in the data saving.\n        self.particle_types = [type_ for type_ in self.agents]\n\n    @property\n    def kill_switch(self):\n        \"\"\"\n        If true, kill the simulation.\n        \"\"\"\n        return self._kill_switch\n\n    @kill_switch.setter\n    def kill_switch(self, value):\n        \"\"\"\n        Set the kill switch.\n        \"\"\"\n        self._kill_switch = value\n\n    def calc_action(self, colloids: typing.List[Colloid]) -&gt; typing.List[Action]:\n        \"\"\"\n        Compute the state of the system based on the current colloid position.\n\n        In the case of the ML models, this method undertakes the following steps:\n\n        1. Compute observable\n        2. Compute action probabilities\n        3. Compute action\n\n        Returns\n        -------\n        action: Action\n                Return the action the colloid should take.\n        kill_switch : bool\n                Flag capable of ending simulation.\n        \"\"\"\n        # Prepare the data storage.\n        actions = {int(np.copy(colloid.id)): Action() for colloid in colloids}\n        switches = []\n\n        # Loop over particle types and compute actions.\n        for agent in self.agents:\n            computed_actions = self.agents[agent].calc_action(colloids=colloids)\n            switches.append(self.agents[agent].kill_switch)\n\n            count = 0  # Count the colloids of a specific species.\n            for colloid in colloids:\n                if str(colloid.type) == agent:\n                    actions[colloid.id] = computed_actions[count]\n                    count += 1\n\n        self.kill_switch = any(switches)\n\n        return list(actions.values())\n</code></pre>"},{"location":"pages/api/swarmrl.force_functions.force_fn/#swarmrl.force_functions.force_fn.ForceFunction.kill_switch","title":"<code>kill_switch</code>  <code>property</code> <code>writable</code>","text":"<p>If true, kill the simulation.</p>"},{"location":"pages/api/swarmrl.force_functions.force_fn/#swarmrl.force_functions.force_fn.ForceFunction.__init__","title":"<code>__init__(agents)</code>","text":"<p>Constructor for the NNModel.</p>"},{"location":"pages/api/swarmrl.force_functions.force_fn/#swarmrl.force_functions.force_fn.ForceFunction.__init__--parameters","title":"Parameters","text":"<p>agents : dict     Agents used in the simulations.</p> Source code in <code>swarmrl/force_functions/force_fn.py</code> <pre><code>def __init__(\n    self,\n    agents: dict,\n):\n    \"\"\"\n    Constructor for the NNModel.\n\n    Parameters\n    ----------\n    agents : dict\n        Agents used in the simulations.\n    \"\"\"\n    super().__init__()\n    self.agents = agents\n\n    # Used in the data saving.\n    self.particle_types = [type_ for type_ in self.agents]\n</code></pre>"},{"location":"pages/api/swarmrl.force_functions.force_fn/#swarmrl.force_functions.force_fn.ForceFunction.calc_action","title":"<code>calc_action(colloids)</code>","text":"<p>Compute the state of the system based on the current colloid position.</p> <p>In the case of the ML models, this method undertakes the following steps:</p> <ol> <li>Compute observable</li> <li>Compute action probabilities</li> <li>Compute action</li> </ol>"},{"location":"pages/api/swarmrl.force_functions.force_fn/#swarmrl.force_functions.force_fn.ForceFunction.calc_action--returns","title":"Returns","text":"<p>action: Action         Return the action the colloid should take. kill_switch : bool         Flag capable of ending simulation.</p> Source code in <code>swarmrl/force_functions/force_fn.py</code> <pre><code>def calc_action(self, colloids: typing.List[Colloid]) -&gt; typing.List[Action]:\n    \"\"\"\n    Compute the state of the system based on the current colloid position.\n\n    In the case of the ML models, this method undertakes the following steps:\n\n    1. Compute observable\n    2. Compute action probabilities\n    3. Compute action\n\n    Returns\n    -------\n    action: Action\n            Return the action the colloid should take.\n    kill_switch : bool\n            Flag capable of ending simulation.\n    \"\"\"\n    # Prepare the data storage.\n    actions = {int(np.copy(colloid.id)): Action() for colloid in colloids}\n    switches = []\n\n    # Loop over particle types and compute actions.\n    for agent in self.agents:\n        computed_actions = self.agents[agent].calc_action(colloids=colloids)\n        switches.append(self.agents[agent].kill_switch)\n\n        count = 0  # Count the colloids of a specific species.\n        for colloid in colloids:\n            if str(colloid.type) == agent:\n                actions[colloid.id] = computed_actions[count]\n                count += 1\n\n    self.kill_switch = any(switches)\n\n    return list(actions.values())\n</code></pre>"},{"location":"pages/api/swarmrl.losses.loss/","title":"swarmrl.losses.loss Module API Reference","text":"<p>Module for the loss parent class.</p>"},{"location":"pages/api/swarmrl.losses.loss/#swarmrl.losses.loss.Loss","title":"<code>Loss</code>","text":"<p>Parent class for a SwarmRL loss model.</p> Source code in <code>swarmrl/losses/loss.py</code> <pre><code>class Loss:\n    \"\"\"\n    Parent class for a SwarmRL loss model.\n    \"\"\"\n\n    def compute_loss(\n        self,\n        network: Network,\n        episode_data: np.ndarray,\n    ):\n        \"\"\"\n        Compute loss on models.\n\n        Parameters\n        ----------\n        network : Network\n                Actor-critic network.\n        episode_data : dict\n                A dictionary of episode data.\n        \"\"\"\n        raise NotImplementedError(\"Implemented in child class.\")\n</code></pre>"},{"location":"pages/api/swarmrl.losses.loss/#swarmrl.losses.loss.Loss.compute_loss","title":"<code>compute_loss(network, episode_data)</code>","text":"<p>Compute loss on models.</p>"},{"location":"pages/api/swarmrl.losses.loss/#swarmrl.losses.loss.Loss.compute_loss--parameters","title":"Parameters","text":"<p>network : Network         Actor-critic network. episode_data : dict         A dictionary of episode data.</p> Source code in <code>swarmrl/losses/loss.py</code> <pre><code>def compute_loss(\n    self,\n    network: Network,\n    episode_data: np.ndarray,\n):\n    \"\"\"\n    Compute loss on models.\n\n    Parameters\n    ----------\n    network : Network\n            Actor-critic network.\n    episode_data : dict\n            A dictionary of episode data.\n    \"\"\"\n    raise NotImplementedError(\"Implemented in child class.\")\n</code></pre>"},{"location":"pages/api/swarmrl.losses.policy_gradient_loss/","title":"swarmrl.losses.policy_gradient_loss Module API Reference","text":"<p>Module for the implementation of policy gradient loss.</p> <p>Policy gradient is the most simplistic loss function where critic loss drives the entire policy learning.</p>"},{"location":"pages/api/swarmrl.losses.policy_gradient_loss/#swarmrl.losses.policy_gradient_loss--notes","title":"Notes","text":"<p>https://spinningup.openai.com/en/latest/algorithms/vpg.html</p>"},{"location":"pages/api/swarmrl.losses.policy_gradient_loss/#swarmrl.losses.policy_gradient_loss.PolicyGradientLoss","title":"<code>PolicyGradientLoss</code>","text":"<p>             Bases: <code>Loss</code></p> <p>Parent class for the reinforcement learning tasks.</p>"},{"location":"pages/api/swarmrl.losses.policy_gradient_loss/#swarmrl.losses.policy_gradient_loss.PolicyGradientLoss--notes","title":"Notes","text":"Source code in <code>swarmrl/losses/policy_gradient_loss.py</code> <pre><code>class PolicyGradientLoss(Loss):\n    \"\"\"\n    Parent class for the reinforcement learning tasks.\n\n    Notes\n    -----\n    \"\"\"\n\n    def __init__(self, value_function: ExpectedReturns = ExpectedReturns()):\n        \"\"\"\n        Constructor for the reward class.\n\n        Parameters\n        ----------\n        value_function : ExpectedReturns\n        \"\"\"\n        super(Loss, self).__init__()\n        self.value_function = value_function\n        self.n_particles = None\n        self.n_time_steps = None\n\n    def _calculate_loss(\n        self,\n        network_params: FrozenDict,\n        network: Network,\n        feature_data: jnp.ndarray,\n        action_indices: jnp.ndarray,\n        rewards: jnp.ndarray,\n    ) -&gt; jnp.array:\n        \"\"\"\n        Compute the loss of the shared actor-critic network.\n\n        Parameters\n        ----------\n        network : FlaxModel\n            The actor-critic network that approximates the policy.\n        network_params : FrozenDict\n            Parameters of the actor-critic model used.\n        feature_data : np.ndarray (n_time_steps, n_particles, feature_dimension)\n            Observable data for each time step and particle within the episode.\n        action_indices : np.ndarray (n_time_steps, n_particles)\n            The actions taken by the policy for all time steps and particles during one\n            episode.\n        rewards : np.ndarray (n_time_steps, n_particles)\n            The rewards received for all time steps and particles during one episode.\n\n\n        Returns\n        -------\n        loss : float\n            The loss of the actor-critic network for the last episode.\n        \"\"\"\n\n        # (n_timesteps, n_particles, n_possibilities)\n        logits, predicted_values = network(network_params, feature_data)\n        predicted_values = predicted_values.squeeze()\n        probabilities = jax.nn.softmax(logits)  # get probabilities\n        chosen_probabilities = gather_n_dim_indices(probabilities, action_indices)\n        log_probs = jnp.log(chosen_probabilities + 1e-8)\n        logger.debug(f\"{log_probs.shape=}\")\n\n        returns = self.value_function(rewards)\n        logger.debug(f\"{returns.shape}\")\n\n        logger.debug(f\"{predicted_values.shape=}\")\n\n        # (n_timesteps, n_particles)\n        advantage = returns - predicted_values\n        logger.debug(f\"{advantage=}\")\n\n        actor_loss = -1 * ((log_probs * advantage).sum(axis=0)).sum()\n        logger.debug(f\"{actor_loss=}\")\n\n        # Sum over time steps and average over agents.\n        critic_loss = optax.huber_loss(predicted_values, returns).sum(axis=0).sum()\n\n        return actor_loss + critic_loss\n\n    def compute_loss(self, network: Network, episode_data):\n        \"\"\"\n        Compute the loss and update the shared actor-critic network.\n\n        Parameters\n        ----------\n        network : Network\n                actor-critic model to use in the analysis.\n        episode_data : np.ndarray (n_timesteps, n_particles, feature_dimension)\n                Observable data for each time step and particle within the episode.\n\n        Returns\n        -------\n\n        \"\"\"\n        feature_data = jnp.array(episode_data.features)\n        action_data = jnp.array(episode_data.actions)\n        reward_data = jnp.array(episode_data.rewards)\n\n        self.n_particles = jnp.shape(feature_data)[1]\n        self.n_time_steps = jnp.shape(feature_data)[0]\n\n        network_grad_fn = jax.value_and_grad(self._calculate_loss)\n        _, network_grads = network_grad_fn(\n            network.model_state.params,\n            network=network,\n            feature_data=feature_data,\n            action_indices=action_data,\n            rewards=reward_data,\n        )\n\n        network.update_model(network_grads)\n</code></pre>"},{"location":"pages/api/swarmrl.losses.policy_gradient_loss/#swarmrl.losses.policy_gradient_loss.PolicyGradientLoss.__init__","title":"<code>__init__(value_function=ExpectedReturns())</code>","text":"<p>Constructor for the reward class.</p>"},{"location":"pages/api/swarmrl.losses.policy_gradient_loss/#swarmrl.losses.policy_gradient_loss.PolicyGradientLoss.__init__--parameters","title":"Parameters","text":"<p>value_function : ExpectedReturns</p> Source code in <code>swarmrl/losses/policy_gradient_loss.py</code> <pre><code>def __init__(self, value_function: ExpectedReturns = ExpectedReturns()):\n    \"\"\"\n    Constructor for the reward class.\n\n    Parameters\n    ----------\n    value_function : ExpectedReturns\n    \"\"\"\n    super(Loss, self).__init__()\n    self.value_function = value_function\n    self.n_particles = None\n    self.n_time_steps = None\n</code></pre>"},{"location":"pages/api/swarmrl.losses.policy_gradient_loss/#swarmrl.losses.policy_gradient_loss.PolicyGradientLoss.compute_loss","title":"<code>compute_loss(network, episode_data)</code>","text":"<p>Compute the loss and update the shared actor-critic network.</p>"},{"location":"pages/api/swarmrl.losses.policy_gradient_loss/#swarmrl.losses.policy_gradient_loss.PolicyGradientLoss.compute_loss--parameters","title":"Parameters","text":"<p>network : Network         actor-critic model to use in the analysis. episode_data : np.ndarray (n_timesteps, n_particles, feature_dimension)         Observable data for each time step and particle within the episode.</p>"},{"location":"pages/api/swarmrl.losses.policy_gradient_loss/#swarmrl.losses.policy_gradient_loss.PolicyGradientLoss.compute_loss--returns","title":"Returns","text":"Source code in <code>swarmrl/losses/policy_gradient_loss.py</code> <pre><code>def compute_loss(self, network: Network, episode_data):\n    \"\"\"\n    Compute the loss and update the shared actor-critic network.\n\n    Parameters\n    ----------\n    network : Network\n            actor-critic model to use in the analysis.\n    episode_data : np.ndarray (n_timesteps, n_particles, feature_dimension)\n            Observable data for each time step and particle within the episode.\n\n    Returns\n    -------\n\n    \"\"\"\n    feature_data = jnp.array(episode_data.features)\n    action_data = jnp.array(episode_data.actions)\n    reward_data = jnp.array(episode_data.rewards)\n\n    self.n_particles = jnp.shape(feature_data)[1]\n    self.n_time_steps = jnp.shape(feature_data)[0]\n\n    network_grad_fn = jax.value_and_grad(self._calculate_loss)\n    _, network_grads = network_grad_fn(\n        network.model_state.params,\n        network=network,\n        feature_data=feature_data,\n        action_indices=action_data,\n        rewards=reward_data,\n    )\n\n    network.update_model(network_grads)\n</code></pre>"},{"location":"pages/api/swarmrl.losses.proximal_policy_loss/","title":"swarmrl.losses.proximal_policy_loss Module API Reference","text":"<p>Loss functions based on Proximal policy optimization.</p>"},{"location":"pages/api/swarmrl.losses.proximal_policy_loss/#swarmrl.losses.proximal_policy_loss--notes","title":"Notes","text":"<p>https://spinningup.openai.com/en/latest/algorithms/ppo.html</p>"},{"location":"pages/api/swarmrl.losses.proximal_policy_loss/#swarmrl.losses.proximal_policy_loss.ProximalPolicyLoss","title":"<code>ProximalPolicyLoss</code>","text":"<p>             Bases: <code>Loss</code>, <code>ABC</code></p> <p>Class to implement the proximal policy loss.</p> Source code in <code>swarmrl/losses/proximal_policy_loss.py</code> <pre><code>class ProximalPolicyLoss(Loss, ABC):\n    \"\"\"\n    Class to implement the proximal policy loss.\n    \"\"\"\n\n    def __init__(\n        self,\n        value_function: GAE = GAE(),\n        sampling_strategy: SamplingStrategy = GumbelDistribution(),\n        n_epochs: int = 20,\n        epsilon: float = 0.2,\n        entropy_coefficient: float = 0.01,\n    ):\n        \"\"\"\n        Constructor for the PPO class.\n\n        Parameters\n        ----------\n        value_function : Callable\n            A the state value function that computes the value of a series of states for\n            using the reward of the trajectory visiting these states\n        n_epochs : int\n            number of PPO updates\n        epsilon : float\n            the maximum of the relative distance between old and updated policy.\n        entropy_coefficient : float\n            Entropy coefficient for the PPO update. # TODO Add more here.\n\n        \"\"\"\n        self.value_function = value_function\n        self.sampling_strategy = sampling_strategy\n        self.n_epochs = n_epochs\n        self.epsilon = epsilon\n        self.entropy_coefficient = entropy_coefficient\n        self.eps = 1e-8\n\n    @partial(jit, static_argnums=(0, 2))\n    def _calculate_loss(\n        self,\n        network_params: FrozenDict,\n        network: Network,\n        feature_data,\n        action_indices,\n        rewards,\n        old_log_probs,\n    ) -&gt; jnp.array:\n        \"\"\"\n        A function that computes the actor loss.\n\n        Parameters\n        ----------\n        network : FlaxModel\n            The actor-critic network that approximates the policy.\n        network_params : FrozenDict\n            Parameters of the actor-critic model used.\n        feature_data : np.ndarray (n_time_steps, n_particles, feature_dimension)\n            Observable data for each time step and particle within the episode.\n        action_indices : np.ndarray (n_time_steps, n_particles)\n            The actions taken by the policy for all time steps and particles during one\n            episode.\n        rewards : np.ndarray (n_time_steps, n_particles)\n            The rewards received for all time steps and particles during one episode.\n        old_log_probs : np.ndarray (n_time_steps, n_particles)\n            The log probabilities of the actions taken by the policy for all time steps\n            and particles during one episode.\n\n        Returns\n        -------\n        loss: float\n            The loss of the actor-critic network for the last episode.\n        \"\"\"\n\n        # compute the probabilities of the old actions under the new policy\n        new_logits, predicted_values = network(network_params, feature_data)\n        predicted_values = predicted_values.squeeze()\n\n        # compute the advantages and returns\n        advantages, returns = self.value_function(\n            rewards=rewards, values=predicted_values\n        )\n\n        # compute the probabilities of the old actions under the new policy\n        new_probabilities = jax.nn.softmax(new_logits, axis=-1)\n\n        # compute the entropy of the whole distribution\n        entropy = self.sampling_strategy.compute_entropy(new_probabilities).sum()\n        chosen_log_probs = jnp.log(\n            gather_n_dim_indices(new_probabilities, action_indices) + self.eps\n        )\n\n        # compute the ratio between old and new probs\n        ratio = jnp.exp(chosen_log_probs - old_log_probs)\n\n        # Compute the actor loss\n\n        # compute the clipped loss\n        clipped_loss = -1 * jnp.minimum(\n            ratio * advantages,\n            jnp.clip(ratio, 1 - self.epsilon, 1 + self.epsilon) * advantages,\n        )\n        particle_actor_loss = jnp.sum(clipped_loss, axis=0)\n        actor_loss = jnp.sum(particle_actor_loss)\n\n        # Compute critic loss\n        total_critic_loss = (\n            optax.huber_loss(predicted_values, returns).sum(axis=0).sum()\n        )\n\n        # Compute combined loss\n        loss = actor_loss - self.entropy_coefficient * entropy + 0.5 * total_critic_loss\n\n        return loss\n\n    def compute_loss(self, network: Network, episode_data):\n        \"\"\"\n        Compute the loss and update the shared actor-critic network.\n\n        Parameters\n        ----------\n        network : Network\n                actor-critic model to use in the analysis.\n        episode_data : np.ndarray (n_timesteps, n_particles, feature_dimension)\n                Observable data for each time step and particle within the episode.\n\n        Returns\n        -------\n\n        \"\"\"\n        old_log_probs_data = jnp.array(episode_data.log_probs)\n        feature_data = jnp.array(episode_data.features)\n        action_data = jnp.array(episode_data.actions)\n        reward_data = jnp.array(episode_data.rewards)\n\n        for _ in range(self.n_epochs):\n            network_grad_fn = jax.value_and_grad(self._calculate_loss)\n            _, network_grad = network_grad_fn(\n                network.model_state.params,\n                network=network,\n                feature_data=feature_data,\n                action_indices=action_data,\n                rewards=reward_data,\n                old_log_probs=old_log_probs_data,\n            )\n\n            network.update_model(network_grad)\n</code></pre>"},{"location":"pages/api/swarmrl.losses.proximal_policy_loss/#swarmrl.losses.proximal_policy_loss.ProximalPolicyLoss.__init__","title":"<code>__init__(value_function=GAE(), sampling_strategy=GumbelDistribution(), n_epochs=20, epsilon=0.2, entropy_coefficient=0.01)</code>","text":"<p>Constructor for the PPO class.</p>"},{"location":"pages/api/swarmrl.losses.proximal_policy_loss/#swarmrl.losses.proximal_policy_loss.ProximalPolicyLoss.__init__--parameters","title":"Parameters","text":"<p>value_function : Callable     A the state value function that computes the value of a series of states for     using the reward of the trajectory visiting these states n_epochs : int     number of PPO updates epsilon : float     the maximum of the relative distance between old and updated policy. entropy_coefficient : float     Entropy coefficient for the PPO update. # TODO Add more here.</p> Source code in <code>swarmrl/losses/proximal_policy_loss.py</code> <pre><code>def __init__(\n    self,\n    value_function: GAE = GAE(),\n    sampling_strategy: SamplingStrategy = GumbelDistribution(),\n    n_epochs: int = 20,\n    epsilon: float = 0.2,\n    entropy_coefficient: float = 0.01,\n):\n    \"\"\"\n    Constructor for the PPO class.\n\n    Parameters\n    ----------\n    value_function : Callable\n        A the state value function that computes the value of a series of states for\n        using the reward of the trajectory visiting these states\n    n_epochs : int\n        number of PPO updates\n    epsilon : float\n        the maximum of the relative distance between old and updated policy.\n    entropy_coefficient : float\n        Entropy coefficient for the PPO update. # TODO Add more here.\n\n    \"\"\"\n    self.value_function = value_function\n    self.sampling_strategy = sampling_strategy\n    self.n_epochs = n_epochs\n    self.epsilon = epsilon\n    self.entropy_coefficient = entropy_coefficient\n    self.eps = 1e-8\n</code></pre>"},{"location":"pages/api/swarmrl.losses.proximal_policy_loss/#swarmrl.losses.proximal_policy_loss.ProximalPolicyLoss.compute_loss","title":"<code>compute_loss(network, episode_data)</code>","text":"<p>Compute the loss and update the shared actor-critic network.</p>"},{"location":"pages/api/swarmrl.losses.proximal_policy_loss/#swarmrl.losses.proximal_policy_loss.ProximalPolicyLoss.compute_loss--parameters","title":"Parameters","text":"<p>network : Network         actor-critic model to use in the analysis. episode_data : np.ndarray (n_timesteps, n_particles, feature_dimension)         Observable data for each time step and particle within the episode.</p>"},{"location":"pages/api/swarmrl.losses.proximal_policy_loss/#swarmrl.losses.proximal_policy_loss.ProximalPolicyLoss.compute_loss--returns","title":"Returns","text":"Source code in <code>swarmrl/losses/proximal_policy_loss.py</code> <pre><code>def compute_loss(self, network: Network, episode_data):\n    \"\"\"\n    Compute the loss and update the shared actor-critic network.\n\n    Parameters\n    ----------\n    network : Network\n            actor-critic model to use in the analysis.\n    episode_data : np.ndarray (n_timesteps, n_particles, feature_dimension)\n            Observable data for each time step and particle within the episode.\n\n    Returns\n    -------\n\n    \"\"\"\n    old_log_probs_data = jnp.array(episode_data.log_probs)\n    feature_data = jnp.array(episode_data.features)\n    action_data = jnp.array(episode_data.actions)\n    reward_data = jnp.array(episode_data.rewards)\n\n    for _ in range(self.n_epochs):\n        network_grad_fn = jax.value_and_grad(self._calculate_loss)\n        _, network_grad = network_grad_fn(\n            network.model_state.params,\n            network=network,\n            feature_data=feature_data,\n            action_indices=action_data,\n            rewards=reward_data,\n            old_log_probs=old_log_probs_data,\n        )\n\n        network.update_model(network_grad)\n</code></pre>"},{"location":"pages/api/swarmrl.networks.flax_network/","title":"swarmrl.networks.flax_network Module API Reference","text":"<p>Jax model for reinforcement learning.</p>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel","title":"<code>FlaxModel</code>","text":"<p>             Bases: <code>Network</code>, <code>ABC</code></p> <p>Class for the Flax model in ZnRND.</p>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel--attributes","title":"Attributes","text":"<p>epoch_count : int         Current epoch stage. Used in saving the models.</p> Source code in <code>swarmrl/networks/flax_network.py</code> <pre><code>class FlaxModel(Network, ABC):\n    \"\"\"\n    Class for the Flax model in ZnRND.\n\n    Attributes\n    ----------\n    epoch_count : int\n            Current epoch stage. Used in saving the models.\n    \"\"\"\n\n    def __init__(\n        self,\n        flax_model: nn.Module,\n        input_shape: tuple,\n        optimizer: GradientTransformation = None,\n        exploration_policy: ExplorationPolicy = RandomExploration(probability=0.0),\n        sampling_strategy: SamplingStrategy = GumbelDistribution(),\n        rng_key: int = None,\n        deployment_mode: bool = False,\n    ):\n        \"\"\"\n        Constructor for a Flax model.\n\n        Parameters\n        ----------\n        flax_model : nn.Module\n                Flax model as a neural network.\n        optimizer : Callable\n                optimizer to use in the training. OpTax is used by default and\n                cross-compatibility is not assured.\n        input_shape : tuple\n                Shape of the NN input.\n        rng_key : int\n                Key to seed the model with. Default is a randomly generated key but\n                the parameter is here for testing purposes.\n        deployment_mode : bool\n                If true, the model is a shell for the network and nothing else. No\n                training can be performed, this is only used in deployment.\n        \"\"\"\n        if rng_key is None:\n            rng_key = onp.random.randint(0, 1027465782564)\n        self.sampling_strategy = sampling_strategy\n        self.model = flax_model\n        self.apply_fn = jax.jit(\n            jax.vmap(self.model.apply, in_axes=(None, 0))\n        )  # Map over agents\n        self.batch_apply_fn = jax.jit(jax.vmap(self.apply_fn, in_axes=(None, 0)))\n        self.input_shape = input_shape\n        self.model_state = None\n\n        if not deployment_mode:\n            self.optimizer = optimizer\n            self.exploration_policy = exploration_policy\n\n            # initialize the model state\n            init_rng = jax.random.PRNGKey(rng_key)\n            _, subkey = jax.random.split(init_rng)\n            self.model_state = self._create_train_state(subkey)\n\n            self.epoch_count = 0\n\n    def _create_custom_train_state(self, optimizer: dict):\n        \"\"\"\n        Deal with the optimizers in case of complex configuration.\n        \"\"\"\n        return type(\"TrainState\", (TrainState,), optimizer)\n\n    def _create_train_state(self, init_rng: int) -&gt; TrainState:\n        \"\"\"\n        Create a training state of the model.\n\n        Parameters\n        ----------\n        init_rng : int\n                Initial rng for train state that is immediately deleted.\n\n        Returns\n        -------\n        state : TrainState / CustomTrainState\n                initial state of model to then be trained.\n                If you have multiple optimizers, this will create a custom train state.\n        \"\"\"\n        params = self.model.init(init_rng, np.ones(list(self.input_shape)))[\"params\"]\n\n        if isinstance(self.optimizer, dict):\n            CustomTrainState = self._create_custom_train_state(self.optimizer)\n\n            return CustomTrainState.create(\n                apply_fn=self.model.apply, params=params, tx=self.optimizer\n            )\n        else:\n            return TrainState.create(\n                apply_fn=self.model.apply, params=params, tx=self.optimizer\n            )\n\n    def reinitialize_network(self):\n        \"\"\"\n        Initialize the neural network.\n        \"\"\"\n        rng_key = onp.random.randint(0, 1027465782564)\n        init_rng = jax.random.PRNGKey(rng_key)\n        _, subkey = jax.random.split(init_rng)\n        self.model_state = self._create_train_state(subkey)\n\n    def update_model(self, grads):\n        \"\"\"\n        Train the model.\n\n        See the parent class for a full doc-string.\n        \"\"\"\n        # Logging for grads and pre-train model state\n        logger.debug(f\"{grads=}\")\n        logger.debug(f\"{self.model_state=}\")\n\n        if isinstance(self.optimizer, dict):\n            pass\n\n        else:\n            self.model_state = self.model_state.apply_gradients(grads=grads)\n\n        # Logging for post-train model state\n        logger.debug(f\"{self.model_state=}\")\n\n        self.epoch_count += 1\n\n    def compute_action(self, observables: List):\n        \"\"\"\n        Compute and action from the action space.\n\n        This method computes an action on all colloids of the relevant type.\n\n        Parameters\n        ----------\n        observables : List (n_agents, observable_dimension)\n                Observable for each colloid for which the action should be computed.\n\n        Returns\n        -------\n        tuple : (np.ndarray, np.ndarray)\n                The first element is an array of indices corresponding to the action\n                taken by the agent. The value is bounded between 0 and the number of\n                output neurons. The second element is an array of the corresponding\n                log_probs (i.e. the output of the network put through a softmax).\n        \"\"\"\n        # Compute state\n        try:\n            logits, _ = self.apply_fn(\n                {\"params\": self.model_state.params}, np.array(observables)\n            )\n        except AttributeError:  # We need this for loaded models.\n            logits, _ = self.apply_fn(\n                {\"params\": self.model_state[\"params\"]}, np.array(observables)\n            )\n        logger.debug(f\"{logits=}\")  # (n_colloids, n_actions)\n\n        # Compute the action\n        indices = self.sampling_strategy(logits)\n        # Add a small value to the log_probs to avoid log(0) errors.\n        eps = 1e-8\n        log_probs = np.log(jax.nn.softmax(logits) + eps)\n\n        indices = self.exploration_policy(\n            indices, logits.shape[-1], onp.random.randint(8759865)\n        )\n        return (\n            indices,\n            np.take_along_axis(log_probs, indices.reshape(-1, 1), axis=1).reshape(-1),\n        )\n\n    def export_model(self, filename: str = \"model\", directory: str = \"Models\"):\n        \"\"\"\n        Export the model state to a directory.\n\n        Parameters\n        ----------\n        filename : str (default=models)\n                Name of the file the models are saved in.\n        directory : str (default=Models)\n                Directory in which to save the models. If the directory is not\n                in the currently directory, it will be created.\n\n        \"\"\"\n        model_params = self.model_state.params\n        opt_state = self.model_state.opt_state\n        opt_step = self.model_state.step\n        epoch = self.epoch_count\n\n        os.makedirs(directory, exist_ok=True)\n\n        with open(directory + \"/\" + filename + \".pkl\", \"wb\") as f:\n            pickle.dump((model_params, opt_state, opt_step, epoch), f)\n\n    def restore_model_state(self, filename, directory):\n        \"\"\"\n        Restore the model state from a file.\n\n        Parameters\n        ----------\n        filename : str\n                Name of the model state file\n        directory : str\n                Path to the model state file.\n\n        Returns\n        -------\n        Updates the model state.\n        \"\"\"\n\n        with open(directory + \"/\" + filename + \".pkl\", \"rb\") as f:\n            model_params, opt_state, opt_step, epoch = pickle.load(f)\n\n        self.model_state = self.model_state.replace(\n            params=model_params, opt_state=opt_state, step=opt_step\n        )\n        self.epoch_count = epoch\n\n    def __call__(self, params: FrozenDict, episode_features):\n        \"\"\"\n        vmaped version of the model call function.\n        Operates on a batch of episodes.\n\n        Parameters\n        ----------\n        parmas : dict\n                Parameters of the model.\n        episode_features: np.ndarray (n_steps, n_agents, observable_dimension)\n                Features of the episode. This contains the features of all agents,\n                for all time steps in the episode.\n\n\n        Returns\n        -------\n        logits : np.ndarray\n                Output of the network.\n        \"\"\"\n\n        return self.batch_apply_fn({\"params\": params}, episode_features)\n</code></pre>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.__call__","title":"<code>__call__(params, episode_features)</code>","text":"<p>vmaped version of the model call function. Operates on a batch of episodes.</p>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.__call__--parameters","title":"Parameters","text":"<p>parmas : dict         Parameters of the model. episode_features: np.ndarray (n_steps, n_agents, observable_dimension)         Features of the episode. This contains the features of all agents,         for all time steps in the episode.</p>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.__call__--returns","title":"Returns","text":"<p>logits : np.ndarray         Output of the network.</p> Source code in <code>swarmrl/networks/flax_network.py</code> <pre><code>def __call__(self, params: FrozenDict, episode_features):\n    \"\"\"\n    vmaped version of the model call function.\n    Operates on a batch of episodes.\n\n    Parameters\n    ----------\n    parmas : dict\n            Parameters of the model.\n    episode_features: np.ndarray (n_steps, n_agents, observable_dimension)\n            Features of the episode. This contains the features of all agents,\n            for all time steps in the episode.\n\n\n    Returns\n    -------\n    logits : np.ndarray\n            Output of the network.\n    \"\"\"\n\n    return self.batch_apply_fn({\"params\": params}, episode_features)\n</code></pre>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.__init__","title":"<code>__init__(flax_model, input_shape, optimizer=None, exploration_policy=RandomExploration(probability=0.0), sampling_strategy=GumbelDistribution(), rng_key=None, deployment_mode=False)</code>","text":"<p>Constructor for a Flax model.</p>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.__init__--parameters","title":"Parameters","text":"<p>flax_model : nn.Module         Flax model as a neural network. optimizer : Callable         optimizer to use in the training. OpTax is used by default and         cross-compatibility is not assured. input_shape : tuple         Shape of the NN input. rng_key : int         Key to seed the model with. Default is a randomly generated key but         the parameter is here for testing purposes. deployment_mode : bool         If true, the model is a shell for the network and nothing else. No         training can be performed, this is only used in deployment.</p> Source code in <code>swarmrl/networks/flax_network.py</code> <pre><code>def __init__(\n    self,\n    flax_model: nn.Module,\n    input_shape: tuple,\n    optimizer: GradientTransformation = None,\n    exploration_policy: ExplorationPolicy = RandomExploration(probability=0.0),\n    sampling_strategy: SamplingStrategy = GumbelDistribution(),\n    rng_key: int = None,\n    deployment_mode: bool = False,\n):\n    \"\"\"\n    Constructor for a Flax model.\n\n    Parameters\n    ----------\n    flax_model : nn.Module\n            Flax model as a neural network.\n    optimizer : Callable\n            optimizer to use in the training. OpTax is used by default and\n            cross-compatibility is not assured.\n    input_shape : tuple\n            Shape of the NN input.\n    rng_key : int\n            Key to seed the model with. Default is a randomly generated key but\n            the parameter is here for testing purposes.\n    deployment_mode : bool\n            If true, the model is a shell for the network and nothing else. No\n            training can be performed, this is only used in deployment.\n    \"\"\"\n    if rng_key is None:\n        rng_key = onp.random.randint(0, 1027465782564)\n    self.sampling_strategy = sampling_strategy\n    self.model = flax_model\n    self.apply_fn = jax.jit(\n        jax.vmap(self.model.apply, in_axes=(None, 0))\n    )  # Map over agents\n    self.batch_apply_fn = jax.jit(jax.vmap(self.apply_fn, in_axes=(None, 0)))\n    self.input_shape = input_shape\n    self.model_state = None\n\n    if not deployment_mode:\n        self.optimizer = optimizer\n        self.exploration_policy = exploration_policy\n\n        # initialize the model state\n        init_rng = jax.random.PRNGKey(rng_key)\n        _, subkey = jax.random.split(init_rng)\n        self.model_state = self._create_train_state(subkey)\n\n        self.epoch_count = 0\n</code></pre>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.compute_action","title":"<code>compute_action(observables)</code>","text":"<p>Compute and action from the action space.</p> <p>This method computes an action on all colloids of the relevant type.</p>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.compute_action--parameters","title":"Parameters","text":"<p>observables : List (n_agents, observable_dimension)         Observable for each colloid for which the action should be computed.</p>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.compute_action--returns","title":"Returns","text":"<p>tuple : (np.ndarray, np.ndarray)         The first element is an array of indices corresponding to the action         taken by the agent. The value is bounded between 0 and the number of         output neurons. The second element is an array of the corresponding         log_probs (i.e. the output of the network put through a softmax).</p> Source code in <code>swarmrl/networks/flax_network.py</code> <pre><code>def compute_action(self, observables: List):\n    \"\"\"\n    Compute and action from the action space.\n\n    This method computes an action on all colloids of the relevant type.\n\n    Parameters\n    ----------\n    observables : List (n_agents, observable_dimension)\n            Observable for each colloid for which the action should be computed.\n\n    Returns\n    -------\n    tuple : (np.ndarray, np.ndarray)\n            The first element is an array of indices corresponding to the action\n            taken by the agent. The value is bounded between 0 and the number of\n            output neurons. The second element is an array of the corresponding\n            log_probs (i.e. the output of the network put through a softmax).\n    \"\"\"\n    # Compute state\n    try:\n        logits, _ = self.apply_fn(\n            {\"params\": self.model_state.params}, np.array(observables)\n        )\n    except AttributeError:  # We need this for loaded models.\n        logits, _ = self.apply_fn(\n            {\"params\": self.model_state[\"params\"]}, np.array(observables)\n        )\n    logger.debug(f\"{logits=}\")  # (n_colloids, n_actions)\n\n    # Compute the action\n    indices = self.sampling_strategy(logits)\n    # Add a small value to the log_probs to avoid log(0) errors.\n    eps = 1e-8\n    log_probs = np.log(jax.nn.softmax(logits) + eps)\n\n    indices = self.exploration_policy(\n        indices, logits.shape[-1], onp.random.randint(8759865)\n    )\n    return (\n        indices,\n        np.take_along_axis(log_probs, indices.reshape(-1, 1), axis=1).reshape(-1),\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.export_model","title":"<code>export_model(filename='model', directory='Models')</code>","text":"<p>Export the model state to a directory.</p>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.export_model--parameters","title":"Parameters","text":"<p>filename : str (default=models)         Name of the file the models are saved in. directory : str (default=Models)         Directory in which to save the models. If the directory is not         in the currently directory, it will be created.</p> Source code in <code>swarmrl/networks/flax_network.py</code> <pre><code>def export_model(self, filename: str = \"model\", directory: str = \"Models\"):\n    \"\"\"\n    Export the model state to a directory.\n\n    Parameters\n    ----------\n    filename : str (default=models)\n            Name of the file the models are saved in.\n    directory : str (default=Models)\n            Directory in which to save the models. If the directory is not\n            in the currently directory, it will be created.\n\n    \"\"\"\n    model_params = self.model_state.params\n    opt_state = self.model_state.opt_state\n    opt_step = self.model_state.step\n    epoch = self.epoch_count\n\n    os.makedirs(directory, exist_ok=True)\n\n    with open(directory + \"/\" + filename + \".pkl\", \"wb\") as f:\n        pickle.dump((model_params, opt_state, opt_step, epoch), f)\n</code></pre>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.reinitialize_network","title":"<code>reinitialize_network()</code>","text":"<p>Initialize the neural network.</p> Source code in <code>swarmrl/networks/flax_network.py</code> <pre><code>def reinitialize_network(self):\n    \"\"\"\n    Initialize the neural network.\n    \"\"\"\n    rng_key = onp.random.randint(0, 1027465782564)\n    init_rng = jax.random.PRNGKey(rng_key)\n    _, subkey = jax.random.split(init_rng)\n    self.model_state = self._create_train_state(subkey)\n</code></pre>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.restore_model_state","title":"<code>restore_model_state(filename, directory)</code>","text":"<p>Restore the model state from a file.</p>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.restore_model_state--parameters","title":"Parameters","text":"<p>filename : str         Name of the model state file directory : str         Path to the model state file.</p>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.restore_model_state--returns","title":"Returns","text":"<p>Updates the model state.</p> Source code in <code>swarmrl/networks/flax_network.py</code> <pre><code>def restore_model_state(self, filename, directory):\n    \"\"\"\n    Restore the model state from a file.\n\n    Parameters\n    ----------\n    filename : str\n            Name of the model state file\n    directory : str\n            Path to the model state file.\n\n    Returns\n    -------\n    Updates the model state.\n    \"\"\"\n\n    with open(directory + \"/\" + filename + \".pkl\", \"rb\") as f:\n        model_params, opt_state, opt_step, epoch = pickle.load(f)\n\n    self.model_state = self.model_state.replace(\n        params=model_params, opt_state=opt_state, step=opt_step\n    )\n    self.epoch_count = epoch\n</code></pre>"},{"location":"pages/api/swarmrl.networks.flax_network/#swarmrl.networks.flax_network.FlaxModel.update_model","title":"<code>update_model(grads)</code>","text":"<p>Train the model.</p> <p>See the parent class for a full doc-string.</p> Source code in <code>swarmrl/networks/flax_network.py</code> <pre><code>def update_model(self, grads):\n    \"\"\"\n    Train the model.\n\n    See the parent class for a full doc-string.\n    \"\"\"\n    # Logging for grads and pre-train model state\n    logger.debug(f\"{grads=}\")\n    logger.debug(f\"{self.model_state=}\")\n\n    if isinstance(self.optimizer, dict):\n        pass\n\n    else:\n        self.model_state = self.model_state.apply_gradients(grads=grads)\n\n    # Logging for post-train model state\n    logger.debug(f\"{self.model_state=}\")\n\n    self.epoch_count += 1\n</code></pre>"},{"location":"pages/api/swarmrl.networks.network/","title":"swarmrl.networks.network Module API Reference","text":"<p>Parent class for the networks.</p>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network","title":"<code>Network</code>","text":"<p>A parent class for the networks that will be used.</p> Source code in <code>swarmrl/networks/network.py</code> <pre><code>class Network:\n    \"\"\"\n    A parent class for the networks that will be used.\n    \"\"\"\n\n    def compute_action(self, observables: List[Colloid], explore_mode: bool = False):\n        \"\"\"\n        Compute and action from the action space.\n\n        This method computes an action on all colloids of the relevent type.\n\n        Parameters\n        ----------\n        observables : List[Colloid]\n                Colloids in the system for which the action should be computed.\n        explore_mode : bool\n                If true, an exploration vs exploitation function is called.\n\n        Returns\n        -------\n        action : int\n                An integer bounded between 0 and the number of output neurons\n                corresponding to the action chosen by the agent.\n        \"\"\"\n        raise NotImplementedError(\"Implemented in child class.\")\n\n    def __call__(self, params: FrozenDict, feature_vector: np.ndarray):\n        \"\"\"\n        Perform the forward pass on the model. This method is\n        used in the update. It uses a vmapped version of the\n        model.apply function.\n\n        Parameters\n        ----------\n        params : FrozenDict\n                Parameters of the model.\n        feature_vector : np.ndarray\n                Current state of the agent on which actions should be made.\n\n        Returns\n        -------\n\n        \"\"\"\n        raise NotImplementedError(\"Implemented in child class.\")\n\n    def export_model(self, filename: str = \"models\", directory: str = \"Models\"):\n        \"\"\"\n        Export the model state to a directory.\n\n        Parameters\n        ----------\n        filename : str (default=models)\n                Name of the file the models are saved in.\n        directory : str (default=Models)\n                Directory in which to save the models. If the directory is not\n                in the currently directory, it will be created.\n\n        \"\"\"\n        raise NotImplementedError(\"Implemented in child class\")\n\n    def restore_model_state(self, filename, directory):\n        \"\"\"\n        Restore the model state from a file.\n\n        Parameters\n        ----------\n        filename : str\n                Name of the model state file.\n        directory : str\n                Path to the model state file.\n\n        Returns\n        -------\n        Updates the model state.\n        \"\"\"\n        raise NotImplementedError(\"Implemented in child class\")\n\n    def update_model(\n        self,\n        grads,\n    ):\n        \"\"\"\n        Train the model.\n\n        For jax model grads are used to update a model state directly. This method\n        takes the grads and updates the params dict corresponding to the relevant\n        model.\n\n        Parameters\n        ----------\n        grads : dict\n                Dict of grads from a jax value_and_grad call.\n        \"\"\"\n        raise NotImplementedError(\"Implemented in child class.\")\n</code></pre>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network.__call__","title":"<code>__call__(params, feature_vector)</code>","text":"<p>Perform the forward pass on the model. This method is used in the update. It uses a vmapped version of the model.apply function.</p>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network.__call__--parameters","title":"Parameters","text":"<p>params : FrozenDict         Parameters of the model. feature_vector : np.ndarray         Current state of the agent on which actions should be made.</p>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network.__call__--returns","title":"Returns","text":"Source code in <code>swarmrl/networks/network.py</code> <pre><code>def __call__(self, params: FrozenDict, feature_vector: np.ndarray):\n    \"\"\"\n    Perform the forward pass on the model. This method is\n    used in the update. It uses a vmapped version of the\n    model.apply function.\n\n    Parameters\n    ----------\n    params : FrozenDict\n            Parameters of the model.\n    feature_vector : np.ndarray\n            Current state of the agent on which actions should be made.\n\n    Returns\n    -------\n\n    \"\"\"\n    raise NotImplementedError(\"Implemented in child class.\")\n</code></pre>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network.compute_action","title":"<code>compute_action(observables, explore_mode=False)</code>","text":"<p>Compute and action from the action space.</p> <p>This method computes an action on all colloids of the relevent type.</p>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network.compute_action--parameters","title":"Parameters","text":"<p>observables : List[Colloid]         Colloids in the system for which the action should be computed. explore_mode : bool         If true, an exploration vs exploitation function is called.</p>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network.compute_action--returns","title":"Returns","text":"<p>action : int         An integer bounded between 0 and the number of output neurons         corresponding to the action chosen by the agent.</p> Source code in <code>swarmrl/networks/network.py</code> <pre><code>def compute_action(self, observables: List[Colloid], explore_mode: bool = False):\n    \"\"\"\n    Compute and action from the action space.\n\n    This method computes an action on all colloids of the relevent type.\n\n    Parameters\n    ----------\n    observables : List[Colloid]\n            Colloids in the system for which the action should be computed.\n    explore_mode : bool\n            If true, an exploration vs exploitation function is called.\n\n    Returns\n    -------\n    action : int\n            An integer bounded between 0 and the number of output neurons\n            corresponding to the action chosen by the agent.\n    \"\"\"\n    raise NotImplementedError(\"Implemented in child class.\")\n</code></pre>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network.export_model","title":"<code>export_model(filename='models', directory='Models')</code>","text":"<p>Export the model state to a directory.</p>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network.export_model--parameters","title":"Parameters","text":"<p>filename : str (default=models)         Name of the file the models are saved in. directory : str (default=Models)         Directory in which to save the models. If the directory is not         in the currently directory, it will be created.</p> Source code in <code>swarmrl/networks/network.py</code> <pre><code>def export_model(self, filename: str = \"models\", directory: str = \"Models\"):\n    \"\"\"\n    Export the model state to a directory.\n\n    Parameters\n    ----------\n    filename : str (default=models)\n            Name of the file the models are saved in.\n    directory : str (default=Models)\n            Directory in which to save the models. If the directory is not\n            in the currently directory, it will be created.\n\n    \"\"\"\n    raise NotImplementedError(\"Implemented in child class\")\n</code></pre>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network.restore_model_state","title":"<code>restore_model_state(filename, directory)</code>","text":"<p>Restore the model state from a file.</p>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network.restore_model_state--parameters","title":"Parameters","text":"<p>filename : str         Name of the model state file. directory : str         Path to the model state file.</p>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network.restore_model_state--returns","title":"Returns","text":"<p>Updates the model state.</p> Source code in <code>swarmrl/networks/network.py</code> <pre><code>def restore_model_state(self, filename, directory):\n    \"\"\"\n    Restore the model state from a file.\n\n    Parameters\n    ----------\n    filename : str\n            Name of the model state file.\n    directory : str\n            Path to the model state file.\n\n    Returns\n    -------\n    Updates the model state.\n    \"\"\"\n    raise NotImplementedError(\"Implemented in child class\")\n</code></pre>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network.update_model","title":"<code>update_model(grads)</code>","text":"<p>Train the model.</p> <p>For jax model grads are used to update a model state directly. This method takes the grads and updates the params dict corresponding to the relevant model.</p>"},{"location":"pages/api/swarmrl.networks.network/#swarmrl.networks.network.Network.update_model--parameters","title":"Parameters","text":"<p>grads : dict         Dict of grads from a jax value_and_grad call.</p> Source code in <code>swarmrl/networks/network.py</code> <pre><code>def update_model(\n    self,\n    grads,\n):\n    \"\"\"\n    Train the model.\n\n    For jax model grads are used to update a model state directly. This method\n    takes the grads and updates the params dict corresponding to the relevant\n    model.\n\n    Parameters\n    ----------\n    grads : dict\n            Dict of grads from a jax value_and_grad call.\n    \"\"\"\n    raise NotImplementedError(\"Implemented in child class.\")\n</code></pre>"},{"location":"pages/api/swarmrl.observables.concentration_field/","title":"swarmrl.observables.concentration_field Module API Reference","text":"<p>Historical position observable computer.</p>"},{"location":"pages/api/swarmrl.observables.concentration_field/#swarmrl.observables.concentration_field--notes","title":"Notes","text":"<p>Observable for sensing changes in some field value, or, the gradient.</p>"},{"location":"pages/api/swarmrl.observables.concentration_field/#swarmrl.observables.concentration_field.ConcentrationField","title":"<code>ConcentrationField</code>","text":"<p>             Bases: <code>Observable</code>, <code>ABC</code></p> <p>Position in box observable.</p>"},{"location":"pages/api/swarmrl.observables.concentration_field/#swarmrl.observables.concentration_field.ConcentrationField--attributes","title":"Attributes","text":"<p>historic_positions : dict         A dictionary of past positions of the colloid to be used in the gradient         computation.</p> Source code in <code>swarmrl/observables/concentration_field.py</code> <pre><code>class ConcentrationField(Observable, ABC):\n    \"\"\"\n    Position in box observable.\n\n    Attributes\n    ----------\n    historic_positions : dict\n            A dictionary of past positions of the colloid to be used in the gradient\n            computation.\n    \"\"\"\n\n    def __init__(\n        self,\n        source: np.ndarray,\n        decay_fn: callable,\n        box_length: np.ndarray,\n        scale_factor: int = 100,\n        particle_type: int = 0,\n    ):\n        \"\"\"\n        Constructor for the observable.\n\n        Parameters\n        ----------\n        source : np.ndarray\n                Source of the field.\n        decay_fn : callable\n                Decay function of the field.\n        box_size : np.ndarray\n                Array for scaling of the distances.\n        scale_factor : int (default=100)\n                Scaling factor for the observable.\n        particle_type : int (default=0)\n                Particle type to compute the observable for.\n        \"\"\"\n        super().__init__(particle_type=particle_type)\n\n        self.source = source / box_length\n        self.decay_fn = decay_fn\n        self._historic_positions = {}\n        self.box_length = box_length\n        self.scale_factor = scale_factor\n        self._observable_shape = (3,)\n\n    def initialize(self, colloids: List[Colloid]):\n        \"\"\"\n        Initialize the observable with starting positions of the colloids.\n\n        Parameters\n        ----------\n        colloids : List[Colloid]\n                List of colloids with which to initialize the observable.\n\n        Returns\n        -------\n        Updates the class state.\n        \"\"\"\n        for item in colloids:\n            index = onp.copy(item.id)\n            position = onp.copy(item.pos) / self.box_length\n            self._historic_positions[str(index)] = position\n\n    def compute_single_observable(self, index: int, colloids: List[Colloid]) -&gt; float:\n        \"\"\"\n        Compute the observable for a single colloid.\n\n        Parameters\n        ----------\n        index : int\n                Index of the colloid to compute the observable for.\n        colloids : List[Colloid]\n                List of colloids in the system.\n        \"\"\"\n        reference_colloid = colloids[index]\n        position = onp.copy(reference_colloid.pos) / self.box_length\n        index = onp.copy(reference_colloid.id)\n        previous_position = self._historic_positions[str(index)]\n\n        # Update historic position.\n        self._historic_positions[str(index)] = position\n\n        current_distance = np.linalg.norm(self.source - position)\n        historic_distance = np.linalg.norm(self.source - previous_position)\n\n        delta = self.decay_fn(current_distance) - self.decay_fn(historic_distance)\n\n        return self.scale_factor * delta\n\n    def compute_observable(self, colloids: List[Colloid]):\n        \"\"\"\n        Compute the position of the colloid.\n\n        Parameters\n        ----------\n        colloids : List[Colloid] (n_colloids, )\n                List of all colloids in the system.\n\n        Returns\n        -------\n        observables : List[float] (n_colloids, dimension)\n                List of observables, one for each colloid. In this case,\n                current field value minus to previous field value.\n        \"\"\"\n        reference_ids = self.get_colloid_indices(colloids)\n\n        if self._historic_positions == {}:\n            msg = (\n                f\"{type(self).__name__} requires initialization. Please set the \"\n                \"initialize attribute of the gym to true and try again.\"\n            )\n            raise ValueError(msg)\n\n        observables = [\n            self.compute_single_observable(index, colloids) for index in reference_ids\n        ]\n\n        return np.array(observables).reshape(-1, 1)\n</code></pre>"},{"location":"pages/api/swarmrl.observables.concentration_field/#swarmrl.observables.concentration_field.ConcentrationField.__init__","title":"<code>__init__(source, decay_fn, box_length, scale_factor=100, particle_type=0)</code>","text":"<p>Constructor for the observable.</p>"},{"location":"pages/api/swarmrl.observables.concentration_field/#swarmrl.observables.concentration_field.ConcentrationField.__init__--parameters","title":"Parameters","text":"<p>source : np.ndarray         Source of the field. decay_fn : callable         Decay function of the field. box_size : np.ndarray         Array for scaling of the distances. scale_factor : int (default=100)         Scaling factor for the observable. particle_type : int (default=0)         Particle type to compute the observable for.</p> Source code in <code>swarmrl/observables/concentration_field.py</code> <pre><code>def __init__(\n    self,\n    source: np.ndarray,\n    decay_fn: callable,\n    box_length: np.ndarray,\n    scale_factor: int = 100,\n    particle_type: int = 0,\n):\n    \"\"\"\n    Constructor for the observable.\n\n    Parameters\n    ----------\n    source : np.ndarray\n            Source of the field.\n    decay_fn : callable\n            Decay function of the field.\n    box_size : np.ndarray\n            Array for scaling of the distances.\n    scale_factor : int (default=100)\n            Scaling factor for the observable.\n    particle_type : int (default=0)\n            Particle type to compute the observable for.\n    \"\"\"\n    super().__init__(particle_type=particle_type)\n\n    self.source = source / box_length\n    self.decay_fn = decay_fn\n    self._historic_positions = {}\n    self.box_length = box_length\n    self.scale_factor = scale_factor\n    self._observable_shape = (3,)\n</code></pre>"},{"location":"pages/api/swarmrl.observables.concentration_field/#swarmrl.observables.concentration_field.ConcentrationField.compute_observable","title":"<code>compute_observable(colloids)</code>","text":"<p>Compute the position of the colloid.</p>"},{"location":"pages/api/swarmrl.observables.concentration_field/#swarmrl.observables.concentration_field.ConcentrationField.compute_observable--parameters","title":"Parameters","text":"<p>colloids : List[Colloid] (n_colloids, )         List of all colloids in the system.</p>"},{"location":"pages/api/swarmrl.observables.concentration_field/#swarmrl.observables.concentration_field.ConcentrationField.compute_observable--returns","title":"Returns","text":"<p>observables : List[float] (n_colloids, dimension)         List of observables, one for each colloid. In this case,         current field value minus to previous field value.</p> Source code in <code>swarmrl/observables/concentration_field.py</code> <pre><code>def compute_observable(self, colloids: List[Colloid]):\n    \"\"\"\n    Compute the position of the colloid.\n\n    Parameters\n    ----------\n    colloids : List[Colloid] (n_colloids, )\n            List of all colloids in the system.\n\n    Returns\n    -------\n    observables : List[float] (n_colloids, dimension)\n            List of observables, one for each colloid. In this case,\n            current field value minus to previous field value.\n    \"\"\"\n    reference_ids = self.get_colloid_indices(colloids)\n\n    if self._historic_positions == {}:\n        msg = (\n            f\"{type(self).__name__} requires initialization. Please set the \"\n            \"initialize attribute of the gym to true and try again.\"\n        )\n        raise ValueError(msg)\n\n    observables = [\n        self.compute_single_observable(index, colloids) for index in reference_ids\n    ]\n\n    return np.array(observables).reshape(-1, 1)\n</code></pre>"},{"location":"pages/api/swarmrl.observables.concentration_field/#swarmrl.observables.concentration_field.ConcentrationField.compute_single_observable","title":"<code>compute_single_observable(index, colloids)</code>","text":"<p>Compute the observable for a single colloid.</p>"},{"location":"pages/api/swarmrl.observables.concentration_field/#swarmrl.observables.concentration_field.ConcentrationField.compute_single_observable--parameters","title":"Parameters","text":"<p>index : int         Index of the colloid to compute the observable for. colloids : List[Colloid]         List of colloids in the system.</p> Source code in <code>swarmrl/observables/concentration_field.py</code> <pre><code>def compute_single_observable(self, index: int, colloids: List[Colloid]) -&gt; float:\n    \"\"\"\n    Compute the observable for a single colloid.\n\n    Parameters\n    ----------\n    index : int\n            Index of the colloid to compute the observable for.\n    colloids : List[Colloid]\n            List of colloids in the system.\n    \"\"\"\n    reference_colloid = colloids[index]\n    position = onp.copy(reference_colloid.pos) / self.box_length\n    index = onp.copy(reference_colloid.id)\n    previous_position = self._historic_positions[str(index)]\n\n    # Update historic position.\n    self._historic_positions[str(index)] = position\n\n    current_distance = np.linalg.norm(self.source - position)\n    historic_distance = np.linalg.norm(self.source - previous_position)\n\n    delta = self.decay_fn(current_distance) - self.decay_fn(historic_distance)\n\n    return self.scale_factor * delta\n</code></pre>"},{"location":"pages/api/swarmrl.observables.concentration_field/#swarmrl.observables.concentration_field.ConcentrationField.initialize","title":"<code>initialize(colloids)</code>","text":"<p>Initialize the observable with starting positions of the colloids.</p>"},{"location":"pages/api/swarmrl.observables.concentration_field/#swarmrl.observables.concentration_field.ConcentrationField.initialize--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids with which to initialize the observable.</p>"},{"location":"pages/api/swarmrl.observables.concentration_field/#swarmrl.observables.concentration_field.ConcentrationField.initialize--returns","title":"Returns","text":"<p>Updates the class state.</p> Source code in <code>swarmrl/observables/concentration_field.py</code> <pre><code>def initialize(self, colloids: List[Colloid]):\n    \"\"\"\n    Initialize the observable with starting positions of the colloids.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids with which to initialize the observable.\n\n    Returns\n    -------\n    Updates the class state.\n    \"\"\"\n    for item in colloids:\n        index = onp.copy(item.id)\n        position = onp.copy(item.pos) / self.box_length\n        self._historic_positions[str(index)] = position\n</code></pre>"},{"location":"pages/api/swarmrl.observables.director/","title":"swarmrl.observables.director Module API Reference","text":"<p>Give position and angle.</p>"},{"location":"pages/api/swarmrl.observables.director/#swarmrl.observables.director.Director","title":"<code>Director</code>","text":"<p>             Bases: <code>Observable</code>, <code>ABC</code></p> <p>Position in box observable.</p> Source code in <code>swarmrl/observables/director.py</code> <pre><code>class Director(Observable, ABC):\n    \"\"\"\n    Position in box observable.\n    \"\"\"\n\n    def __init__(self, particle_type: int = 0):\n        \"\"\"\n        Constructor for the observable.\n\n        Parameters\n        ----------\n        box_length : np.ndarray\n                Length of the box with which to normalize.\n        \"\"\"\n        super().__init__(particle_type=particle_type)\n\n    def compute_single_observable(self, index: int, colloids: list):\n        \"\"\"\n        Compute the position of the colloid.\n\n        Parameters\n        ----------\n        index : int\n                Index of the colloid for which the observable should be computed.\n        other_colloids\n                Other colloids in the system.\n        \"\"\"\n        colloid = colloids[index]\n\n        director = onp.copy(colloid.director)\n\n        return director\n\n    def compute_observable(self, colloids: List[Colloid]):\n        \"\"\"\n        Compute the current state observable for all colloids.\n\n        Parameters\n        ----------\n        colloids : List[Colloid] (n_colloids, )\n                List of all colloids in the system.\n        \"\"\"\n        indices = self.get_colloid_indices(colloids)\n\n        return [self.compute_single_observable(i, colloids) for i in indices]\n</code></pre>"},{"location":"pages/api/swarmrl.observables.director/#swarmrl.observables.director.Director.__init__","title":"<code>__init__(particle_type=0)</code>","text":"<p>Constructor for the observable.</p>"},{"location":"pages/api/swarmrl.observables.director/#swarmrl.observables.director.Director.__init__--parameters","title":"Parameters","text":"<p>box_length : np.ndarray         Length of the box with which to normalize.</p> Source code in <code>swarmrl/observables/director.py</code> <pre><code>def __init__(self, particle_type: int = 0):\n    \"\"\"\n    Constructor for the observable.\n\n    Parameters\n    ----------\n    box_length : np.ndarray\n            Length of the box with which to normalize.\n    \"\"\"\n    super().__init__(particle_type=particle_type)\n</code></pre>"},{"location":"pages/api/swarmrl.observables.director/#swarmrl.observables.director.Director.compute_observable","title":"<code>compute_observable(colloids)</code>","text":"<p>Compute the current state observable for all colloids.</p>"},{"location":"pages/api/swarmrl.observables.director/#swarmrl.observables.director.Director.compute_observable--parameters","title":"Parameters","text":"<p>colloids : List[Colloid] (n_colloids, )         List of all colloids in the system.</p> Source code in <code>swarmrl/observables/director.py</code> <pre><code>def compute_observable(self, colloids: List[Colloid]):\n    \"\"\"\n    Compute the current state observable for all colloids.\n\n    Parameters\n    ----------\n    colloids : List[Colloid] (n_colloids, )\n            List of all colloids in the system.\n    \"\"\"\n    indices = self.get_colloid_indices(colloids)\n\n    return [self.compute_single_observable(i, colloids) for i in indices]\n</code></pre>"},{"location":"pages/api/swarmrl.observables.director/#swarmrl.observables.director.Director.compute_single_observable","title":"<code>compute_single_observable(index, colloids)</code>","text":"<p>Compute the position of the colloid.</p>"},{"location":"pages/api/swarmrl.observables.director/#swarmrl.observables.director.Director.compute_single_observable--parameters","title":"Parameters","text":"<p>index : int         Index of the colloid for which the observable should be computed. other_colloids         Other colloids in the system.</p> Source code in <code>swarmrl/observables/director.py</code> <pre><code>def compute_single_observable(self, index: int, colloids: list):\n    \"\"\"\n    Compute the position of the colloid.\n\n    Parameters\n    ----------\n    index : int\n            Index of the colloid for which the observable should be computed.\n    other_colloids\n            Other colloids in the system.\n    \"\"\"\n    colloid = colloids[index]\n\n    director = onp.copy(colloid.director)\n\n    return director\n</code></pre>"},{"location":"pages/api/swarmrl.observables.multi_sensing/","title":"swarmrl.observables.multi_sensing Module API Reference","text":"<p>Class for an observable which computes several observables.</p>"},{"location":"pages/api/swarmrl.observables.multi_sensing/#swarmrl.observables.multi_sensing.MultiSensing","title":"<code>MultiSensing</code>","text":"<p>             Bases: <code>Observable</code>, <code>ABC</code></p> <p>Takes several observables and returns them as a list of observables.</p> Source code in <code>swarmrl/observables/multi_sensing.py</code> <pre><code>class MultiSensing(Observable, ABC):\n    \"\"\"\n    Takes several observables and returns them as a list of observables.\n    \"\"\"\n\n    def __init__(\n        self,\n        observables: List[Observable],\n    ):\n        \"\"\"\n        Constructor for the observable.\n\n        In this observables, the order with which the observables are\n        passed to the constructor is the order in which they are\n        concatenated.\n\n        Parameters\n        ----------\n        Observables : List[Observable]\n                List of observables.\n        \"\"\"\n        self.observables = observables\n\n    def initialize(self, colloids: List[Colloid]):\n        \"\"\"\n        Initialize the observables as needed.\n\n        Parameters\n        ----------\n        colloids : List[Colloid]\n                List of colloids with which to initialize the observable.\n\n        Returns\n        -------\n        Some of the observables passed to the constructor might need to be\n        initialized with the positions of the colloids. This method does\n        that.\n        \"\"\"\n        for item in self.observables:\n            item.initialize(colloids)\n\n    def compute_observable(self, colloids: List[Colloid]) -&gt; List:\n        \"\"\"\n        Computes all observables and returns them in a concatenated list.\n\n        Parameters\n        ----------\n        colloids : list of all colloids.\n\n        Returns\n        -------\n        List of observables, computed in the order that they were given\n        at initialization.\n\n        Notes\n        -----\n        This may not work well for observables that return different\n        shapes as they must be lists. We should consider a different\n        return type such as a dict. This however needs to be tested\n        on neural networks so the slower lists will work for now.\n        \"\"\"\n        # Get the observables for each colloid.\n        unshaped_observable = []  # shape (n_obs, n_colloids, ...)\n        for item in self.observables:\n            unshaped_observable.append(item.compute_observable(colloids))\n\n        n_colloids = len(unshaped_observable[0])\n\n        # Reshape the observables to be (n_colloids, n_observables, )\n        observable = [[] for _ in range(n_colloids)]\n        for i, item in enumerate(unshaped_observable):\n            for j, colloid in enumerate(item):\n                observable[j].append(colloid)\n\n        return onp.array(observable)\n</code></pre>"},{"location":"pages/api/swarmrl.observables.multi_sensing/#swarmrl.observables.multi_sensing.MultiSensing.__init__","title":"<code>__init__(observables)</code>","text":"<p>Constructor for the observable.</p> <p>In this observables, the order with which the observables are passed to the constructor is the order in which they are concatenated.</p>"},{"location":"pages/api/swarmrl.observables.multi_sensing/#swarmrl.observables.multi_sensing.MultiSensing.__init__--parameters","title":"Parameters","text":"<p>Observables : List[Observable]         List of observables.</p> Source code in <code>swarmrl/observables/multi_sensing.py</code> <pre><code>def __init__(\n    self,\n    observables: List[Observable],\n):\n    \"\"\"\n    Constructor for the observable.\n\n    In this observables, the order with which the observables are\n    passed to the constructor is the order in which they are\n    concatenated.\n\n    Parameters\n    ----------\n    Observables : List[Observable]\n            List of observables.\n    \"\"\"\n    self.observables = observables\n</code></pre>"},{"location":"pages/api/swarmrl.observables.multi_sensing/#swarmrl.observables.multi_sensing.MultiSensing.compute_observable","title":"<code>compute_observable(colloids)</code>","text":"<p>Computes all observables and returns them in a concatenated list.</p>"},{"location":"pages/api/swarmrl.observables.multi_sensing/#swarmrl.observables.multi_sensing.MultiSensing.compute_observable--parameters","title":"Parameters","text":"<p>colloids : list of all colloids.</p>"},{"location":"pages/api/swarmrl.observables.multi_sensing/#swarmrl.observables.multi_sensing.MultiSensing.compute_observable--returns","title":"Returns","text":"<p>List of observables, computed in the order that they were given at initialization.</p>"},{"location":"pages/api/swarmrl.observables.multi_sensing/#swarmrl.observables.multi_sensing.MultiSensing.compute_observable--notes","title":"Notes","text":"<p>This may not work well for observables that return different shapes as they must be lists. We should consider a different return type such as a dict. This however needs to be tested on neural networks so the slower lists will work for now.</p> Source code in <code>swarmrl/observables/multi_sensing.py</code> <pre><code>def compute_observable(self, colloids: List[Colloid]) -&gt; List:\n    \"\"\"\n    Computes all observables and returns them in a concatenated list.\n\n    Parameters\n    ----------\n    colloids : list of all colloids.\n\n    Returns\n    -------\n    List of observables, computed in the order that they were given\n    at initialization.\n\n    Notes\n    -----\n    This may not work well for observables that return different\n    shapes as they must be lists. We should consider a different\n    return type such as a dict. This however needs to be tested\n    on neural networks so the slower lists will work for now.\n    \"\"\"\n    # Get the observables for each colloid.\n    unshaped_observable = []  # shape (n_obs, n_colloids, ...)\n    for item in self.observables:\n        unshaped_observable.append(item.compute_observable(colloids))\n\n    n_colloids = len(unshaped_observable[0])\n\n    # Reshape the observables to be (n_colloids, n_observables, )\n    observable = [[] for _ in range(n_colloids)]\n    for i, item in enumerate(unshaped_observable):\n        for j, colloid in enumerate(item):\n            observable[j].append(colloid)\n\n    return onp.array(observable)\n</code></pre>"},{"location":"pages/api/swarmrl.observables.multi_sensing/#swarmrl.observables.multi_sensing.MultiSensing.initialize","title":"<code>initialize(colloids)</code>","text":"<p>Initialize the observables as needed.</p>"},{"location":"pages/api/swarmrl.observables.multi_sensing/#swarmrl.observables.multi_sensing.MultiSensing.initialize--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids with which to initialize the observable.</p>"},{"location":"pages/api/swarmrl.observables.multi_sensing/#swarmrl.observables.multi_sensing.MultiSensing.initialize--returns","title":"Returns","text":"<p>Some of the observables passed to the constructor might need to be initialized with the positions of the colloids. This method does that.</p> Source code in <code>swarmrl/observables/multi_sensing.py</code> <pre><code>def initialize(self, colloids: List[Colloid]):\n    \"\"\"\n    Initialize the observables as needed.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids with which to initialize the observable.\n\n    Returns\n    -------\n    Some of the observables passed to the constructor might need to be\n    initialized with the positions of the colloids. This method does\n    that.\n    \"\"\"\n    for item in self.observables:\n        item.initialize(colloids)\n</code></pre>"},{"location":"pages/api/swarmrl.observables.observable/","title":"swarmrl.observables.observable Module API Reference","text":"<p>Parent class for the observable.</p>"},{"location":"pages/api/swarmrl.observables.observable/#swarmrl.observables.observable.Observable","title":"<code>Observable</code>","text":"<p>Parent class for observables.</p> <p>Observables act as inputs to the neural networks.</p> Source code in <code>swarmrl/observables/observable.py</code> <pre><code>class Observable:\n    \"\"\"\n    Parent class for observables.\n\n    Observables act as inputs to the neural networks.\n    \"\"\"\n\n    def __init__(self, particle_type: int):\n        \"\"\"\n        Constructor for the observable.\n        \"\"\"\n        self._shape = None\n        self.particle_type: int = particle_type\n\n    def initialize(self, colloids: List[Colloid]):\n        \"\"\"\n        Initialize the observable with starting positions of the colloids.\n\n        The parent method will just pass. This is because some observables\n        might not need to be initialized. Those that do need to be initialized\n        will override this method.\n\n        Parameters\n        ----------\n        colloids : List[Colloid]\n                List of colloids with which to initialize the observable.\n\n        Returns\n        -------\n        Updates the class state.\n        \"\"\"\n        pass\n\n    def get_colloid_indices(self, colloids: List[Colloid], p_type: int = None):\n        \"\"\"\n        Get the indices of the colloids in the observable of a specific type.\n\n        Parameters\n        ----------\n        colloids : List[Colloid]\n                List of colloids from which to get the indices.\n        p_type : int (default=None)\n                Type of the colloids to get the indices for. If None, the\n                particle_type attribute of the class is used.\n\n\n        Returns\n        -------\n        indices : List[int]\n                List of indices for the colloids of a particular type.\n        \"\"\"\n        if p_type is None:\n            p_type = self.particle_type\n\n        indices = []\n        for i, colloid in enumerate(colloids):\n            if colloid.type == p_type:\n                indices.append(i)\n\n        return indices\n\n    def compute_observable(self, colloids: List[Colloid]) -&gt; List:\n        \"\"\"\n        Compute the current state observable for all colloids.\n\n        Parameters\n        ----------\n        colloids : List[Colloid] (n_colloids, )\n                List of all colloids in the system.\n\n        Returns\n        -------\n        observables : List[np.ndarray] (n_colloids, dimension)\n                List of observables, one for each colloid.\n\n        \"\"\"\n        raise NotImplementedError(\"Implemented in child class.\")\n\n    @property\n    def observable_shape(self):\n        \"\"\"\n        Unchangeable shape of the observable.\n        Returns\n        -------\n\n        \"\"\"\n        return self._shape\n</code></pre>"},{"location":"pages/api/swarmrl.observables.observable/#swarmrl.observables.observable.Observable.observable_shape","title":"<code>observable_shape</code>  <code>property</code>","text":"<p>Unchangeable shape of the observable. Returns</p>"},{"location":"pages/api/swarmrl.observables.observable/#swarmrl.observables.observable.Observable.__init__","title":"<code>__init__(particle_type)</code>","text":"<p>Constructor for the observable.</p> Source code in <code>swarmrl/observables/observable.py</code> <pre><code>def __init__(self, particle_type: int):\n    \"\"\"\n    Constructor for the observable.\n    \"\"\"\n    self._shape = None\n    self.particle_type: int = particle_type\n</code></pre>"},{"location":"pages/api/swarmrl.observables.observable/#swarmrl.observables.observable.Observable.compute_observable","title":"<code>compute_observable(colloids)</code>","text":"<p>Compute the current state observable for all colloids.</p>"},{"location":"pages/api/swarmrl.observables.observable/#swarmrl.observables.observable.Observable.compute_observable--parameters","title":"Parameters","text":"<p>colloids : List[Colloid] (n_colloids, )         List of all colloids in the system.</p>"},{"location":"pages/api/swarmrl.observables.observable/#swarmrl.observables.observable.Observable.compute_observable--returns","title":"Returns","text":"<p>observables : List[np.ndarray] (n_colloids, dimension)         List of observables, one for each colloid.</p> Source code in <code>swarmrl/observables/observable.py</code> <pre><code>def compute_observable(self, colloids: List[Colloid]) -&gt; List:\n    \"\"\"\n    Compute the current state observable for all colloids.\n\n    Parameters\n    ----------\n    colloids : List[Colloid] (n_colloids, )\n            List of all colloids in the system.\n\n    Returns\n    -------\n    observables : List[np.ndarray] (n_colloids, dimension)\n            List of observables, one for each colloid.\n\n    \"\"\"\n    raise NotImplementedError(\"Implemented in child class.\")\n</code></pre>"},{"location":"pages/api/swarmrl.observables.observable/#swarmrl.observables.observable.Observable.get_colloid_indices","title":"<code>get_colloid_indices(colloids, p_type=None)</code>","text":"<p>Get the indices of the colloids in the observable of a specific type.</p>"},{"location":"pages/api/swarmrl.observables.observable/#swarmrl.observables.observable.Observable.get_colloid_indices--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids from which to get the indices. p_type : int (default=None)         Type of the colloids to get the indices for. If None, the         particle_type attribute of the class is used.</p>"},{"location":"pages/api/swarmrl.observables.observable/#swarmrl.observables.observable.Observable.get_colloid_indices--returns","title":"Returns","text":"<p>indices : List[int]         List of indices for the colloids of a particular type.</p> Source code in <code>swarmrl/observables/observable.py</code> <pre><code>def get_colloid_indices(self, colloids: List[Colloid], p_type: int = None):\n    \"\"\"\n    Get the indices of the colloids in the observable of a specific type.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids from which to get the indices.\n    p_type : int (default=None)\n            Type of the colloids to get the indices for. If None, the\n            particle_type attribute of the class is used.\n\n\n    Returns\n    -------\n    indices : List[int]\n            List of indices for the colloids of a particular type.\n    \"\"\"\n    if p_type is None:\n        p_type = self.particle_type\n\n    indices = []\n    for i, colloid in enumerate(colloids):\n        if colloid.type == p_type:\n            indices.append(i)\n\n    return indices\n</code></pre>"},{"location":"pages/api/swarmrl.observables.observable/#swarmrl.observables.observable.Observable.initialize","title":"<code>initialize(colloids)</code>","text":"<p>Initialize the observable with starting positions of the colloids.</p> <p>The parent method will just pass. This is because some observables might not need to be initialized. Those that do need to be initialized will override this method.</p>"},{"location":"pages/api/swarmrl.observables.observable/#swarmrl.observables.observable.Observable.initialize--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids with which to initialize the observable.</p>"},{"location":"pages/api/swarmrl.observables.observable/#swarmrl.observables.observable.Observable.initialize--returns","title":"Returns","text":"<p>Updates the class state.</p> Source code in <code>swarmrl/observables/observable.py</code> <pre><code>def initialize(self, colloids: List[Colloid]):\n    \"\"\"\n    Initialize the observable with starting positions of the colloids.\n\n    The parent method will just pass. This is because some observables\n    might not need to be initialized. Those that do need to be initialized\n    will override this method.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids with which to initialize the observable.\n\n    Returns\n    -------\n    Updates the class state.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"pages/api/swarmrl.observables.particle_sensing/","title":"swarmrl.observables.particle_sensing Module API Reference","text":"<p>Observable for particle sensing.</p>"},{"location":"pages/api/swarmrl.observables.particle_sensing/#swarmrl.observables.particle_sensing.ParticleSensing","title":"<code>ParticleSensing</code>","text":"<p>             Bases: <code>Observable</code></p> <p>Class for particle sensing.</p> Source code in <code>swarmrl/observables/particle_sensing.py</code> <pre><code>class ParticleSensing(Observable):\n    \"\"\"\n    Class for particle sensing.\n    \"\"\"\n\n    def __init__(\n        self,\n        decay_fn: callable,\n        box_length: np.ndarray,\n        sensing_type: int = 0,\n        scale_factor: int = 100,\n        particle_type: int = 0,\n    ):\n        \"\"\"\n        Constructor for the observable.\n\n        Parameters\n        ----------\n        decay_fn : callable\n                Decay function of the field.\n        box_size : np.ndarray\n                Array for scaling of the distances.\n        sensing_type : int (default=0)\n                Type of particle to sense.\n        scale_factor : int (default=100)\n                Scaling factor for the observable.\n        particle_type : int (default=0)\n                Particle type to compute the observable for.\n        \"\"\"\n        super().__init__(particle_type=particle_type)\n\n        self.decay_fn = decay_fn\n        self.box_length = box_length\n        self.sensing_type = sensing_type\n        self.scale_factor = scale_factor\n\n        self.historical_field = {}\n\n        self.observable_fn = jax.vmap(\n            self.compute_single_observable,\n            in_axes=(0, 0, None, 0),\n            # out_axes=()\n        )\n\n    def initialize(self, colloids: List[Colloid]):\n        \"\"\"\n        Initialize the observable with starting positions of the colloids.\n\n        Parameters\n        ----------\n        colloids : List[Colloid]\n                List of colloids with which to initialize the observable.\n\n        Returns\n        -------\n        Updates the class state.\n        \"\"\"\n        reference_ids = self.get_colloid_indices(colloids)\n        historic_values = np.zeros(len(reference_ids))\n\n        positions = []\n        indices = []\n        for index in reference_ids:\n            indices.append(colloids[index].id)\n            positions.append(colloids[index].pos)\n\n        sensed_colloids = np.array(\n            [colloid.pos for colloid in colloids if colloid.type == self.sensing_type]\n        )\n\n        out_indices, _, field_values = self.observable_fn(\n            np.array(indices), np.array(positions), sensed_colloids, historic_values\n        )\n\n        for index, value in zip(out_indices, onp.array(field_values)):\n            self.historical_field[str(index)] = value\n\n    def compute_single_observable(\n        self,\n        index: int,\n        reference_position: np.ndarray,\n        test_positions: np.ndarray,\n        historic_value: float,\n    ) -&gt; tuple:\n        \"\"\"\n        Compute the observable for a single colloid.\n\n        Parameters\n        ----------\n        index : int\n                Index of the colloid to compute the observable for.\n        reference_position : np.ndarray (3,)\n                Position of the reference colloid.\n        test_positions : np.ndarray (n_colloids, 3)\n                Positions of the test colloids.\n        historic_value : float\n                Historic value of the observable.\n\n        Returns\n        -------\n        tuple (index, observable_value)\n        index : int\n                Index of the colloid to compute the observable for.\n        observable_value : float\n                Value of the observable.\n        \"\"\"\n        distances = np.linalg.norm(\n            (test_positions - reference_position) / self.box_length, axis=-1\n        )\n        indices = np.asarray(np.nonzero(distances, size=distances.shape[0] - 1))\n        distances = np.take(distances, indices, axis=0)\n        # Compute field value\n        field_value = self.decay_fn(distances).sum()\n        return index, field_value - historic_value, field_value\n\n    def compute_observable(self, colloids: List[Colloid]):\n        \"\"\"\n        Compute the position of the colloid.\n\n        Parameters\n        ----------\n        colloids : List[Colloid] (n_colloids, )\n                List of all colloids in the system.\n\n        Returns\n        -------\n        observables : List[float] (n_colloids, dimension)\n                List of observables, one for each colloid. In this case,\n                current field value minus to previous field value.\n        \"\"\"\n        if self.historical_field == {}:\n            msg = (\n                f\"{type(self).__name__} requires initialization. Please set the \"\n                \"initialize attribute of the gym to true and try again.\"\n            )\n            raise ValueError(msg)\n\n        reference_ids = self.get_colloid_indices(colloids)\n        positions = []\n        indices = []\n        historic_values = []\n        for index in reference_ids:\n            indices.append(colloids[index].id)\n            positions.append(colloids[index].pos)\n            historic_values.append(self.historical_field[str(colloids[index].id)])\n\n        test_points = np.array(\n            [colloid.pos for colloid in colloids if colloid.type == self.sensing_type]\n        )\n\n        out_indices, delta_values, field_values = self.observable_fn(\n            np.array(indices),\n            np.array(positions),\n            test_points,\n            np.array(historic_values),\n        )\n\n        for index, value in zip(out_indices, onp.array(field_values)):\n            self.historical_field[str(index)] = value\n\n        return self.scale_factor * delta_values.reshape(-1, 1)\n</code></pre>"},{"location":"pages/api/swarmrl.observables.particle_sensing/#swarmrl.observables.particle_sensing.ParticleSensing.__init__","title":"<code>__init__(decay_fn, box_length, sensing_type=0, scale_factor=100, particle_type=0)</code>","text":"<p>Constructor for the observable.</p>"},{"location":"pages/api/swarmrl.observables.particle_sensing/#swarmrl.observables.particle_sensing.ParticleSensing.__init__--parameters","title":"Parameters","text":"<p>decay_fn : callable         Decay function of the field. box_size : np.ndarray         Array for scaling of the distances. sensing_type : int (default=0)         Type of particle to sense. scale_factor : int (default=100)         Scaling factor for the observable. particle_type : int (default=0)         Particle type to compute the observable for.</p> Source code in <code>swarmrl/observables/particle_sensing.py</code> <pre><code>def __init__(\n    self,\n    decay_fn: callable,\n    box_length: np.ndarray,\n    sensing_type: int = 0,\n    scale_factor: int = 100,\n    particle_type: int = 0,\n):\n    \"\"\"\n    Constructor for the observable.\n\n    Parameters\n    ----------\n    decay_fn : callable\n            Decay function of the field.\n    box_size : np.ndarray\n            Array for scaling of the distances.\n    sensing_type : int (default=0)\n            Type of particle to sense.\n    scale_factor : int (default=100)\n            Scaling factor for the observable.\n    particle_type : int (default=0)\n            Particle type to compute the observable for.\n    \"\"\"\n    super().__init__(particle_type=particle_type)\n\n    self.decay_fn = decay_fn\n    self.box_length = box_length\n    self.sensing_type = sensing_type\n    self.scale_factor = scale_factor\n\n    self.historical_field = {}\n\n    self.observable_fn = jax.vmap(\n        self.compute_single_observable,\n        in_axes=(0, 0, None, 0),\n        # out_axes=()\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.observables.particle_sensing/#swarmrl.observables.particle_sensing.ParticleSensing.compute_observable","title":"<code>compute_observable(colloids)</code>","text":"<p>Compute the position of the colloid.</p>"},{"location":"pages/api/swarmrl.observables.particle_sensing/#swarmrl.observables.particle_sensing.ParticleSensing.compute_observable--parameters","title":"Parameters","text":"<p>colloids : List[Colloid] (n_colloids, )         List of all colloids in the system.</p>"},{"location":"pages/api/swarmrl.observables.particle_sensing/#swarmrl.observables.particle_sensing.ParticleSensing.compute_observable--returns","title":"Returns","text":"<p>observables : List[float] (n_colloids, dimension)         List of observables, one for each colloid. In this case,         current field value minus to previous field value.</p> Source code in <code>swarmrl/observables/particle_sensing.py</code> <pre><code>def compute_observable(self, colloids: List[Colloid]):\n    \"\"\"\n    Compute the position of the colloid.\n\n    Parameters\n    ----------\n    colloids : List[Colloid] (n_colloids, )\n            List of all colloids in the system.\n\n    Returns\n    -------\n    observables : List[float] (n_colloids, dimension)\n            List of observables, one for each colloid. In this case,\n            current field value minus to previous field value.\n    \"\"\"\n    if self.historical_field == {}:\n        msg = (\n            f\"{type(self).__name__} requires initialization. Please set the \"\n            \"initialize attribute of the gym to true and try again.\"\n        )\n        raise ValueError(msg)\n\n    reference_ids = self.get_colloid_indices(colloids)\n    positions = []\n    indices = []\n    historic_values = []\n    for index in reference_ids:\n        indices.append(colloids[index].id)\n        positions.append(colloids[index].pos)\n        historic_values.append(self.historical_field[str(colloids[index].id)])\n\n    test_points = np.array(\n        [colloid.pos for colloid in colloids if colloid.type == self.sensing_type]\n    )\n\n    out_indices, delta_values, field_values = self.observable_fn(\n        np.array(indices),\n        np.array(positions),\n        test_points,\n        np.array(historic_values),\n    )\n\n    for index, value in zip(out_indices, onp.array(field_values)):\n        self.historical_field[str(index)] = value\n\n    return self.scale_factor * delta_values.reshape(-1, 1)\n</code></pre>"},{"location":"pages/api/swarmrl.observables.particle_sensing/#swarmrl.observables.particle_sensing.ParticleSensing.compute_single_observable","title":"<code>compute_single_observable(index, reference_position, test_positions, historic_value)</code>","text":"<p>Compute the observable for a single colloid.</p>"},{"location":"pages/api/swarmrl.observables.particle_sensing/#swarmrl.observables.particle_sensing.ParticleSensing.compute_single_observable--parameters","title":"Parameters","text":"<p>index : int         Index of the colloid to compute the observable for. reference_position : np.ndarray (3,)         Position of the reference colloid. test_positions : np.ndarray (n_colloids, 3)         Positions of the test colloids. historic_value : float         Historic value of the observable.</p>"},{"location":"pages/api/swarmrl.observables.particle_sensing/#swarmrl.observables.particle_sensing.ParticleSensing.compute_single_observable--returns","title":"Returns","text":"<p>tuple (index, observable_value) index : int         Index of the colloid to compute the observable for. observable_value : float         Value of the observable.</p> Source code in <code>swarmrl/observables/particle_sensing.py</code> <pre><code>def compute_single_observable(\n    self,\n    index: int,\n    reference_position: np.ndarray,\n    test_positions: np.ndarray,\n    historic_value: float,\n) -&gt; tuple:\n    \"\"\"\n    Compute the observable for a single colloid.\n\n    Parameters\n    ----------\n    index : int\n            Index of the colloid to compute the observable for.\n    reference_position : np.ndarray (3,)\n            Position of the reference colloid.\n    test_positions : np.ndarray (n_colloids, 3)\n            Positions of the test colloids.\n    historic_value : float\n            Historic value of the observable.\n\n    Returns\n    -------\n    tuple (index, observable_value)\n    index : int\n            Index of the colloid to compute the observable for.\n    observable_value : float\n            Value of the observable.\n    \"\"\"\n    distances = np.linalg.norm(\n        (test_positions - reference_position) / self.box_length, axis=-1\n    )\n    indices = np.asarray(np.nonzero(distances, size=distances.shape[0] - 1))\n    distances = np.take(distances, indices, axis=0)\n    # Compute field value\n    field_value = self.decay_fn(distances).sum()\n    return index, field_value - historic_value, field_value\n</code></pre>"},{"location":"pages/api/swarmrl.observables.particle_sensing/#swarmrl.observables.particle_sensing.ParticleSensing.initialize","title":"<code>initialize(colloids)</code>","text":"<p>Initialize the observable with starting positions of the colloids.</p>"},{"location":"pages/api/swarmrl.observables.particle_sensing/#swarmrl.observables.particle_sensing.ParticleSensing.initialize--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids with which to initialize the observable.</p>"},{"location":"pages/api/swarmrl.observables.particle_sensing/#swarmrl.observables.particle_sensing.ParticleSensing.initialize--returns","title":"Returns","text":"<p>Updates the class state.</p> Source code in <code>swarmrl/observables/particle_sensing.py</code> <pre><code>def initialize(self, colloids: List[Colloid]):\n    \"\"\"\n    Initialize the observable with starting positions of the colloids.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids with which to initialize the observable.\n\n    Returns\n    -------\n    Updates the class state.\n    \"\"\"\n    reference_ids = self.get_colloid_indices(colloids)\n    historic_values = np.zeros(len(reference_ids))\n\n    positions = []\n    indices = []\n    for index in reference_ids:\n        indices.append(colloids[index].id)\n        positions.append(colloids[index].pos)\n\n    sensed_colloids = np.array(\n        [colloid.pos for colloid in colloids if colloid.type == self.sensing_type]\n    )\n\n    out_indices, _, field_values = self.observable_fn(\n        np.array(indices), np.array(positions), sensed_colloids, historic_values\n    )\n\n    for index, value in zip(out_indices, onp.array(field_values)):\n        self.historical_field[str(index)] = value\n</code></pre>"},{"location":"pages/api/swarmrl.observables.position/","title":"swarmrl.observables.position Module API Reference","text":"<p>Position observable computer.</p>"},{"location":"pages/api/swarmrl.observables.position/#swarmrl.observables.position.PositionObservable","title":"<code>PositionObservable</code>","text":"<p>             Bases: <code>Observable</code>, <code>ABC</code></p> <p>Position in box observable.</p> Source code in <code>swarmrl/observables/position.py</code> <pre><code>class PositionObservable(Observable, ABC):\n    \"\"\"\n    Position in box observable.\n    \"\"\"\n\n    def __init__(self, box_length: np.ndarray, particle_type: int = 0):\n        \"\"\"\n        Constructor for the observable.\n\n        Parameters\n        ----------\n        box_length : np.ndarray\n                Length of the box with which to normalize.\n        \"\"\"\n        super().__init__(particle_type=particle_type)\n        self.box_length = box_length\n\n    def compute_single_observable(self, index: int, colloids: list):\n        \"\"\"\n        Compute the position of the colloid.\n\n        Parameters\n        ----------\n        index : int\n                Index of the colloid for which the observable should be computed.\n        colloids : list\n                Colloids in the system.\n        \"\"\"\n        colloid = colloids[index]\n\n        data = onp.copy(colloid.pos)\n\n        return np.array(data) / self.box_length\n\n    def compute_observable(self, colloids: List[Colloid]):\n        \"\"\"\n        Compute the current state observable for all colloids.\n\n        Parameters\n        ----------\n        colloids : List[Colloid] (n_colloids, )\n                List of all colloids in the system.\n        \"\"\"\n        indices = self.get_colloid_indices(colloids)\n\n        return [self.compute_single_observable(i, colloids) for i in indices]\n</code></pre>"},{"location":"pages/api/swarmrl.observables.position/#swarmrl.observables.position.PositionObservable.__init__","title":"<code>__init__(box_length, particle_type=0)</code>","text":"<p>Constructor for the observable.</p>"},{"location":"pages/api/swarmrl.observables.position/#swarmrl.observables.position.PositionObservable.__init__--parameters","title":"Parameters","text":"<p>box_length : np.ndarray         Length of the box with which to normalize.</p> Source code in <code>swarmrl/observables/position.py</code> <pre><code>def __init__(self, box_length: np.ndarray, particle_type: int = 0):\n    \"\"\"\n    Constructor for the observable.\n\n    Parameters\n    ----------\n    box_length : np.ndarray\n            Length of the box with which to normalize.\n    \"\"\"\n    super().__init__(particle_type=particle_type)\n    self.box_length = box_length\n</code></pre>"},{"location":"pages/api/swarmrl.observables.position/#swarmrl.observables.position.PositionObservable.compute_observable","title":"<code>compute_observable(colloids)</code>","text":"<p>Compute the current state observable for all colloids.</p>"},{"location":"pages/api/swarmrl.observables.position/#swarmrl.observables.position.PositionObservable.compute_observable--parameters","title":"Parameters","text":"<p>colloids : List[Colloid] (n_colloids, )         List of all colloids in the system.</p> Source code in <code>swarmrl/observables/position.py</code> <pre><code>def compute_observable(self, colloids: List[Colloid]):\n    \"\"\"\n    Compute the current state observable for all colloids.\n\n    Parameters\n    ----------\n    colloids : List[Colloid] (n_colloids, )\n            List of all colloids in the system.\n    \"\"\"\n    indices = self.get_colloid_indices(colloids)\n\n    return [self.compute_single_observable(i, colloids) for i in indices]\n</code></pre>"},{"location":"pages/api/swarmrl.observables.position/#swarmrl.observables.position.PositionObservable.compute_single_observable","title":"<code>compute_single_observable(index, colloids)</code>","text":"<p>Compute the position of the colloid.</p>"},{"location":"pages/api/swarmrl.observables.position/#swarmrl.observables.position.PositionObservable.compute_single_observable--parameters","title":"Parameters","text":"<p>index : int         Index of the colloid for which the observable should be computed. colloids : list         Colloids in the system.</p> Source code in <code>swarmrl/observables/position.py</code> <pre><code>def compute_single_observable(self, index: int, colloids: list):\n    \"\"\"\n    Compute the position of the colloid.\n\n    Parameters\n    ----------\n    index : int\n            Index of the colloid for which the observable should be computed.\n    colloids : list\n            Colloids in the system.\n    \"\"\"\n    colloid = colloids[index]\n\n    data = onp.copy(colloid.pos)\n\n    return np.array(data) / self.box_length\n</code></pre>"},{"location":"pages/api/swarmrl.observables.subdivided_vision_cones/","title":"swarmrl.observables.subdivided_vision_cones Module API Reference","text":"<p>Computes vision cone(s).</p>"},{"location":"pages/api/swarmrl.observables.subdivided_vision_cones/#swarmrl.observables.subdivided_vision_cones.SubdividedVisionCones","title":"<code>SubdividedVisionCones</code>","text":"<p>             Bases: <code>Observable</code></p> <p>The vision cone acts like a camera for the particles. It can either output all colloids within its view, a function of the distances between one colloid and all other colloids, or the normalised distance to the source.</p> Source code in <code>swarmrl/observables/subdivided_vision_cones.py</code> <pre><code>class SubdividedVisionCones(Observable):\n    \"\"\"\n    The vision cone acts like a camera for the particles. It can either output all\n    colloids within its view, a function of the distances between one colloid and all\n    other colloids, or the normalised distance to the source.\n    \"\"\"\n\n    def __init__(\n        self,\n        vision_range: float,\n        vision_half_angle: float,\n        n_cones: int,\n        radii: List[float],\n        detected_types=None,\n        particle_type: int = 0,\n    ):\n        \"\"\"\n        Constructor for the observable.\n\n        Parameters\n        ----------\n        vision_range : float\n                How far the particles can see.\n        vision_half_angle : float\n                the half width of the field of view in radiant units\n        n_cones: int\n                In how many cone is the field of view subdivided\n        radii: list\n                List of the radii of the colloids in the experiment,\n                ordered by the ids of the colloids\n        detected_types: list\n                list of colloid types to be detected in requested order.\n                For example [0,2] here colloids of type 1 won't be detected.\n                if None then all will be detected.\n        particle_type : int (default=0)\n                Particle type to compute the observable for.\n        \"\"\"\n        super().__init__(particle_type=particle_type)\n        self.vision_range = vision_range\n        self.vision_half_angle = vision_half_angle\n        self.n_cones = n_cones\n        self.radii = radii\n        self.detected_types = detected_types\n        self.angle_fn = jit(calc_signed_angle_between_directors)\n\n    def _detect_all_things_to_see(self, colloids: List[Colloid]):\n        \"\"\"\n        Determines what types of colloids are present in the simulation\n\n        Parameters\n        ----------\n        colloids : object\n                Colloids with all possible different types.\n\n        Returns\n        -------\n        One dimensional np.array with all possible types\n        in the corresponding index in which\n        they will also later be found when the observable is calculated.\n        \"\"\"\n        all_types = []\n        for c in colloids:\n            if c.type not in all_types:\n                all_types.append(c.type)\n        self.detected_types = np.array(np.sort(all_types))\n\n    @partial(jit, static_argnums=(0,))\n    def _calculate_cones_single_object(\n        self,\n        my_pos: np.ndarray,\n        my_director: np.ndarray,\n        c_type: int,\n        c_pos: np.ndarray,\n        radius: float,\n    ):\n        \"\"\"\n        Compute the vision cones of one colloid from one colloid.\n\n        Parameters\n        ----------\n        my_pos : np.ndarray\n                the 2D position of the colloid that has vision\n        my_director : np.ndarray\n                the 2D orientation of the colloid that has vision\n        c_type : int\n                The type of the colloid that is seen\n        c_pos : np.ndarray\n                The position of the colloid that is seen\n        radius : float\n                The radius of the colloid that has vision\n        Returns\n        -------\n        np.ndarray of shape (n_cones, num_of_detected_types) containing\n        the vision values for each cone and for each particle type that\n        can be visible. At most one value is unequal to zero.\n        \"\"\"\n        # generate a blue print of the output values\n        vision_val_out = jnp.ones((self.n_cones, len(self.detected_types)))\n\n        dist = c_pos - my_pos\n        dist_norm = jnp.linalg.norm(dist)\n        in_range = dist_norm &lt; self.vision_range\n        # check if output values will correspond with\n        # no visible colloid at all because to far away\n        vision_val_out *= in_range\n        # calculation could stop here but is carried\n        # on with zeros due to parallelization\n        # keep on calculating even if there are only zeros\n\n        # adjust the amplitude of the vision to the correct value\n        vision_val_out *= jnp.min(jnp.array([1, 2 * radius / dist_norm]))\n\n        # generate a mask that is only true for the 2D array entries with the right type\n        type_mask = (\n            jnp.ones((self.n_cones, len(self.detected_types)))\n            * np.array(self.detected_types)[np.newaxis, :]\n        )\n        correct_type_mask = jnp.where(type_mask == c_type, True, False)\n        # Apply the mask on the output values\n        vision_val_out *= correct_type_mask\n\n        # compare to the direction of view with\n        # the direction in which the other colloid is.\n        # Get the singed angle between them\n        # call the jax.jit version of calc_signed_angle_between_directors()\n        angle = self.angle_fn(my_director, dist / dist_norm)\n\n        # get masks with True if the colloid is in the specific vision cone\n        rims = (\n            -self.vision_half_angle\n            + jnp.arange(self.n_cones + 1) * self.vision_half_angle * 2 / self.n_cones\n        )\n        in_left_rim = jnp.where(rims[:-1] &lt; angle, True, False)\n        in_right_rim = jnp.where(rims[1:] &gt; angle, True, False)\n        in_a_cone = in_left_rim * in_right_rim\n        # apply mask to the output_values\n        vision_val_out *= in_a_cone[:, np.newaxis]\n\n        # 2D array with right vision amplitude for\n        # right type and cone only if distance &lt; cut off radius\n        return vision_val_out\n\n    def _calculate_cones(self, my_pos, my_director, other_colloids: List[Colloid]):\n        \"\"\"\n        Calculates the vision cones of the colloid.\n\n        Parameters\n        ----------\n        my_pos : np.ndarray\n                Position of the colloid.\n        my_director : np.ndarray\n                Normalised director of the colloid.\n        other_colloids : List[Colloid]\n                all the colloids besides the one with my_pos and my_director\n        Returns\n        -------\n        np.array of shape (n_cones, num_of_types) containing the vision values\n        for each cone and for each particle type that can be visible.\n        \"\"\"\n\n        # prepare traceable colloid data for vectorized vision cone evaluation\n        other_colloids_id = np.zeros((len(other_colloids)))\n        other_colloids_pos = np.zeros((len(other_colloids), 3))\n        other_colloids_types = np.zeros((len(other_colloids)))\n        for index, c in enumerate(other_colloids):\n            other_colloids_id[index] = c.id\n            other_colloids_types[index] = c.type\n            other_colloids_pos[index, :] = c.pos\n\n        # wrap jax.vmap around the vision cone\n        # evaluation concerning a single other colloid\n        # therefore spare out a for loop over all colloid to be seen\n        # make it parallelizable at the cost of calculating with sparse arrays\n        calculate_cones = vmap(\n            self._calculate_cones_single_object,\n            in_axes=(None, None, 0, 0, 0),\n            out_axes=0,\n        )\n\n        # executing the vectorized function\n        vision_val_out_expanded = calculate_cones(\n            my_pos,\n            my_director,\n            other_colloids_types,\n            other_colloids_pos,\n            np.array(self.radii),\n        )\n        # collapsing the data of every individual other_colloid and returning the result\n        return np.sum(vision_val_out_expanded, axis=0)\n\n    def compute_single_observable(\n        self, index: int, colloids: List[Colloid]\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Compute the vision cones of the colloid.\n\n        Parameters\n        ----------\n        index : int\n                Index of colloid for which the observable should be computed.\n        colloids\n                colloids in the system.\n        Returns\n        -------\n        np.array of shape (n_cones, num_of_detected_types) containing the vision values\n        for each cone and for each particle type that can be visible.\n        \"\"\"\n        colloid = colloids[index]\n\n        if self.detected_types is None:\n            self._detect_all_things_to_see(colloids)\n\n        my_pos, my_director = colloid.pos, colloid.director\n\n        of_others = [\n            [c, self.radii[i]] for i, c in enumerate(colloids) if c is not index\n        ]\n        other_colloids = [of_others[i][0] for i in range(len(of_others))]\n        self.radii = [of_others[i][1] for i in range(len(of_others))]\n\n        observable = self._calculate_cones(my_pos, my_director, other_colloids)\n\n        return observable\n\n    def compute_observable(self, colloids: List[Colloid]):\n        \"\"\"\n        Compute the vision cones of the colloids.\n\n        Parameters\n        ----------\n        colloids\n                colloids in the system.\n        Returns\n        -------\n        np.array of shape (n_colloids, n_cones, num_of_detected_types)\n        containing the vision values\n        \"\"\"\n        reference_ids = self.get_colloid_indices(colloids)\n\n        return [\n            self.compute_single_observable(index, colloids) for index in reference_ids\n        ]\n</code></pre>"},{"location":"pages/api/swarmrl.observables.subdivided_vision_cones/#swarmrl.observables.subdivided_vision_cones.SubdividedVisionCones.__init__","title":"<code>__init__(vision_range, vision_half_angle, n_cones, radii, detected_types=None, particle_type=0)</code>","text":"<p>Constructor for the observable.</p>"},{"location":"pages/api/swarmrl.observables.subdivided_vision_cones/#swarmrl.observables.subdivided_vision_cones.SubdividedVisionCones.__init__--parameters","title":"Parameters","text":"<p>vision_range : float         How far the particles can see. vision_half_angle : float         the half width of the field of view in radiant units n_cones: int         In how many cone is the field of view subdivided radii: list         List of the radii of the colloids in the experiment,         ordered by the ids of the colloids detected_types: list         list of colloid types to be detected in requested order.         For example [0,2] here colloids of type 1 won't be detected.         if None then all will be detected. particle_type : int (default=0)         Particle type to compute the observable for.</p> Source code in <code>swarmrl/observables/subdivided_vision_cones.py</code> <pre><code>def __init__(\n    self,\n    vision_range: float,\n    vision_half_angle: float,\n    n_cones: int,\n    radii: List[float],\n    detected_types=None,\n    particle_type: int = 0,\n):\n    \"\"\"\n    Constructor for the observable.\n\n    Parameters\n    ----------\n    vision_range : float\n            How far the particles can see.\n    vision_half_angle : float\n            the half width of the field of view in radiant units\n    n_cones: int\n            In how many cone is the field of view subdivided\n    radii: list\n            List of the radii of the colloids in the experiment,\n            ordered by the ids of the colloids\n    detected_types: list\n            list of colloid types to be detected in requested order.\n            For example [0,2] here colloids of type 1 won't be detected.\n            if None then all will be detected.\n    particle_type : int (default=0)\n            Particle type to compute the observable for.\n    \"\"\"\n    super().__init__(particle_type=particle_type)\n    self.vision_range = vision_range\n    self.vision_half_angle = vision_half_angle\n    self.n_cones = n_cones\n    self.radii = radii\n    self.detected_types = detected_types\n    self.angle_fn = jit(calc_signed_angle_between_directors)\n</code></pre>"},{"location":"pages/api/swarmrl.observables.subdivided_vision_cones/#swarmrl.observables.subdivided_vision_cones.SubdividedVisionCones.compute_observable","title":"<code>compute_observable(colloids)</code>","text":"<p>Compute the vision cones of the colloids.</p>"},{"location":"pages/api/swarmrl.observables.subdivided_vision_cones/#swarmrl.observables.subdivided_vision_cones.SubdividedVisionCones.compute_observable--parameters","title":"Parameters","text":"<p>colloids         colloids in the system. Returns</p> <p>np.array of shape (n_colloids, n_cones, num_of_detected_types) containing the vision values</p> Source code in <code>swarmrl/observables/subdivided_vision_cones.py</code> <pre><code>def compute_observable(self, colloids: List[Colloid]):\n    \"\"\"\n    Compute the vision cones of the colloids.\n\n    Parameters\n    ----------\n    colloids\n            colloids in the system.\n    Returns\n    -------\n    np.array of shape (n_colloids, n_cones, num_of_detected_types)\n    containing the vision values\n    \"\"\"\n    reference_ids = self.get_colloid_indices(colloids)\n\n    return [\n        self.compute_single_observable(index, colloids) for index in reference_ids\n    ]\n</code></pre>"},{"location":"pages/api/swarmrl.observables.subdivided_vision_cones/#swarmrl.observables.subdivided_vision_cones.SubdividedVisionCones.compute_single_observable","title":"<code>compute_single_observable(index, colloids)</code>","text":"<p>Compute the vision cones of the colloid.</p>"},{"location":"pages/api/swarmrl.observables.subdivided_vision_cones/#swarmrl.observables.subdivided_vision_cones.SubdividedVisionCones.compute_single_observable--parameters","title":"Parameters","text":"<p>index : int         Index of colloid for which the observable should be computed. colloids         colloids in the system. Returns</p> <p>np.array of shape (n_cones, num_of_detected_types) containing the vision values for each cone and for each particle type that can be visible.</p> Source code in <code>swarmrl/observables/subdivided_vision_cones.py</code> <pre><code>def compute_single_observable(\n    self, index: int, colloids: List[Colloid]\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute the vision cones of the colloid.\n\n    Parameters\n    ----------\n    index : int\n            Index of colloid for which the observable should be computed.\n    colloids\n            colloids in the system.\n    Returns\n    -------\n    np.array of shape (n_cones, num_of_detected_types) containing the vision values\n    for each cone and for each particle type that can be visible.\n    \"\"\"\n    colloid = colloids[index]\n\n    if self.detected_types is None:\n        self._detect_all_things_to_see(colloids)\n\n    my_pos, my_director = colloid.pos, colloid.director\n\n    of_others = [\n        [c, self.radii[i]] for i, c in enumerate(colloids) if c is not index\n    ]\n    other_colloids = [of_others[i][0] for i in range(len(of_others))]\n    self.radii = [of_others[i][1] for i in range(len(of_others))]\n\n    observable = self._calculate_cones(my_pos, my_director, other_colloids)\n\n    return observable\n</code></pre>"},{"location":"pages/api/swarmrl.sampling_strategies.categorical_distribution/","title":"swarmrl.sampling_strategies.categorical_distribution Module API Reference","text":"<p>Module for the categorical distribution.</p>"},{"location":"pages/api/swarmrl.sampling_strategies.categorical_distribution/#swarmrl.sampling_strategies.categorical_distribution.CategoricalDistribution","title":"<code>CategoricalDistribution</code>","text":"<p>             Bases: <code>SamplingStrategy</code>, <code>ABC</code></p> <p>Class for the Gumbel distribution.</p> Source code in <code>swarmrl/sampling_strategies/categorical_distribution.py</code> <pre><code>class CategoricalDistribution(SamplingStrategy, ABC):\n    \"\"\"\n    Class for the Gumbel distribution.\n    \"\"\"\n\n    def __init__(self, noise: str = \"none\"):\n        \"\"\"\n        Constructor for the categorical distribution.\n\n        Parameters\n        ----------\n        noise : str\n                Noise method to use, options include none, uniform and gaussian.\n        \"\"\"\n        noise_dict = {\n            \"uniform\": jax.random.uniform,\n            \"gaussian\": jax.random.normal,\n            \"none\": None,\n        }\n        try:\n            self.noise = noise_dict[noise]\n        except KeyError:\n            msg = (\n                f\"Parsed noise method {noise} is not implemented, please choose\"\n                \"from 'none', 'gaussian' and 'uniform'.\"\n            )\n            raise KeyError(msg)\n\n    def __call__(self, logits: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Sample from the distribution.\n\n        Parameters\n        ----------\n        logits : np.ndarray (n_colloids, n_dimensions)\n                Logits from the model to use in the computation for all colloids.\n        entropy : bool\n                If true, the Shannon entropy of the distribution is returned.\n\n        Returns\n        -------\n        indices : np.ndarray (n_colloids,)\n                Index of the selected option in the distribution.\n        \"\"\"\n        rng = jax.random.PRNGKey(onp.random.randint(0, 1236534623))\n\n        try:\n            noise = self.noise(rng, shape=logits.shape)\n        except TypeError:\n            # If set to None the noise is just 0\n            noise = 0\n\n        indices = jax.random.categorical(rng, logits=logits + noise)\n\n        return indices\n</code></pre>"},{"location":"pages/api/swarmrl.sampling_strategies.categorical_distribution/#swarmrl.sampling_strategies.categorical_distribution.CategoricalDistribution.__call__","title":"<code>__call__(logits)</code>","text":"<p>Sample from the distribution.</p>"},{"location":"pages/api/swarmrl.sampling_strategies.categorical_distribution/#swarmrl.sampling_strategies.categorical_distribution.CategoricalDistribution.__call__--parameters","title":"Parameters","text":"<p>logits : np.ndarray (n_colloids, n_dimensions)         Logits from the model to use in the computation for all colloids. entropy : bool         If true, the Shannon entropy of the distribution is returned.</p>"},{"location":"pages/api/swarmrl.sampling_strategies.categorical_distribution/#swarmrl.sampling_strategies.categorical_distribution.CategoricalDistribution.__call__--returns","title":"Returns","text":"<p>indices : np.ndarray (n_colloids,)         Index of the selected option in the distribution.</p> Source code in <code>swarmrl/sampling_strategies/categorical_distribution.py</code> <pre><code>def __call__(self, logits: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Sample from the distribution.\n\n    Parameters\n    ----------\n    logits : np.ndarray (n_colloids, n_dimensions)\n            Logits from the model to use in the computation for all colloids.\n    entropy : bool\n            If true, the Shannon entropy of the distribution is returned.\n\n    Returns\n    -------\n    indices : np.ndarray (n_colloids,)\n            Index of the selected option in the distribution.\n    \"\"\"\n    rng = jax.random.PRNGKey(onp.random.randint(0, 1236534623))\n\n    try:\n        noise = self.noise(rng, shape=logits.shape)\n    except TypeError:\n        # If set to None the noise is just 0\n        noise = 0\n\n    indices = jax.random.categorical(rng, logits=logits + noise)\n\n    return indices\n</code></pre>"},{"location":"pages/api/swarmrl.sampling_strategies.categorical_distribution/#swarmrl.sampling_strategies.categorical_distribution.CategoricalDistribution.__init__","title":"<code>__init__(noise='none')</code>","text":"<p>Constructor for the categorical distribution.</p>"},{"location":"pages/api/swarmrl.sampling_strategies.categorical_distribution/#swarmrl.sampling_strategies.categorical_distribution.CategoricalDistribution.__init__--parameters","title":"Parameters","text":"<p>noise : str         Noise method to use, options include none, uniform and gaussian.</p> Source code in <code>swarmrl/sampling_strategies/categorical_distribution.py</code> <pre><code>def __init__(self, noise: str = \"none\"):\n    \"\"\"\n    Constructor for the categorical distribution.\n\n    Parameters\n    ----------\n    noise : str\n            Noise method to use, options include none, uniform and gaussian.\n    \"\"\"\n    noise_dict = {\n        \"uniform\": jax.random.uniform,\n        \"gaussian\": jax.random.normal,\n        \"none\": None,\n    }\n    try:\n        self.noise = noise_dict[noise]\n    except KeyError:\n        msg = (\n            f\"Parsed noise method {noise} is not implemented, please choose\"\n            \"from 'none', 'gaussian' and 'uniform'.\"\n        )\n        raise KeyError(msg)\n</code></pre>"},{"location":"pages/api/swarmrl.sampling_strategies.gumbel_distribution/","title":"swarmrl.sampling_strategies.gumbel_distribution Module API Reference","text":"<p>Module for the Gumbel distribution.</p>"},{"location":"pages/api/swarmrl.sampling_strategies.gumbel_distribution/#swarmrl.sampling_strategies.gumbel_distribution.GumbelDistribution","title":"<code>GumbelDistribution</code>","text":"<p>             Bases: <code>SamplingStrategy</code>, <code>ABC</code></p> <p>Class for the Gumbel distribution.</p> Source code in <code>swarmrl/sampling_strategies/gumbel_distribution.py</code> <pre><code>class GumbelDistribution(SamplingStrategy, ABC):\n    \"\"\"\n    Class for the Gumbel distribution.\n    \"\"\"\n\n    def __call__(self, logits: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Sample from the distribution.\n\n        Parameters\n        ----------\n        logits : np.ndarray (n_colloids, n_dimensions)\n                Logits from the model to use in the computation for all colloids.\n\n        Returns\n        -------\n        indices : np.ndarray (n_colloids,)\n                Indeices of chosen actions for all colloids.\n\n        Notes\n        -----\n        See https://arxiv.org/abs/1611.01144 for more information.\n        \"\"\"\n        rng = jax.random.PRNGKey(onp.random.randint(0, 1236534623))\n        noise = jax.random.uniform(rng, shape=logits.shape)\n\n        indices = np.argmax(logits - np.log(-np.log(noise)), axis=-1)\n\n        return indices\n</code></pre>"},{"location":"pages/api/swarmrl.sampling_strategies.gumbel_distribution/#swarmrl.sampling_strategies.gumbel_distribution.GumbelDistribution.__call__","title":"<code>__call__(logits)</code>","text":"<p>Sample from the distribution.</p>"},{"location":"pages/api/swarmrl.sampling_strategies.gumbel_distribution/#swarmrl.sampling_strategies.gumbel_distribution.GumbelDistribution.__call__--parameters","title":"Parameters","text":"<p>logits : np.ndarray (n_colloids, n_dimensions)         Logits from the model to use in the computation for all colloids.</p>"},{"location":"pages/api/swarmrl.sampling_strategies.gumbel_distribution/#swarmrl.sampling_strategies.gumbel_distribution.GumbelDistribution.__call__--returns","title":"Returns","text":"<p>indices : np.ndarray (n_colloids,)         Indeices of chosen actions for all colloids.</p>"},{"location":"pages/api/swarmrl.sampling_strategies.gumbel_distribution/#swarmrl.sampling_strategies.gumbel_distribution.GumbelDistribution.__call__--notes","title":"Notes","text":"<p>See https://arxiv.org/abs/1611.01144 for more information.</p> Source code in <code>swarmrl/sampling_strategies/gumbel_distribution.py</code> <pre><code>def __call__(self, logits: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Sample from the distribution.\n\n    Parameters\n    ----------\n    logits : np.ndarray (n_colloids, n_dimensions)\n            Logits from the model to use in the computation for all colloids.\n\n    Returns\n    -------\n    indices : np.ndarray (n_colloids,)\n            Indeices of chosen actions for all colloids.\n\n    Notes\n    -----\n    See https://arxiv.org/abs/1611.01144 for more information.\n    \"\"\"\n    rng = jax.random.PRNGKey(onp.random.randint(0, 1236534623))\n    noise = jax.random.uniform(rng, shape=logits.shape)\n\n    indices = np.argmax(logits - np.log(-np.log(noise)), axis=-1)\n\n    return indices\n</code></pre>"},{"location":"pages/api/swarmrl.sampling_strategies.sampling_strategy/","title":"swarmrl.sampling_strategies.sampling_strategy Module API Reference","text":"<p>Parent class for sampling strategies.</p>"},{"location":"pages/api/swarmrl.sampling_strategies.sampling_strategy/#swarmrl.sampling_strategies.sampling_strategy.SamplingStrategy","title":"<code>SamplingStrategy</code>","text":"<p>Parent class for sampling strategies.</p> Source code in <code>swarmrl/sampling_strategies/sampling_strategy.py</code> <pre><code>class SamplingStrategy:\n    \"\"\"\n    Parent class for sampling strategies.\n    \"\"\"\n\n    def compute_entropy(self, probabilities: np.ndarray) -&gt; float:\n        \"\"\"\n        Compute the Shannon entropy of the probabilities.\n\n        Parameters\n        ----------\n        probabilities : np.ndarray (n_colloids, n_actions)\n                Probabilities for each colloid to take specific actions.\n        \"\"\"\n        eps = 1e-8\n        probabilities += eps\n        return -np.sum(probabilities * np.log(probabilities))\n\n    def __call__(self, logits: np.ndarray) -&gt; int:\n        \"\"\"\n        Sample from the distribution.\n\n        Parameters\n        ----------\n        logits : np.ndarray (n_colloids, n_dimensions)\n                Logits from the model to use in the computation for each colloid.\n\n        Returns\n        -------\n        sample : int\n                Index of the selected option in the distribution.\n        \"\"\"\n        raise NotImplementedError(\"Implemented in child classes.\")\n</code></pre>"},{"location":"pages/api/swarmrl.sampling_strategies.sampling_strategy/#swarmrl.sampling_strategies.sampling_strategy.SamplingStrategy.__call__","title":"<code>__call__(logits)</code>","text":"<p>Sample from the distribution.</p>"},{"location":"pages/api/swarmrl.sampling_strategies.sampling_strategy/#swarmrl.sampling_strategies.sampling_strategy.SamplingStrategy.__call__--parameters","title":"Parameters","text":"<p>logits : np.ndarray (n_colloids, n_dimensions)         Logits from the model to use in the computation for each colloid.</p>"},{"location":"pages/api/swarmrl.sampling_strategies.sampling_strategy/#swarmrl.sampling_strategies.sampling_strategy.SamplingStrategy.__call__--returns","title":"Returns","text":"<p>sample : int         Index of the selected option in the distribution.</p> Source code in <code>swarmrl/sampling_strategies/sampling_strategy.py</code> <pre><code>def __call__(self, logits: np.ndarray) -&gt; int:\n    \"\"\"\n    Sample from the distribution.\n\n    Parameters\n    ----------\n    logits : np.ndarray (n_colloids, n_dimensions)\n            Logits from the model to use in the computation for each colloid.\n\n    Returns\n    -------\n    sample : int\n            Index of the selected option in the distribution.\n    \"\"\"\n    raise NotImplementedError(\"Implemented in child classes.\")\n</code></pre>"},{"location":"pages/api/swarmrl.sampling_strategies.sampling_strategy/#swarmrl.sampling_strategies.sampling_strategy.SamplingStrategy.compute_entropy","title":"<code>compute_entropy(probabilities)</code>","text":"<p>Compute the Shannon entropy of the probabilities.</p>"},{"location":"pages/api/swarmrl.sampling_strategies.sampling_strategy/#swarmrl.sampling_strategies.sampling_strategy.SamplingStrategy.compute_entropy--parameters","title":"Parameters","text":"<p>probabilities : np.ndarray (n_colloids, n_actions)         Probabilities for each colloid to take specific actions.</p> Source code in <code>swarmrl/sampling_strategies/sampling_strategy.py</code> <pre><code>def compute_entropy(self, probabilities: np.ndarray) -&gt; float:\n    \"\"\"\n    Compute the Shannon entropy of the probabilities.\n\n    Parameters\n    ----------\n    probabilities : np.ndarray (n_colloids, n_actions)\n            Probabilities for each colloid to take specific actions.\n    \"\"\"\n    eps = 1e-8\n    probabilities += eps\n    return -np.sum(probabilities * np.log(probabilities))\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.multi_tasking/","title":"swarmrl.tasks.multi_tasking Module API Reference","text":"<p>Class for multi-tasking.</p>"},{"location":"pages/api/swarmrl.tasks.multi_tasking/#swarmrl.tasks.multi_tasking.MultiTasking","title":"<code>MultiTasking</code>","text":"<p>             Bases: <code>Task</code></p> <p>Class for handling multiple tasks.</p> Source code in <code>swarmrl/tasks/multi_tasking.py</code> <pre><code>class MultiTasking(Task):\n    \"\"\"\n    Class for handling multiple tasks.\n    \"\"\"\n\n    def __init__(self, particle_type: int = 0, tasks: List[Task] = []):\n        \"\"\"\n        Constructor for multi-tasking.\n        \"\"\"\n        super().__init__(particle_type)\n        self.tasks = tasks\n\n    def initialize(self, colloids: List[Colloid]):\n        \"\"\"\n        Initialize the observables as needed.\n\n        Parameters\n        ----------\n        colloids : List[Colloid]\n                List of colloids with which to initialize the observable.\n\n        Returns\n        -------\n        Some of the observables passed to the constructor might need to be\n        initialized with the positions of the colloids. This method does\n        that.\n        \"\"\"\n        for item in self.tasks:\n            item.initialize(colloids)\n\n    def __call__(self, colloids: List[Colloid]) -&gt; np.ndarray:\n        \"\"\"\n        Computes all observables and returns them in a concatenated list.\n\n        Parameters\n        ----------\n        colloids : list of all colloids.\n\n        Returns\n        -------\n        rewards : np.ndarray of shape (num_colloids, )\n                Array of rewards for each colloid.\n        \"\"\"\n        species_indices = self.get_colloid_indices(colloids)\n        rewards = np.zeros(len(species_indices))\n        for task in self.tasks:\n            ts = task(colloids)\n            rewards += ts\n\n        return rewards\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.multi_tasking/#swarmrl.tasks.multi_tasking.MultiTasking.__call__","title":"<code>__call__(colloids)</code>","text":"<p>Computes all observables and returns them in a concatenated list.</p>"},{"location":"pages/api/swarmrl.tasks.multi_tasking/#swarmrl.tasks.multi_tasking.MultiTasking.__call__--parameters","title":"Parameters","text":"<p>colloids : list of all colloids.</p>"},{"location":"pages/api/swarmrl.tasks.multi_tasking/#swarmrl.tasks.multi_tasking.MultiTasking.__call__--returns","title":"Returns","text":"<p>rewards : np.ndarray of shape (num_colloids, )         Array of rewards for each colloid.</p> Source code in <code>swarmrl/tasks/multi_tasking.py</code> <pre><code>def __call__(self, colloids: List[Colloid]) -&gt; np.ndarray:\n    \"\"\"\n    Computes all observables and returns them in a concatenated list.\n\n    Parameters\n    ----------\n    colloids : list of all colloids.\n\n    Returns\n    -------\n    rewards : np.ndarray of shape (num_colloids, )\n            Array of rewards for each colloid.\n    \"\"\"\n    species_indices = self.get_colloid_indices(colloids)\n    rewards = np.zeros(len(species_indices))\n    for task in self.tasks:\n        ts = task(colloids)\n        rewards += ts\n\n    return rewards\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.multi_tasking/#swarmrl.tasks.multi_tasking.MultiTasking.__init__","title":"<code>__init__(particle_type=0, tasks=[])</code>","text":"<p>Constructor for multi-tasking.</p> Source code in <code>swarmrl/tasks/multi_tasking.py</code> <pre><code>def __init__(self, particle_type: int = 0, tasks: List[Task] = []):\n    \"\"\"\n    Constructor for multi-tasking.\n    \"\"\"\n    super().__init__(particle_type)\n    self.tasks = tasks\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.multi_tasking/#swarmrl.tasks.multi_tasking.MultiTasking.initialize","title":"<code>initialize(colloids)</code>","text":"<p>Initialize the observables as needed.</p>"},{"location":"pages/api/swarmrl.tasks.multi_tasking/#swarmrl.tasks.multi_tasking.MultiTasking.initialize--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids with which to initialize the observable.</p>"},{"location":"pages/api/swarmrl.tasks.multi_tasking/#swarmrl.tasks.multi_tasking.MultiTasking.initialize--returns","title":"Returns","text":"<p>Some of the observables passed to the constructor might need to be initialized with the positions of the colloids. This method does that.</p> Source code in <code>swarmrl/tasks/multi_tasking.py</code> <pre><code>def initialize(self, colloids: List[Colloid]):\n    \"\"\"\n    Initialize the observables as needed.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids with which to initialize the observable.\n\n    Returns\n    -------\n    Some of the observables passed to the constructor might need to be\n    initialized with the positions of the colloids. This method does\n    that.\n    \"\"\"\n    for item in self.tasks:\n        item.initialize(colloids)\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.object_movement.rod_rotation/","title":"swarmrl.tasks.object_movement.rod_rotation Module API Reference","text":"<p>Class for rod rotation task.</p>"},{"location":"pages/api/swarmrl.tasks.object_movement.rod_rotation/#swarmrl.tasks.object_movement.rod_rotation.RotateRod","title":"<code>RotateRod</code>","text":"<p>             Bases: <code>Task</code></p> <p>Rotate a rod.</p> Source code in <code>swarmrl/tasks/object_movement/rod_rotation.py</code> <pre><code>class RotateRod(Task):\n    \"\"\"\n    Rotate a rod.\n    \"\"\"\n\n    def __init__(\n        self,\n        partition: bool = True,\n        rod_type: int = 1,\n        particle_type: int = 0,\n        direction: str = \"CCW\",\n        angular_velocity_scale: int = 1,\n        velocity_history: int = 100,\n    ):\n        \"\"\"\n        Constructor for the find origin task.\n\n        Parameters\n        ----------\n        partition : bool (default=True)\n                Whether to partition the reward by particle contribution.\n        rod_type : int (default=1)\n                Type of particle making up the rod.\n        scale_factor : float (default=100.0)\n                The amount the velocity is scaled by to get the reward.\n        direction : Union[None, str] (default=None)\n                Direction of the rod to rotate. If None, the rod will\n                rotate arbitrarily.\n        particle_type : int (default=0)\n                Type of particle receiving the reward.\n        velocity_history : int (default=100)\n                Number of steps to average the velocity over.\n        \"\"\"\n        super().__init__(particle_type=particle_type)\n        self.partition = partition\n        self.rod_type = rod_type\n\n        if direction == \"CW\":\n            angular_velocity_scale *= -1  # CW is negative\n\n        self.angular_velocity_scale = angular_velocity_scale\n        self._velocity_history = np.nan * np.ones(velocity_history)\n        self._append_index = int(velocity_history - 1)\n\n        # Class only attributes\n        self._historic_rod_director = None\n        self._historic_velocity = 1.0\n\n        self.decomp_fn = jax.jit(compute_torque_partition_on_rod)\n\n    def initialize(self, colloids: List[Colloid]):\n        \"\"\"\n        Prepare the task for running.\n\n        In this case, as all rod directors are the same, we\n        only need to take on for the historical value.\n\n        Parameters\n        ----------\n        colloids : List[Colloid]\n                List of colloids to be used in the task.\n\n        Returns\n        -------\n        Updates the class state.\n        \"\"\"\n        for item in colloids:\n            if item.type == self.rod_type:\n                self._historic_rod_director = onp.copy(item.director)\n                break\n\n    def _compute_angular_velocity(self, new_director: np.ndarray):\n        \"\"\"\n        Compute the instantaneous angular velocity of the rod.\n\n        Parameters\n        ----------\n        new_director : np.ndarray (3, )\n                New rod director.\n\n        Returns\n        -------\n        angular_velocity : float\n                Angular velocity of the rod\n        \"\"\"\n        angular_velocity = np.arctan2(\n            np.cross(self._historic_rod_director[:2], new_director[:2]),\n            np.dot(self._historic_rod_director[:2], new_director[:2]),\n        )\n\n        # Convert to degrees for better scaling.\n        angular_velocity = np.rad2deg(angular_velocity)\n\n        # Update the historical rod director and velocity.\n        self._historic_rod_director = new_director\n        self._velocity_history = np.roll(self._velocity_history, -1)\n        self._velocity_history = self._velocity_history.at[self._append_index].set(\n            angular_velocity\n        )\n\n        # Return the scaled average velocity.\n        return self.angular_velocity_scale * np.nanmean(self._velocity_history)\n\n    def partition_reward(\n        self,\n        reward: float,\n        colloid_positions: np.ndarray,\n        rod_positions: np.ndarray,\n        rod_directors: np.ndarray,\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Partition a reward into colloid contributions.\n\n        Parameters\n        ----------\n        reward : float\n                Reward to be partitioned.\n        colloid_positions : np.ndarray (n_colloids, 3)\n                Positions of the colloids.\n        rod_positions : np.ndarray (n_rod, 3)\n                Positions of the rod particles.\n        rod_directors : np.ndarray (n_rod, 3)\n                Directors of the rod particles.\n\n        Returns\n        -------\n        partitioned_reward : np.ndarray (n_colloids, )\n                Partitioned reward for each colloid.\n        \"\"\"\n        if self.partition:\n            colloid_partitions = self.decomp_fn(\n                colloid_positions, rod_positions, rod_directors\n            )\n        else:\n            colloid_partitions = (\n                np.ones(colloid_positions.shape[0]) / colloid_positions.shape[0]\n            )\n\n        return reward * colloid_partitions\n\n    def _compute_angular_velocity_reward(\n        self,\n        rod_directors: np.ndarray,\n        rod_positions: np.ndarray,\n        colloid_positions: np.ndarray,\n    ):\n        \"\"\"\n        Compute the angular velocity reward.\n\n        Parameters\n        ----------\n        rod_directors : np.ndarray (n_rod, 3)\n                Directors of the rod particles.\n        rod_positions : np.ndarray (n_rod, 3)\n                Positions of the rod particles.\n        colloid_positions : np.ndarray (n_colloids, 3)\n                Positions of the colloids.\n\n        Returns\n        -------\n        angular_velocity_reward : float\n                Angular velocity reward.\n        \"\"\"\n        # Compute angular velocity\n        angular_velocity = self._compute_angular_velocity(rod_directors[0])\n        # Compute colloid-wise rewards\n        return self.partition_reward(\n            angular_velocity, colloid_positions, rod_positions, rod_directors\n        )\n\n    def __call__(self, colloids: List[Colloid]):\n        \"\"\"\n        Compute the reward.\n\n        In this case of this task, the observable itself is the gradient of the field\n        that the colloid is swimming in. Therefore, the change is simply scaled and\n        returned.\n\n        Parameters\n        ----------\n        colloids : List[Colloid] (n_colloids, )\n                List of colloids to be used in the task.\n\n        Returns\n        -------\n        rewards : List[float] (n_colloids, )\n                Rewards for each colloid.\n        \"\"\"\n        # Collect the important data.\n        rod = [colloid for colloid in colloids if colloid.type == self.rod_type]\n        rod_positions = np.array([colloid.pos for colloid in rod])\n        rod_directors = np.array([colloid.director for colloid in rod])\n\n        chosen_colloids = [\n            colloid for colloid in colloids if colloid.type == self.particle_type\n        ]\n        colloid_positions = np.array([colloid.pos for colloid in chosen_colloids])\n\n        # Compute the angular velocity reward\n        angular_velocity_term = self._compute_angular_velocity_reward(\n            rod_directors, rod_positions, colloid_positions\n        )\n\n        return angular_velocity_term\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.object_movement.rod_rotation/#swarmrl.tasks.object_movement.rod_rotation.RotateRod.__call__","title":"<code>__call__(colloids)</code>","text":"<p>Compute the reward.</p> <p>In this case of this task, the observable itself is the gradient of the field that the colloid is swimming in. Therefore, the change is simply scaled and returned.</p>"},{"location":"pages/api/swarmrl.tasks.object_movement.rod_rotation/#swarmrl.tasks.object_movement.rod_rotation.RotateRod.__call__--parameters","title":"Parameters","text":"<p>colloids : List[Colloid] (n_colloids, )         List of colloids to be used in the task.</p>"},{"location":"pages/api/swarmrl.tasks.object_movement.rod_rotation/#swarmrl.tasks.object_movement.rod_rotation.RotateRod.__call__--returns","title":"Returns","text":"<p>rewards : List[float] (n_colloids, )         Rewards for each colloid.</p> Source code in <code>swarmrl/tasks/object_movement/rod_rotation.py</code> <pre><code>def __call__(self, colloids: List[Colloid]):\n    \"\"\"\n    Compute the reward.\n\n    In this case of this task, the observable itself is the gradient of the field\n    that the colloid is swimming in. Therefore, the change is simply scaled and\n    returned.\n\n    Parameters\n    ----------\n    colloids : List[Colloid] (n_colloids, )\n            List of colloids to be used in the task.\n\n    Returns\n    -------\n    rewards : List[float] (n_colloids, )\n            Rewards for each colloid.\n    \"\"\"\n    # Collect the important data.\n    rod = [colloid for colloid in colloids if colloid.type == self.rod_type]\n    rod_positions = np.array([colloid.pos for colloid in rod])\n    rod_directors = np.array([colloid.director for colloid in rod])\n\n    chosen_colloids = [\n        colloid for colloid in colloids if colloid.type == self.particle_type\n    ]\n    colloid_positions = np.array([colloid.pos for colloid in chosen_colloids])\n\n    # Compute the angular velocity reward\n    angular_velocity_term = self._compute_angular_velocity_reward(\n        rod_directors, rod_positions, colloid_positions\n    )\n\n    return angular_velocity_term\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.object_movement.rod_rotation/#swarmrl.tasks.object_movement.rod_rotation.RotateRod.__init__","title":"<code>__init__(partition=True, rod_type=1, particle_type=0, direction='CCW', angular_velocity_scale=1, velocity_history=100)</code>","text":"<p>Constructor for the find origin task.</p>"},{"location":"pages/api/swarmrl.tasks.object_movement.rod_rotation/#swarmrl.tasks.object_movement.rod_rotation.RotateRod.__init__--parameters","title":"Parameters","text":"<p>partition : bool (default=True)         Whether to partition the reward by particle contribution. rod_type : int (default=1)         Type of particle making up the rod. scale_factor : float (default=100.0)         The amount the velocity is scaled by to get the reward. direction : Union[None, str] (default=None)         Direction of the rod to rotate. If None, the rod will         rotate arbitrarily. particle_type : int (default=0)         Type of particle receiving the reward. velocity_history : int (default=100)         Number of steps to average the velocity over.</p> Source code in <code>swarmrl/tasks/object_movement/rod_rotation.py</code> <pre><code>def __init__(\n    self,\n    partition: bool = True,\n    rod_type: int = 1,\n    particle_type: int = 0,\n    direction: str = \"CCW\",\n    angular_velocity_scale: int = 1,\n    velocity_history: int = 100,\n):\n    \"\"\"\n    Constructor for the find origin task.\n\n    Parameters\n    ----------\n    partition : bool (default=True)\n            Whether to partition the reward by particle contribution.\n    rod_type : int (default=1)\n            Type of particle making up the rod.\n    scale_factor : float (default=100.0)\n            The amount the velocity is scaled by to get the reward.\n    direction : Union[None, str] (default=None)\n            Direction of the rod to rotate. If None, the rod will\n            rotate arbitrarily.\n    particle_type : int (default=0)\n            Type of particle receiving the reward.\n    velocity_history : int (default=100)\n            Number of steps to average the velocity over.\n    \"\"\"\n    super().__init__(particle_type=particle_type)\n    self.partition = partition\n    self.rod_type = rod_type\n\n    if direction == \"CW\":\n        angular_velocity_scale *= -1  # CW is negative\n\n    self.angular_velocity_scale = angular_velocity_scale\n    self._velocity_history = np.nan * np.ones(velocity_history)\n    self._append_index = int(velocity_history - 1)\n\n    # Class only attributes\n    self._historic_rod_director = None\n    self._historic_velocity = 1.0\n\n    self.decomp_fn = jax.jit(compute_torque_partition_on_rod)\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.object_movement.rod_rotation/#swarmrl.tasks.object_movement.rod_rotation.RotateRod.initialize","title":"<code>initialize(colloids)</code>","text":"<p>Prepare the task for running.</p> <p>In this case, as all rod directors are the same, we only need to take on for the historical value.</p>"},{"location":"pages/api/swarmrl.tasks.object_movement.rod_rotation/#swarmrl.tasks.object_movement.rod_rotation.RotateRod.initialize--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids to be used in the task.</p>"},{"location":"pages/api/swarmrl.tasks.object_movement.rod_rotation/#swarmrl.tasks.object_movement.rod_rotation.RotateRod.initialize--returns","title":"Returns","text":"<p>Updates the class state.</p> Source code in <code>swarmrl/tasks/object_movement/rod_rotation.py</code> <pre><code>def initialize(self, colloids: List[Colloid]):\n    \"\"\"\n    Prepare the task for running.\n\n    In this case, as all rod directors are the same, we\n    only need to take on for the historical value.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids to be used in the task.\n\n    Returns\n    -------\n    Updates the class state.\n    \"\"\"\n    for item in colloids:\n        if item.type == self.rod_type:\n            self._historic_rod_director = onp.copy(item.director)\n            break\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.object_movement.rod_rotation/#swarmrl.tasks.object_movement.rod_rotation.RotateRod.partition_reward","title":"<code>partition_reward(reward, colloid_positions, rod_positions, rod_directors)</code>","text":"<p>Partition a reward into colloid contributions.</p>"},{"location":"pages/api/swarmrl.tasks.object_movement.rod_rotation/#swarmrl.tasks.object_movement.rod_rotation.RotateRod.partition_reward--parameters","title":"Parameters","text":"<p>reward : float         Reward to be partitioned. colloid_positions : np.ndarray (n_colloids, 3)         Positions of the colloids. rod_positions : np.ndarray (n_rod, 3)         Positions of the rod particles. rod_directors : np.ndarray (n_rod, 3)         Directors of the rod particles.</p>"},{"location":"pages/api/swarmrl.tasks.object_movement.rod_rotation/#swarmrl.tasks.object_movement.rod_rotation.RotateRod.partition_reward--returns","title":"Returns","text":"<p>partitioned_reward : np.ndarray (n_colloids, )         Partitioned reward for each colloid.</p> Source code in <code>swarmrl/tasks/object_movement/rod_rotation.py</code> <pre><code>def partition_reward(\n    self,\n    reward: float,\n    colloid_positions: np.ndarray,\n    rod_positions: np.ndarray,\n    rod_directors: np.ndarray,\n) -&gt; np.ndarray:\n    \"\"\"\n    Partition a reward into colloid contributions.\n\n    Parameters\n    ----------\n    reward : float\n            Reward to be partitioned.\n    colloid_positions : np.ndarray (n_colloids, 3)\n            Positions of the colloids.\n    rod_positions : np.ndarray (n_rod, 3)\n            Positions of the rod particles.\n    rod_directors : np.ndarray (n_rod, 3)\n            Directors of the rod particles.\n\n    Returns\n    -------\n    partitioned_reward : np.ndarray (n_colloids, )\n            Partitioned reward for each colloid.\n    \"\"\"\n    if self.partition:\n        colloid_partitions = self.decomp_fn(\n            colloid_positions, rod_positions, rod_directors\n        )\n    else:\n        colloid_partitions = (\n            np.ones(colloid_positions.shape[0]) / colloid_positions.shape[0]\n        )\n\n    return reward * colloid_partitions\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/","title":"swarmrl.tasks.searching.gradient_sensing Module API Reference","text":"<p>Run and tumble task</p> <p>This task uses the change in the gradient to determine whether a move was good or not.</p>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing--notes","title":"Notes","text":"<p>Requires a warm up step.</p>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing","title":"<code>GradientSensing</code>","text":"<p>             Bases: <code>Task</code>, <code>ABC</code></p> <p>Find a location in a box using distances.</p> Source code in <code>swarmrl/tasks/searching/gradient_sensing.py</code> <pre><code>class GradientSensing(Task, ABC):\n    \"\"\"\n    Find a location in a box using distances.\n    \"\"\"\n\n    def __init__(\n        self,\n        source: np.ndarray = np.array([0, 0, 0]),\n        decay_function: callable = None,\n        box_length: np.ndarray = np.array([1.0, 1.0, 0.0]),\n        reward_scale_factor: int = 10,\n        particle_type: int = 0,\n    ):\n        \"\"\"\n        Constructor for the find origin task.\n\n        Parameters\n        ----------\n        source : np.ndarray (default = (0, 0 0))\n                Source of the gradient.\n        decay_function : callable (required=True)\n                A function that describes the decay of the field along one dimension.\n                This cannot be left None. The function should take a distance from the\n                source and return the magnitude of the field at this point.\n        box_length : np.ndarray\n                Side length of the box.\n        reward_scale_factor : int (default=10)\n                The amount the field is scaled by to get the reward.\n        particle_type : int (default=0)\n\n        \"\"\"\n        super().__init__(particle_type=particle_type)\n        self.source = source / box_length\n        self.decay_fn = decay_function\n        self.reward_scale_factor = reward_scale_factor\n        self.box_length = box_length\n\n        # Class only attributes\n        self._historic_positions = {}\n\n    def initialize(self, colloids: List[Colloid]):\n        \"\"\"\n        Prepare the task for running.\n\n        Parameters\n        ----------\n        colloids : List[Colloid]\n                List of colloids to be used in the task.\n\n        Returns\n        -------\n        observable :\n                Returns the observable required for the task.\n        \"\"\"\n        for item in colloids:\n            if item.type == self.particle_type:\n                index = onp.copy(item.id)\n                position = onp.copy(item.pos) / self.box_length\n                self._historic_positions[str(index)] = position\n\n    def change_source(self, new_source: np.ndarray):\n        \"\"\"\n        Changes the concentration field source.\n\n        Parameters\n        ----------\n        new_source : np.ndarray\n                Coordinates of the new source.\n        \"\"\"\n        self.source = new_source\n\n    def compute_colloid_reward(self, index: int, colloids):\n        \"\"\"\n        Compute the reward for a single colloid.\n\n        Parameters\n        ----------\n        index : int\n                Index of the colloid to compute the reward for.\n\n        Returns\n        -------\n        reward : float\n                Reward for the colloid.\n        \"\"\"\n        colloid_id = onp.copy(colloids[index].id)\n        # Get the current position of the colloid\n        current_position = onp.copy(colloids[index].pos) / self.box_length\n\n        # Get the old position of the colloid\n        old_position = self._historic_positions[str(colloid_id)]\n\n        # Compute the distance from the source\n        current_distance = np.linalg.norm(current_position - self.source)\n        old_distance = np.linalg.norm(old_position - self.source)\n\n        # Compute difference in scaled_distances\n        delta = self.decay_fn(current_distance) - self.decay_fn(old_distance)\n\n        # Compute the reward\n        reward = np.clip(self.reward_scale_factor * delta, 0.0, None)\n\n        # Update the historic position\n        self._historic_positions[str(colloid_id)] = current_position\n\n        return reward\n\n    def __call__(self, colloids: List[Colloid]):\n        \"\"\"\n        Compute the reward.\n\n        In this case of this task, the observable itself is the gradient of the field\n        that the colloid is swimming in. Therefore, the change is simply scaled and\n        returned.\n\n        Parameters\n        ----------\n        colloids : List[Colloid] (n_colloids, )\n                List of colloids to be used in the task.\n\n        Returns\n        -------\n        rewards : List[float] (n_colloids, )\n                Rewards for each colloid.\n        \"\"\"\n        colloid_indices = self.get_colloid_indices(colloids)\n\n        return np.array(\n            [self.compute_colloid_reward(index, colloids) for index in colloid_indices]\n        )\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing.__call__","title":"<code>__call__(colloids)</code>","text":"<p>Compute the reward.</p> <p>In this case of this task, the observable itself is the gradient of the field that the colloid is swimming in. Therefore, the change is simply scaled and returned.</p>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing.__call__--parameters","title":"Parameters","text":"<p>colloids : List[Colloid] (n_colloids, )         List of colloids to be used in the task.</p>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing.__call__--returns","title":"Returns","text":"<p>rewards : List[float] (n_colloids, )         Rewards for each colloid.</p> Source code in <code>swarmrl/tasks/searching/gradient_sensing.py</code> <pre><code>def __call__(self, colloids: List[Colloid]):\n    \"\"\"\n    Compute the reward.\n\n    In this case of this task, the observable itself is the gradient of the field\n    that the colloid is swimming in. Therefore, the change is simply scaled and\n    returned.\n\n    Parameters\n    ----------\n    colloids : List[Colloid] (n_colloids, )\n            List of colloids to be used in the task.\n\n    Returns\n    -------\n    rewards : List[float] (n_colloids, )\n            Rewards for each colloid.\n    \"\"\"\n    colloid_indices = self.get_colloid_indices(colloids)\n\n    return np.array(\n        [self.compute_colloid_reward(index, colloids) for index in colloid_indices]\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing.__init__","title":"<code>__init__(source=np.array([0, 0, 0]), decay_function=None, box_length=np.array([1.0, 1.0, 0.0]), reward_scale_factor=10, particle_type=0)</code>","text":"<p>Constructor for the find origin task.</p>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing.__init__--parameters","title":"Parameters","text":"<p>source : np.ndarray (default = (0, 0 0))         Source of the gradient. decay_function : callable (required=True)         A function that describes the decay of the field along one dimension.         This cannot be left None. The function should take a distance from the         source and return the magnitude of the field at this point. box_length : np.ndarray         Side length of the box. reward_scale_factor : int (default=10)         The amount the field is scaled by to get the reward. particle_type : int (default=0)</p> Source code in <code>swarmrl/tasks/searching/gradient_sensing.py</code> <pre><code>def __init__(\n    self,\n    source: np.ndarray = np.array([0, 0, 0]),\n    decay_function: callable = None,\n    box_length: np.ndarray = np.array([1.0, 1.0, 0.0]),\n    reward_scale_factor: int = 10,\n    particle_type: int = 0,\n):\n    \"\"\"\n    Constructor for the find origin task.\n\n    Parameters\n    ----------\n    source : np.ndarray (default = (0, 0 0))\n            Source of the gradient.\n    decay_function : callable (required=True)\n            A function that describes the decay of the field along one dimension.\n            This cannot be left None. The function should take a distance from the\n            source and return the magnitude of the field at this point.\n    box_length : np.ndarray\n            Side length of the box.\n    reward_scale_factor : int (default=10)\n            The amount the field is scaled by to get the reward.\n    particle_type : int (default=0)\n\n    \"\"\"\n    super().__init__(particle_type=particle_type)\n    self.source = source / box_length\n    self.decay_fn = decay_function\n    self.reward_scale_factor = reward_scale_factor\n    self.box_length = box_length\n\n    # Class only attributes\n    self._historic_positions = {}\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing.change_source","title":"<code>change_source(new_source)</code>","text":"<p>Changes the concentration field source.</p>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing.change_source--parameters","title":"Parameters","text":"<p>new_source : np.ndarray         Coordinates of the new source.</p> Source code in <code>swarmrl/tasks/searching/gradient_sensing.py</code> <pre><code>def change_source(self, new_source: np.ndarray):\n    \"\"\"\n    Changes the concentration field source.\n\n    Parameters\n    ----------\n    new_source : np.ndarray\n            Coordinates of the new source.\n    \"\"\"\n    self.source = new_source\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing.compute_colloid_reward","title":"<code>compute_colloid_reward(index, colloids)</code>","text":"<p>Compute the reward for a single colloid.</p>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing.compute_colloid_reward--parameters","title":"Parameters","text":"<p>index : int         Index of the colloid to compute the reward for.</p>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing.compute_colloid_reward--returns","title":"Returns","text":"<p>reward : float         Reward for the colloid.</p> Source code in <code>swarmrl/tasks/searching/gradient_sensing.py</code> <pre><code>def compute_colloid_reward(self, index: int, colloids):\n    \"\"\"\n    Compute the reward for a single colloid.\n\n    Parameters\n    ----------\n    index : int\n            Index of the colloid to compute the reward for.\n\n    Returns\n    -------\n    reward : float\n            Reward for the colloid.\n    \"\"\"\n    colloid_id = onp.copy(colloids[index].id)\n    # Get the current position of the colloid\n    current_position = onp.copy(colloids[index].pos) / self.box_length\n\n    # Get the old position of the colloid\n    old_position = self._historic_positions[str(colloid_id)]\n\n    # Compute the distance from the source\n    current_distance = np.linalg.norm(current_position - self.source)\n    old_distance = np.linalg.norm(old_position - self.source)\n\n    # Compute difference in scaled_distances\n    delta = self.decay_fn(current_distance) - self.decay_fn(old_distance)\n\n    # Compute the reward\n    reward = np.clip(self.reward_scale_factor * delta, 0.0, None)\n\n    # Update the historic position\n    self._historic_positions[str(colloid_id)] = current_position\n\n    return reward\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing.initialize","title":"<code>initialize(colloids)</code>","text":"<p>Prepare the task for running.</p>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing.initialize--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids to be used in the task.</p>"},{"location":"pages/api/swarmrl.tasks.searching.gradient_sensing/#swarmrl.tasks.searching.gradient_sensing.GradientSensing.initialize--returns","title":"Returns","text":"<p>observable :         Returns the observable required for the task.</p> Source code in <code>swarmrl/tasks/searching/gradient_sensing.py</code> <pre><code>def initialize(self, colloids: List[Colloid]):\n    \"\"\"\n    Prepare the task for running.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids to be used in the task.\n\n    Returns\n    -------\n    observable :\n            Returns the observable required for the task.\n    \"\"\"\n    for item in colloids:\n        if item.type == self.particle_type:\n            index = onp.copy(item.id)\n            position = onp.copy(item.pos) / self.box_length\n            self._historic_positions[str(index)] = position\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.searching.species_search/","title":"swarmrl.tasks.searching.species_search Module API Reference","text":"<p>Class for the species search task.</p>"},{"location":"pages/api/swarmrl.tasks.searching.species_search/#swarmrl.tasks.searching.species_search.SpeciesSearch","title":"<code>SpeciesSearch</code>","text":"<p>             Bases: <code>Task</code></p> <p>Class for the species search task.</p> Source code in <code>swarmrl/tasks/searching/species_search.py</code> <pre><code>class SpeciesSearch(Task):\n    \"\"\"\n    Class for the species search task.\n    \"\"\"\n\n    def __init__(\n        self,\n        decay_fn: callable,\n        box_length: np.ndarray,\n        sensing_type: int = 0,\n        avoid: bool = False,\n        scale_factor: int = 100,\n        particle_type: int = 0,\n    ):\n        \"\"\"\n        Constructor for the observable.\n\n        Parameters\n        ----------\n        decay_fn : callable\n                Decay function of the field.\n        box_size : np.ndarray\n                Array for scaling of the distances.\n        sensing_type : int (default=0)\n                Type of particle to sense.\n        scale_factor : int (default=100)\n                Scaling factor for the observable.\n        avoid : bool (default=False)\n                Whether to avoid or move to the sensing type.\n        particle_type : int (default=0)\n                Particle type to compute the observable for.\n        \"\"\"\n        super().__init__(particle_type=particle_type)\n\n        self.decay_fn = decay_fn\n        self.box_length = box_length\n        self.sensing_type = sensing_type\n        self.scale_factor = scale_factor\n        self.avoid = avoid\n\n        self.historical_field = {}\n\n        self.task_fn = jax.vmap(\n            self.compute_single_particle_task, in_axes=(0, 0, None, 0)\n        )\n\n    def initialize(self, colloids: List[Colloid]):\n        \"\"\"\n        Initialize the observable with starting positions of the colloids.\n\n        Parameters\n        ----------\n        colloids : List[Colloid]\n                List of colloids with which to initialize the observable.\n\n        Returns\n        -------\n        Updates the class state.\n        \"\"\"\n        reference_ids = self.get_colloid_indices(colloids)\n        historic_values = np.zeros(len(reference_ids))\n\n        positions = []\n        indices = []\n        for index in reference_ids:\n            indices.append(colloids[index].id)\n            positions.append(colloids[index].pos)\n\n        test_points = np.array(\n            [colloid.pos for colloid in colloids if colloid.type == self.sensing_type]\n        )\n\n        out_indices, _, field_values = self.task_fn(\n            np.array(indices), np.array(positions), test_points, historic_values\n        )\n\n        for index, value in zip(out_indices, onp.array(field_values)):\n            self.historical_field[str(index)] = value\n\n    def compute_single_particle_task(\n        self,\n        index: int,\n        reference_position: np.ndarray,\n        test_positions: np.ndarray,\n        historic_value: float,\n    ) -&gt; tuple:\n        \"\"\"\n        Compute the task for a single colloid.\n\n        Parameters\n        ----------\n        index : int\n                Index of the colloid to compute the observable for.\n        reference_position : np.ndarray (3,)\n                Position of the reference colloid.\n        test_positions : np.ndarray (n_colloids, 3)\n                Positions of the test colloids.\n        historic_value : float\n                Historic value of the observable.\n\n        Returns\n        -------\n        tuple (index, task_value)\n        index : int\n                Index of the colloid to compute the observable for.\n        task_value : float\n                Value of the task.\n        \"\"\"\n        distances = np.linalg.norm(\n            (test_positions - reference_position) / self.box_length, axis=-1\n        )\n        indices = np.asarray(np.nonzero(distances, size=distances.shape[0] - 1))\n        distances = np.take(distances, indices, axis=0)\n        field_value = self.decay_fn(distances).sum()\n\n        return index, field_value - historic_value, field_value\n\n    def __call__(self, colloids: List[Colloid]):\n        \"\"\"\n        Compute the reward on the colloids.\n\n        Parameters\n        ----------\n        colloids : List[Colloid] (n_colloids, )\n                List of all colloids in the system.\n\n        Returns\n        -------\n        rewards : List[float] (n_colloids, dimension)\n                List of rewards, one for each colloid.\n        \"\"\"\n        if self.historical_field == {}:\n            msg = (\n                f\"{type(self).__name__} requires initialization. Please set the \"\n                \"initialize attribute of the gym to true and try again.\"\n            )\n            raise ValueError(msg)\n\n        reference_ids = self.get_colloid_indices(colloids)\n        positions = []\n        indices = []\n        historic_values = []\n        for index in reference_ids:\n            indices.append(colloids[index].id)\n            positions.append(colloids[index].pos)\n            historic_values.append(self.historical_field[str(colloids[index].id)])\n\n        test_points = np.array(\n            [colloid.pos for colloid in colloids if colloid.type == self.sensing_type]\n        )\n\n        out_indices, delta_values, field_values = self.task_fn(\n            np.array(indices),\n            np.array(positions),\n            test_points,\n            np.array(historic_values),\n        )\n\n        for index, value in zip(out_indices, onp.array(field_values)):\n            self.historical_field[str(index)] = value\n\n        if self.avoid:\n            rewards = np.clip(delta_values, None, 0)\n        else:\n            rewards = np.clip(delta_values, 0, None)\n\n        return self.scale_factor * rewards\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.searching.species_search/#swarmrl.tasks.searching.species_search.SpeciesSearch.__call__","title":"<code>__call__(colloids)</code>","text":"<p>Compute the reward on the colloids.</p>"},{"location":"pages/api/swarmrl.tasks.searching.species_search/#swarmrl.tasks.searching.species_search.SpeciesSearch.__call__--parameters","title":"Parameters","text":"<p>colloids : List[Colloid] (n_colloids, )         List of all colloids in the system.</p>"},{"location":"pages/api/swarmrl.tasks.searching.species_search/#swarmrl.tasks.searching.species_search.SpeciesSearch.__call__--returns","title":"Returns","text":"<p>rewards : List[float] (n_colloids, dimension)         List of rewards, one for each colloid.</p> Source code in <code>swarmrl/tasks/searching/species_search.py</code> <pre><code>def __call__(self, colloids: List[Colloid]):\n    \"\"\"\n    Compute the reward on the colloids.\n\n    Parameters\n    ----------\n    colloids : List[Colloid] (n_colloids, )\n            List of all colloids in the system.\n\n    Returns\n    -------\n    rewards : List[float] (n_colloids, dimension)\n            List of rewards, one for each colloid.\n    \"\"\"\n    if self.historical_field == {}:\n        msg = (\n            f\"{type(self).__name__} requires initialization. Please set the \"\n            \"initialize attribute of the gym to true and try again.\"\n        )\n        raise ValueError(msg)\n\n    reference_ids = self.get_colloid_indices(colloids)\n    positions = []\n    indices = []\n    historic_values = []\n    for index in reference_ids:\n        indices.append(colloids[index].id)\n        positions.append(colloids[index].pos)\n        historic_values.append(self.historical_field[str(colloids[index].id)])\n\n    test_points = np.array(\n        [colloid.pos for colloid in colloids if colloid.type == self.sensing_type]\n    )\n\n    out_indices, delta_values, field_values = self.task_fn(\n        np.array(indices),\n        np.array(positions),\n        test_points,\n        np.array(historic_values),\n    )\n\n    for index, value in zip(out_indices, onp.array(field_values)):\n        self.historical_field[str(index)] = value\n\n    if self.avoid:\n        rewards = np.clip(delta_values, None, 0)\n    else:\n        rewards = np.clip(delta_values, 0, None)\n\n    return self.scale_factor * rewards\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.searching.species_search/#swarmrl.tasks.searching.species_search.SpeciesSearch.__init__","title":"<code>__init__(decay_fn, box_length, sensing_type=0, avoid=False, scale_factor=100, particle_type=0)</code>","text":"<p>Constructor for the observable.</p>"},{"location":"pages/api/swarmrl.tasks.searching.species_search/#swarmrl.tasks.searching.species_search.SpeciesSearch.__init__--parameters","title":"Parameters","text":"<p>decay_fn : callable         Decay function of the field. box_size : np.ndarray         Array for scaling of the distances. sensing_type : int (default=0)         Type of particle to sense. scale_factor : int (default=100)         Scaling factor for the observable. avoid : bool (default=False)         Whether to avoid or move to the sensing type. particle_type : int (default=0)         Particle type to compute the observable for.</p> Source code in <code>swarmrl/tasks/searching/species_search.py</code> <pre><code>def __init__(\n    self,\n    decay_fn: callable,\n    box_length: np.ndarray,\n    sensing_type: int = 0,\n    avoid: bool = False,\n    scale_factor: int = 100,\n    particle_type: int = 0,\n):\n    \"\"\"\n    Constructor for the observable.\n\n    Parameters\n    ----------\n    decay_fn : callable\n            Decay function of the field.\n    box_size : np.ndarray\n            Array for scaling of the distances.\n    sensing_type : int (default=0)\n            Type of particle to sense.\n    scale_factor : int (default=100)\n            Scaling factor for the observable.\n    avoid : bool (default=False)\n            Whether to avoid or move to the sensing type.\n    particle_type : int (default=0)\n            Particle type to compute the observable for.\n    \"\"\"\n    super().__init__(particle_type=particle_type)\n\n    self.decay_fn = decay_fn\n    self.box_length = box_length\n    self.sensing_type = sensing_type\n    self.scale_factor = scale_factor\n    self.avoid = avoid\n\n    self.historical_field = {}\n\n    self.task_fn = jax.vmap(\n        self.compute_single_particle_task, in_axes=(0, 0, None, 0)\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.searching.species_search/#swarmrl.tasks.searching.species_search.SpeciesSearch.compute_single_particle_task","title":"<code>compute_single_particle_task(index, reference_position, test_positions, historic_value)</code>","text":"<p>Compute the task for a single colloid.</p>"},{"location":"pages/api/swarmrl.tasks.searching.species_search/#swarmrl.tasks.searching.species_search.SpeciesSearch.compute_single_particle_task--parameters","title":"Parameters","text":"<p>index : int         Index of the colloid to compute the observable for. reference_position : np.ndarray (3,)         Position of the reference colloid. test_positions : np.ndarray (n_colloids, 3)         Positions of the test colloids. historic_value : float         Historic value of the observable.</p>"},{"location":"pages/api/swarmrl.tasks.searching.species_search/#swarmrl.tasks.searching.species_search.SpeciesSearch.compute_single_particle_task--returns","title":"Returns","text":"<p>tuple (index, task_value) index : int         Index of the colloid to compute the observable for. task_value : float         Value of the task.</p> Source code in <code>swarmrl/tasks/searching/species_search.py</code> <pre><code>def compute_single_particle_task(\n    self,\n    index: int,\n    reference_position: np.ndarray,\n    test_positions: np.ndarray,\n    historic_value: float,\n) -&gt; tuple:\n    \"\"\"\n    Compute the task for a single colloid.\n\n    Parameters\n    ----------\n    index : int\n            Index of the colloid to compute the observable for.\n    reference_position : np.ndarray (3,)\n            Position of the reference colloid.\n    test_positions : np.ndarray (n_colloids, 3)\n            Positions of the test colloids.\n    historic_value : float\n            Historic value of the observable.\n\n    Returns\n    -------\n    tuple (index, task_value)\n    index : int\n            Index of the colloid to compute the observable for.\n    task_value : float\n            Value of the task.\n    \"\"\"\n    distances = np.linalg.norm(\n        (test_positions - reference_position) / self.box_length, axis=-1\n    )\n    indices = np.asarray(np.nonzero(distances, size=distances.shape[0] - 1))\n    distances = np.take(distances, indices, axis=0)\n    field_value = self.decay_fn(distances).sum()\n\n    return index, field_value - historic_value, field_value\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.searching.species_search/#swarmrl.tasks.searching.species_search.SpeciesSearch.initialize","title":"<code>initialize(colloids)</code>","text":"<p>Initialize the observable with starting positions of the colloids.</p>"},{"location":"pages/api/swarmrl.tasks.searching.species_search/#swarmrl.tasks.searching.species_search.SpeciesSearch.initialize--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids with which to initialize the observable.</p>"},{"location":"pages/api/swarmrl.tasks.searching.species_search/#swarmrl.tasks.searching.species_search.SpeciesSearch.initialize--returns","title":"Returns","text":"<p>Updates the class state.</p> Source code in <code>swarmrl/tasks/searching/species_search.py</code> <pre><code>def initialize(self, colloids: List[Colloid]):\n    \"\"\"\n    Initialize the observable with starting positions of the colloids.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids with which to initialize the observable.\n\n    Returns\n    -------\n    Updates the class state.\n    \"\"\"\n    reference_ids = self.get_colloid_indices(colloids)\n    historic_values = np.zeros(len(reference_ids))\n\n    positions = []\n    indices = []\n    for index in reference_ids:\n        indices.append(colloids[index].id)\n        positions.append(colloids[index].pos)\n\n    test_points = np.array(\n        [colloid.pos for colloid in colloids if colloid.type == self.sensing_type]\n    )\n\n    out_indices, _, field_values = self.task_fn(\n        np.array(indices), np.array(positions), test_points, historic_values\n    )\n\n    for index, value in zip(out_indices, onp.array(field_values)):\n        self.historical_field[str(index)] = value\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.task/","title":"swarmrl.tasks.task Module API Reference","text":"<p>Module for the parent class of the tasks.</p>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task--notes","title":"Notes","text":"<p>The reward classes handle the computation of the reward from an environment and compute the loss for the models to train on.</p>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task","title":"<code>Task</code>","text":"<p>Parent class for the reinforcement learning tasks.</p> Source code in <code>swarmrl/tasks/task.py</code> <pre><code>class Task:\n    \"\"\"\n    Parent class for the reinforcement learning tasks.\n    \"\"\"\n\n    def __init__(self, particle_type: int = 0):\n        \"\"\"\n        Constructor for the reward class.\n\n        Parameters\n        ----------\n        particle_type : int (default=0)\n                Particle type to compute the reward for.\n        \"\"\"\n        self.particle_type = particle_type\n\n        self._kill_switch = False\n\n    @property\n    def kill_switch(self):\n        \"\"\"\n        Kill switch property of the task\n        \"\"\"\n        return self._kill_switch\n\n    @kill_switch.setter\n    def kill_switch(self, value: bool):\n        \"\"\"\n        Set the kill switch property.\n\n        Parameters\n        ----------\n        value : bool\n            Value to set the kill switch to.\n        \"\"\"\n        self._kill_switch = value\n\n    def initialize(self, colloids: List[Colloid]):\n        \"\"\"\n        Initialize the task with starting positions of the colloids.\n\n        The parent method will just pass. This is because some observables\n        might not need to be initialized. Those that do need to be initialized\n        will override this method.\n\n        Parameters\n        ----------\n        colloids : List[Colloid]\n                List of colloids with which to initialize the observable.\n\n        Returns\n        -------\n        Updates the class state.\n        \"\"\"\n        pass\n\n    def get_colloid_indices(self, colloids: List[Colloid], p_type: int = None):\n        \"\"\"\n        Get the indices of the colloids in the observable of a specific type.\n\n        Parameters\n        ----------\n        colloids : List[Colloid]\n                List of colloids from which to get the indices.\n        p_type : int (default=None)\n                Type of the colloids to get the indices for. If None, the\n                particle_type attribute of the class is used.\n\n\n        Returns\n        -------\n        indices : List[int]\n                List of indices for the colloids of a particular type.\n        \"\"\"\n        if p_type is None:\n            p_type = self.particle_type\n\n        indices = []\n        for i, colloid in enumerate(colloids):\n            if colloid.type == p_type:\n                indices.append(i)\n\n        return indices\n\n    def __call__(self, colloids: List[Colloid]) -&gt; float:\n        \"\"\"\n        Compute the reward on the whole group of particles.\n\n        Parameters\n        ----------\n        colloids : List[Colloid] (n_colloids, dimension)\n                List of colloid objects in the system.\n\n        Returns\n        -------\n        Reward : float\n                Reward for the current state.\n\n        Examples\n        --------\n        my_task = Task()\n        reward = my_task(state)\n        \"\"\"\n        raise NotImplementedError(\"Implemented in child class.\")\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task.kill_switch","title":"<code>kill_switch</code>  <code>property</code> <code>writable</code>","text":"<p>Kill switch property of the task</p>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task.__call__","title":"<code>__call__(colloids)</code>","text":"<p>Compute the reward on the whole group of particles.</p>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task.__call__--parameters","title":"Parameters","text":"<p>colloids : List[Colloid] (n_colloids, dimension)         List of colloid objects in the system.</p>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task.__call__--returns","title":"Returns","text":"<p>Reward : float         Reward for the current state.</p>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task.__call__--examples","title":"Examples","text":"<p>my_task = Task() reward = my_task(state)</p> Source code in <code>swarmrl/tasks/task.py</code> <pre><code>def __call__(self, colloids: List[Colloid]) -&gt; float:\n    \"\"\"\n    Compute the reward on the whole group of particles.\n\n    Parameters\n    ----------\n    colloids : List[Colloid] (n_colloids, dimension)\n            List of colloid objects in the system.\n\n    Returns\n    -------\n    Reward : float\n            Reward for the current state.\n\n    Examples\n    --------\n    my_task = Task()\n    reward = my_task(state)\n    \"\"\"\n    raise NotImplementedError(\"Implemented in child class.\")\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task.__init__","title":"<code>__init__(particle_type=0)</code>","text":"<p>Constructor for the reward class.</p>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task.__init__--parameters","title":"Parameters","text":"<p>particle_type : int (default=0)         Particle type to compute the reward for.</p> Source code in <code>swarmrl/tasks/task.py</code> <pre><code>def __init__(self, particle_type: int = 0):\n    \"\"\"\n    Constructor for the reward class.\n\n    Parameters\n    ----------\n    particle_type : int (default=0)\n            Particle type to compute the reward for.\n    \"\"\"\n    self.particle_type = particle_type\n\n    self._kill_switch = False\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task.get_colloid_indices","title":"<code>get_colloid_indices(colloids, p_type=None)</code>","text":"<p>Get the indices of the colloids in the observable of a specific type.</p>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task.get_colloid_indices--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids from which to get the indices. p_type : int (default=None)         Type of the colloids to get the indices for. If None, the         particle_type attribute of the class is used.</p>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task.get_colloid_indices--returns","title":"Returns","text":"<p>indices : List[int]         List of indices for the colloids of a particular type.</p> Source code in <code>swarmrl/tasks/task.py</code> <pre><code>def get_colloid_indices(self, colloids: List[Colloid], p_type: int = None):\n    \"\"\"\n    Get the indices of the colloids in the observable of a specific type.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids from which to get the indices.\n    p_type : int (default=None)\n            Type of the colloids to get the indices for. If None, the\n            particle_type attribute of the class is used.\n\n\n    Returns\n    -------\n    indices : List[int]\n            List of indices for the colloids of a particular type.\n    \"\"\"\n    if p_type is None:\n        p_type = self.particle_type\n\n    indices = []\n    for i, colloid in enumerate(colloids):\n        if colloid.type == p_type:\n            indices.append(i)\n\n    return indices\n</code></pre>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task.initialize","title":"<code>initialize(colloids)</code>","text":"<p>Initialize the task with starting positions of the colloids.</p> <p>The parent method will just pass. This is because some observables might not need to be initialized. Those that do need to be initialized will override this method.</p>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task.initialize--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids with which to initialize the observable.</p>"},{"location":"pages/api/swarmrl.tasks.task/#swarmrl.tasks.task.Task.initialize--returns","title":"Returns","text":"<p>Updates the class state.</p> Source code in <code>swarmrl/tasks/task.py</code> <pre><code>def initialize(self, colloids: List[Colloid]):\n    \"\"\"\n    Initialize the task with starting positions of the colloids.\n\n    The parent method will just pass. This is because some observables\n    might not need to be initialized. Those that do need to be initialized\n    will override this method.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids with which to initialize the observable.\n\n    Returns\n    -------\n    Updates the class state.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"pages/api/swarmrl.trainers.continuous_trainer/","title":"swarmrl.trainers.continuous_trainer Module API Reference","text":"<p>Module to implement a simple multi-layer perceptron for the colloids.</p>"},{"location":"pages/api/swarmrl.trainers.continuous_trainer/#swarmrl.trainers.continuous_trainer.ContinuousTrainer","title":"<code>ContinuousTrainer</code>","text":"<p>             Bases: <code>Trainer</code></p> <p>Class for the simple MLP RL implementation.</p>"},{"location":"pages/api/swarmrl.trainers.continuous_trainer/#swarmrl.trainers.continuous_trainer.ContinuousTrainer--attributes","title":"Attributes","text":"<p>rl_protocols : list(protocol)         A list of RL protocols to use in the simulation.</p> Source code in <code>swarmrl/trainers/continuous_trainer.py</code> <pre><code>class ContinuousTrainer(Trainer):\n    \"\"\"\n    Class for the simple MLP RL implementation.\n\n    Attributes\n    ----------\n    rl_protocols : list(protocol)\n            A list of RL protocols to use in the simulation.\n    \"\"\"\n\n    def perform_rl_training(\n        self,\n        system_runner: Engine,\n        n_episodes: int,\n        episode_length: int,\n        load_bar: bool = True,\n    ):\n        \"\"\"\n        Perform the RL training.\n\n        Parameters\n        ----------\n        system_runner : Engine\n                Engine used to perform steps for each agent.\n        n_episodes : int\n                Number of episodes to use in the training.\n        episode_length : int\n                Number of time steps in one episode.\n        load_bar : bool (default=True)\n                If true, show a progress bar.\n        \"\"\"\n        self.engine = system_runner\n        rewards = [0.0]\n        current_reward = 0.0\n        episode = 0\n        force_fn = self.initialize_training()\n\n        # Initialize the tasks and observables.\n        for agent in self.agents.values():\n            agent.reset_agent(self.engine.colloids)\n\n        progress = Progress(\n            \"Episode: {task.fields[Episode]}\",\n            BarColumn(),\n            \"Episode reward: {task.fields[current_reward]} Running Reward:\"\n            \" {task.fields[running_reward]}\",\n            TimeRemainingColumn(),\n        )\n\n        with progress:\n            task = progress.add_task(\n                \"RL Training\",\n                total=n_episodes,\n                Episode=episode,\n                current_reward=current_reward,\n                running_reward=np.mean(rewards),\n                visible=load_bar,\n            )\n            for _ in range(n_episodes):\n                self.engine.integrate(episode_length, force_fn)\n                force_fn, current_reward, killed = self.update_rl()\n\n                if killed:\n                    print(\"Simulation has been ended by the task, ending training.\")\n                    system_runner.finalize()\n                    break\n\n                rewards.append(current_reward)\n                episode += 1\n                progress.update(\n                    task,\n                    advance=1,\n                    Episode=episode,\n                    current_reward=np.round(current_reward, 2),\n                    running_reward=np.round(np.mean(rewards[-10:]), 2),\n                )\n\n        return np.array(rewards)\n</code></pre>"},{"location":"pages/api/swarmrl.trainers.continuous_trainer/#swarmrl.trainers.continuous_trainer.ContinuousTrainer.perform_rl_training","title":"<code>perform_rl_training(system_runner, n_episodes, episode_length, load_bar=True)</code>","text":"<p>Perform the RL training.</p>"},{"location":"pages/api/swarmrl.trainers.continuous_trainer/#swarmrl.trainers.continuous_trainer.ContinuousTrainer.perform_rl_training--parameters","title":"Parameters","text":"<p>system_runner : Engine         Engine used to perform steps for each agent. n_episodes : int         Number of episodes to use in the training. episode_length : int         Number of time steps in one episode. load_bar : bool (default=True)         If true, show a progress bar.</p> Source code in <code>swarmrl/trainers/continuous_trainer.py</code> <pre><code>def perform_rl_training(\n    self,\n    system_runner: Engine,\n    n_episodes: int,\n    episode_length: int,\n    load_bar: bool = True,\n):\n    \"\"\"\n    Perform the RL training.\n\n    Parameters\n    ----------\n    system_runner : Engine\n            Engine used to perform steps for each agent.\n    n_episodes : int\n            Number of episodes to use in the training.\n    episode_length : int\n            Number of time steps in one episode.\n    load_bar : bool (default=True)\n            If true, show a progress bar.\n    \"\"\"\n    self.engine = system_runner\n    rewards = [0.0]\n    current_reward = 0.0\n    episode = 0\n    force_fn = self.initialize_training()\n\n    # Initialize the tasks and observables.\n    for agent in self.agents.values():\n        agent.reset_agent(self.engine.colloids)\n\n    progress = Progress(\n        \"Episode: {task.fields[Episode]}\",\n        BarColumn(),\n        \"Episode reward: {task.fields[current_reward]} Running Reward:\"\n        \" {task.fields[running_reward]}\",\n        TimeRemainingColumn(),\n    )\n\n    with progress:\n        task = progress.add_task(\n            \"RL Training\",\n            total=n_episodes,\n            Episode=episode,\n            current_reward=current_reward,\n            running_reward=np.mean(rewards),\n            visible=load_bar,\n        )\n        for _ in range(n_episodes):\n            self.engine.integrate(episode_length, force_fn)\n            force_fn, current_reward, killed = self.update_rl()\n\n            if killed:\n                print(\"Simulation has been ended by the task, ending training.\")\n                system_runner.finalize()\n                break\n\n            rewards.append(current_reward)\n            episode += 1\n            progress.update(\n                task,\n                advance=1,\n                Episode=episode,\n                current_reward=np.round(current_reward, 2),\n                running_reward=np.round(np.mean(rewards[-10:]), 2),\n            )\n\n    return np.array(rewards)\n</code></pre>"},{"location":"pages/api/swarmrl.trainers.episodic_trainer/","title":"swarmrl.trainers.episodic_trainer Module API Reference","text":"<p>Module for the EpisodicTrainer</p>"},{"location":"pages/api/swarmrl.trainers.episodic_trainer/#swarmrl.trainers.episodic_trainer.EpisodicTrainer","title":"<code>EpisodicTrainer</code>","text":"<p>             Bases: <code>Trainer</code></p> <p>Class for the simple MLP RL implementation.</p>"},{"location":"pages/api/swarmrl.trainers.episodic_trainer/#swarmrl.trainers.episodic_trainer.EpisodicTrainer--attributes","title":"Attributes","text":"<p>rl_protocols : list(protocol)         A list of RL protocols to use in the simulation.</p> Source code in <code>swarmrl/trainers/episodic_trainer.py</code> <pre><code>class EpisodicTrainer(Trainer):\n    \"\"\"\n    Class for the simple MLP RL implementation.\n\n    Attributes\n    ----------\n    rl_protocols : list(protocol)\n            A list of RL protocols to use in the simulation.\n    \"\"\"\n\n    def perform_rl_training(\n        self,\n        get_engine: callable,\n        system: \"System\",\n        n_episodes: int,\n        episode_length: int,\n        reset_frequency: int = 1,\n        load_bar: bool = True,\n    ):\n        \"\"\"\n        Perform the RL training.\n\n        Parameters\n        ----------\n        get_engine : callable\n                Function to get the engine for the simulation.\n        system_runner : espressomd.System\n                Engine used to perform steps for each agent.\n        n_episodes : int\n                Number of episodes to use in the training.\n        episode_length : int\n                Number of time steps in one episode.\n        reset_frequency : int (default=1)\n                After how many episodes is the simulation reset.\n        load_bar : bool (default=True)\n                If true, show a progress bar.\n\n        Notes\n        -----\n        If you are using semi-episodic training but your task kills the\n        simulation, the system will be reset.\n        \"\"\"\n        killed = False\n        rewards = [0.0]\n        current_reward = 0.0\n        force_fn = self.initialize_training()\n\n        progress = Progress(\n            \"Episode: {task.fields[Episode]}\",\n            BarColumn(),\n            \"Episode reward: {task.fields[current_reward]} Running Reward:\"\n            \" {task.fields[running_reward]}\",\n            TimeRemainingColumn(),\n        )\n\n        with progress:\n            task = progress.add_task(\n                \"Episodic Training\",\n                total=n_episodes,\n                Episode=0,\n                current_reward=current_reward,\n                running_reward=np.mean(rewards),\n                visible=load_bar,\n            )\n            for episode in range(n_episodes):\n\n                # Check if the system should be reset.\n                if episode % reset_frequency == 0 or killed:\n                    self.engine = None\n                    self.engine = get_engine(system)\n\n                    # Initialize the tasks and observables.\n                    for agent in self.agents.values():\n                        agent.reset_agent(self.engine.colloids)\n\n                self.engine.integrate(episode_length, force_fn)\n\n                force_fn, current_reward, killed = self.update_rl()\n\n                rewards.append(current_reward)\n\n                episode += 1\n                progress.update(\n                    task,\n                    advance=1,\n                    Episode=episode,\n                    current_reward=np.round(current_reward, 2),\n                    running_reward=np.round(np.mean(rewards[-10:]), 2),\n                )\n                self.engine.finalize()\n\n        return np.array(rewards)\n</code></pre>"},{"location":"pages/api/swarmrl.trainers.episodic_trainer/#swarmrl.trainers.episodic_trainer.EpisodicTrainer.perform_rl_training","title":"<code>perform_rl_training(get_engine, system, n_episodes, episode_length, reset_frequency=1, load_bar=True)</code>","text":"<p>Perform the RL training.</p>"},{"location":"pages/api/swarmrl.trainers.episodic_trainer/#swarmrl.trainers.episodic_trainer.EpisodicTrainer.perform_rl_training--parameters","title":"Parameters","text":"<p>get_engine : callable         Function to get the engine for the simulation. system_runner : espressomd.System         Engine used to perform steps for each agent. n_episodes : int         Number of episodes to use in the training. episode_length : int         Number of time steps in one episode. reset_frequency : int (default=1)         After how many episodes is the simulation reset. load_bar : bool (default=True)         If true, show a progress bar.</p>"},{"location":"pages/api/swarmrl.trainers.episodic_trainer/#swarmrl.trainers.episodic_trainer.EpisodicTrainer.perform_rl_training--notes","title":"Notes","text":"<p>If you are using semi-episodic training but your task kills the simulation, the system will be reset.</p> Source code in <code>swarmrl/trainers/episodic_trainer.py</code> <pre><code>def perform_rl_training(\n    self,\n    get_engine: callable,\n    system: \"System\",\n    n_episodes: int,\n    episode_length: int,\n    reset_frequency: int = 1,\n    load_bar: bool = True,\n):\n    \"\"\"\n    Perform the RL training.\n\n    Parameters\n    ----------\n    get_engine : callable\n            Function to get the engine for the simulation.\n    system_runner : espressomd.System\n            Engine used to perform steps for each agent.\n    n_episodes : int\n            Number of episodes to use in the training.\n    episode_length : int\n            Number of time steps in one episode.\n    reset_frequency : int (default=1)\n            After how many episodes is the simulation reset.\n    load_bar : bool (default=True)\n            If true, show a progress bar.\n\n    Notes\n    -----\n    If you are using semi-episodic training but your task kills the\n    simulation, the system will be reset.\n    \"\"\"\n    killed = False\n    rewards = [0.0]\n    current_reward = 0.0\n    force_fn = self.initialize_training()\n\n    progress = Progress(\n        \"Episode: {task.fields[Episode]}\",\n        BarColumn(),\n        \"Episode reward: {task.fields[current_reward]} Running Reward:\"\n        \" {task.fields[running_reward]}\",\n        TimeRemainingColumn(),\n    )\n\n    with progress:\n        task = progress.add_task(\n            \"Episodic Training\",\n            total=n_episodes,\n            Episode=0,\n            current_reward=current_reward,\n            running_reward=np.mean(rewards),\n            visible=load_bar,\n        )\n        for episode in range(n_episodes):\n\n            # Check if the system should be reset.\n            if episode % reset_frequency == 0 or killed:\n                self.engine = None\n                self.engine = get_engine(system)\n\n                # Initialize the tasks and observables.\n                for agent in self.agents.values():\n                    agent.reset_agent(self.engine.colloids)\n\n            self.engine.integrate(episode_length, force_fn)\n\n            force_fn, current_reward, killed = self.update_rl()\n\n            rewards.append(current_reward)\n\n            episode += 1\n            progress.update(\n                task,\n                advance=1,\n                Episode=episode,\n                current_reward=np.round(current_reward, 2),\n                running_reward=np.round(np.mean(rewards[-10:]), 2),\n            )\n            self.engine.finalize()\n\n    return np.array(rewards)\n</code></pre>"},{"location":"pages/api/swarmrl.trainers.trainer/","title":"swarmrl.trainers.trainer Module API Reference","text":"<p>Module for the Trainer parent.</p>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer","title":"<code>Trainer</code>","text":"<p>Parent class for the RL Trainer.</p>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer--attributes","title":"Attributes","text":"<p>rl_protocols : list(protocol)         A list of RL protocols to use in the simulation. loss : Loss         An optimization method to compute the loss and update the model.</p> Source code in <code>swarmrl/trainers/trainer.py</code> <pre><code>class Trainer:\n    \"\"\"\n    Parent class for the RL Trainer.\n\n    Attributes\n    ----------\n    rl_protocols : list(protocol)\n            A list of RL protocols to use in the simulation.\n    loss : Loss\n            An optimization method to compute the loss and update the model.\n    \"\"\"\n\n    _engine = None\n\n    @property\n    def engine(self):\n        \"\"\"\n        Runner engine property.\n        \"\"\"\n        return self._engine\n\n    @engine.setter\n    def engine(self, value):\n        \"\"\"\n        Set the engine value.\n        \"\"\"\n        self._engine = value\n\n    def __init__(\n        self,\n        agents: List[ActorCriticAgent],\n    ):\n        \"\"\"\n        Constructor for the MLP RL.\n\n        Parameters\n        ----------\n        agents : list\n                A list of RL agents\n        loss : Loss\n                A loss model to use in the A-C loss computation.\n        \"\"\"\n        self.agents = {}\n\n        # Add the protocols to an easily accessible internal dict.\n        # TODO: Maybe turn into a dataclass? Not sure if it helps yet.\n        for agent in agents:\n            self.agents[str(agent.particle_type)] = agent\n\n    def initialize_training(self) -&gt; ForceFunction:\n        \"\"\"\n        Return an initialized interaction model.\n\n        Returns\n        -------\n        interaction_model : ForceFunction\n                Interaction model to start the simulation with.\n        \"\"\"\n\n        return ForceFunction(\n            agents=self.agents,\n        )\n\n    def update_rl(self) -&gt; Tuple[ForceFunction, np.ndarray]:\n        \"\"\"\n        Update the RL algorithm.\n\n        Returns\n        -------\n        interaction_model : MLModel\n                Interaction model to use in the next episode.\n        reward : np.ndarray\n                Current mean episode reward. This is returned for nice progress bars.\n        killed : bool\n                Whether or not the task has ended the training.\n        \"\"\"\n        reward = 0.0  # TODO: Separate between species and optimize visualization.\n        switches = []\n\n        for agent in self.agents.values():\n            if isinstance(agent, ActorCriticAgent):\n                ag_reward, ag_killed = agent.update_agent()\n                reward += np.mean(ag_reward)\n                switches.append(ag_killed)\n\n        # Create a new interaction model.\n        interaction_model = ForceFunction(agents=self.agents)\n        return interaction_model, np.array(reward), any(switches)\n\n    def export_models(self, directory: str = \"Models\"):\n        \"\"\"\n        Export the models to the specified directory.\n\n        Parameters\n        ----------\n        directory : str (default='Models')\n                Directory in which to save the models.\n\n        Returns\n        -------\n        Saves the actor and the critic to the specific directory.\n        \"\"\"\n        for agent in self.agents.values():\n            agent.save_agent(directory)\n\n    def restore_models(self, directory: str = \"Models\"):\n        \"\"\"\n        Export the models to the specified directory.\n\n        Parameters\n        ----------\n        directory : str (default='Models')\n                Directory from which to load the objects.\n\n        Returns\n        -------\n        Loads the actor and critic from the specific directory.\n        \"\"\"\n        for agent in self.agents.values():\n            agent.restore_agent(directory)\n\n    def initialize_models(self):\n        \"\"\"\n        Initialize all of the models in the gym.\n        \"\"\"\n        for agent in self.agents.values():\n            agent.initialize_network()\n\n    def perform_rl_training(self, **kwargs):\n        \"\"\"\n        Perform the RL training.\n\n        Parameters\n        ----------\n        **kwargs\n            All arguments related to the specific trainer.\n        \"\"\"\n        raise NotImplementedError(\"Implemented in child class\")\n</code></pre>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.engine","title":"<code>engine</code>  <code>property</code> <code>writable</code>","text":"<p>Runner engine property.</p>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.__init__","title":"<code>__init__(agents)</code>","text":"<p>Constructor for the MLP RL.</p>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.__init__--parameters","title":"Parameters","text":"<p>agents : list         A list of RL agents loss : Loss         A loss model to use in the A-C loss computation.</p> Source code in <code>swarmrl/trainers/trainer.py</code> <pre><code>def __init__(\n    self,\n    agents: List[ActorCriticAgent],\n):\n    \"\"\"\n    Constructor for the MLP RL.\n\n    Parameters\n    ----------\n    agents : list\n            A list of RL agents\n    loss : Loss\n            A loss model to use in the A-C loss computation.\n    \"\"\"\n    self.agents = {}\n\n    # Add the protocols to an easily accessible internal dict.\n    # TODO: Maybe turn into a dataclass? Not sure if it helps yet.\n    for agent in agents:\n        self.agents[str(agent.particle_type)] = agent\n</code></pre>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.export_models","title":"<code>export_models(directory='Models')</code>","text":"<p>Export the models to the specified directory.</p>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.export_models--parameters","title":"Parameters","text":"<p>directory : str (default='Models')         Directory in which to save the models.</p>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.export_models--returns","title":"Returns","text":"<p>Saves the actor and the critic to the specific directory.</p> Source code in <code>swarmrl/trainers/trainer.py</code> <pre><code>def export_models(self, directory: str = \"Models\"):\n    \"\"\"\n    Export the models to the specified directory.\n\n    Parameters\n    ----------\n    directory : str (default='Models')\n            Directory in which to save the models.\n\n    Returns\n    -------\n    Saves the actor and the critic to the specific directory.\n    \"\"\"\n    for agent in self.agents.values():\n        agent.save_agent(directory)\n</code></pre>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.initialize_models","title":"<code>initialize_models()</code>","text":"<p>Initialize all of the models in the gym.</p> Source code in <code>swarmrl/trainers/trainer.py</code> <pre><code>def initialize_models(self):\n    \"\"\"\n    Initialize all of the models in the gym.\n    \"\"\"\n    for agent in self.agents.values():\n        agent.initialize_network()\n</code></pre>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.initialize_training","title":"<code>initialize_training()</code>","text":"<p>Return an initialized interaction model.</p>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.initialize_training--returns","title":"Returns","text":"<p>interaction_model : ForceFunction         Interaction model to start the simulation with.</p> Source code in <code>swarmrl/trainers/trainer.py</code> <pre><code>def initialize_training(self) -&gt; ForceFunction:\n    \"\"\"\n    Return an initialized interaction model.\n\n    Returns\n    -------\n    interaction_model : ForceFunction\n            Interaction model to start the simulation with.\n    \"\"\"\n\n    return ForceFunction(\n        agents=self.agents,\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.perform_rl_training","title":"<code>perform_rl_training(**kwargs)</code>","text":"<p>Perform the RL training.</p>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.perform_rl_training--parameters","title":"Parameters","text":"<p>**kwargs     All arguments related to the specific trainer.</p> Source code in <code>swarmrl/trainers/trainer.py</code> <pre><code>def perform_rl_training(self, **kwargs):\n    \"\"\"\n    Perform the RL training.\n\n    Parameters\n    ----------\n    **kwargs\n        All arguments related to the specific trainer.\n    \"\"\"\n    raise NotImplementedError(\"Implemented in child class\")\n</code></pre>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.restore_models","title":"<code>restore_models(directory='Models')</code>","text":"<p>Export the models to the specified directory.</p>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.restore_models--parameters","title":"Parameters","text":"<p>directory : str (default='Models')         Directory from which to load the objects.</p>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.restore_models--returns","title":"Returns","text":"<p>Loads the actor and critic from the specific directory.</p> Source code in <code>swarmrl/trainers/trainer.py</code> <pre><code>def restore_models(self, directory: str = \"Models\"):\n    \"\"\"\n    Export the models to the specified directory.\n\n    Parameters\n    ----------\n    directory : str (default='Models')\n            Directory from which to load the objects.\n\n    Returns\n    -------\n    Loads the actor and critic from the specific directory.\n    \"\"\"\n    for agent in self.agents.values():\n        agent.restore_agent(directory)\n</code></pre>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.update_rl","title":"<code>update_rl()</code>","text":"<p>Update the RL algorithm.</p>"},{"location":"pages/api/swarmrl.trainers.trainer/#swarmrl.trainers.trainer.Trainer.update_rl--returns","title":"Returns","text":"<p>interaction_model : MLModel         Interaction model to use in the next episode. reward : np.ndarray         Current mean episode reward. This is returned for nice progress bars. killed : bool         Whether or not the task has ended the training.</p> Source code in <code>swarmrl/trainers/trainer.py</code> <pre><code>def update_rl(self) -&gt; Tuple[ForceFunction, np.ndarray]:\n    \"\"\"\n    Update the RL algorithm.\n\n    Returns\n    -------\n    interaction_model : MLModel\n            Interaction model to use in the next episode.\n    reward : np.ndarray\n            Current mean episode reward. This is returned for nice progress bars.\n    killed : bool\n            Whether or not the task has ended the training.\n    \"\"\"\n    reward = 0.0  # TODO: Separate between species and optimize visualization.\n    switches = []\n\n    for agent in self.agents.values():\n        if isinstance(agent, ActorCriticAgent):\n            ag_reward, ag_killed = agent.update_agent()\n            reward += np.mean(ag_reward)\n            switches.append(ag_killed)\n\n    # Create a new interaction model.\n    interaction_model = ForceFunction(agents=self.agents)\n    return interaction_model, np.array(reward), any(switches)\n</code></pre>"},{"location":"pages/api/swarmrl.training_routines.ensemble_submit/","title":"swarmrl.training_routines.ensemble_submit Module API Reference","text":"<p>Class for submitting many jobs in parallel to a cluster.</p>"},{"location":"pages/api/swarmrl.training_routines.ensemble_submit/#swarmrl.training_routines.ensemble_submit.EnsembleTraining","title":"<code>EnsembleTraining</code>","text":"<p>Class for ensemble training.</p> Source code in <code>swarmrl/training_routines/ensemble_submit.py</code> <pre><code>class EnsembleTraining:\n    \"\"\"\n    Class for ensemble training.\n    \"\"\"\n\n    def __init__(\n        self,\n        trainer: ContinuousTrainer,\n        simulation_runner_generator: callable,\n        number_of_ensembles: int,\n        episode_length: int,\n        n_episodes: int,\n        n_parallel_jobs: int = None,\n        load_path: Path = None,\n        cluster: JobQueueCluster = None,\n        output_dir: Path = Path(\"./ensembled-training\"),\n    ) -&gt; None:\n        \"\"\"\n        Constructor for the ensemble training routine.\n\n        Parameters\n        ----------\n        trainer : Trainer\n            The trainer used to train.\n        number_of_ensmbles : int\n            The number of ensembles to train.\n        episode_length : int\n            The length of each episode.\n        n_episodes : int\n            The number of episodes to train for.\n        simulation_runner_generator : callable\n            A callable function that returns a simulation runner.\n        n_parallel_jobs : int\n            The number of parallel jobs to run.\n        cluster : JobQueueCluster\n            The cluster to run the jobs on.\n            If None, the jobs will be run locally.\n        load_path : Path or str or None (default)\n            The path to load the models from.\n        output_dir : Path or str or None (default)\n            The directory to save the models to.\n\n        \"\"\"\n        self.simulation_runner_generator = simulation_runner_generator\n        self.output_dir = Path(output_dir)\n        self.load_path = load_path\n        self.episode_length = episode_length\n        self.n_episodes = n_episodes\n\n        # Update the default parameters.\n        if n_parallel_jobs is None:\n            n_parallel_jobs = number_of_ensembles\n\n        self.trainer = trainer\n        self.number_of_ensembles = number_of_ensembles\n        self.n_parallel_jobs = n_parallel_jobs\n\n        # Use default local cluster if None is given.\n        if cluster is None:\n            cluster = LocalCluster(\n                processes=True,\n                threads_per_worker=2,\n                silence_logs=logging.ERROR,\n                resources={\"espresso\": 1},\n            )\n        self.cluster = cluster\n        self.client = Client(cluster)\n\n        self.cluster.scale(n=self.n_parallel_jobs)\n        webbrowser.open(self.client.dashboard_link)\n\n        # Create the output directory if needed.\n        if not self.output_dir.exists():\n            os.makedirs(self.output_dir)\n\n    @staticmethod\n    def _train_model(\n        save_path: str,\n        trainer: ContinuousTrainer,\n        system_runner: callable,\n        load_directory: str = None,\n        episode_length: int = 100,\n        n_episodes: int = 100,\n    ) -&gt; List:\n        \"\"\"\n        Job to submit to dask.\n\n        Parameters\n        ----------\n        ensemble_id : int\n            The ensemble id.\n        trainer : Trainer\n            The trainer to use in training.\n        load_directory : str\n            The directory to load the models from.\n        episode_length : int\n            The length of each episode.\n        n_episodes : int\n            The number of episodes to train for.\n        \"\"\"\n        model_id = save_path.split(\"_\")[-1]\n        # Create the new paths.\n        os.makedirs(save_path)\n        os.chdir(save_path)\n\n        # Get the system runner.\n        system_runner = system_runner()\n        if load_directory is not None:\n            trainer.restore_models(directory=load_directory)\n        else:\n            trainer.initialize_models()\n\n        # Train the gym.\n        rewards = trainer.perform_rl_training(\n            system_runner,\n            n_episodes=n_episodes,\n            episode_length=episode_length,\n            load_bar=False,\n        )\n        trainer.export_models()\n\n        return rewards, model_id\n\n    def train_ensemble(self) -&gt; None:\n        \"\"\"\n        Train the ensemble.\n\n        Returns\n        -------\n        model_performance : dict\n            A dictionary of the model performance.\n            structure of the dictionary is: {model_id: rewards}.\n        \"\"\"\n        futures = []\n        names = [\n            (self.output_dir / f\"ensemble_{i}\").resolve().as_posix()\n            for i in range(self.number_of_ensembles)\n        ]\n\n        for i in range(self.number_of_ensembles // self.n_parallel_jobs):\n            block = self.client.map(\n                self._train_model,\n                names[i * self.n_parallel_jobs : (i + 1) * self.n_parallel_jobs],\n                [self.trainer] * self.n_parallel_jobs,\n                [self.simulation_runner_generator] * self.n_parallel_jobs,\n                [self.load_path] * self.n_parallel_jobs,\n                [self.episode_length] * self.n_parallel_jobs,\n                [self.n_episodes] * self.n_parallel_jobs,\n                resources={\"espresso\": 1},\n            )\n            _ = wait(block)\n            futures += self.client.gather(block)\n            _ = self.client.restart(wait_for_workers=False)\n            _ = self.client.wait_for_workers(self.n_parallel_jobs)\n\n        # shut down the cluster\n        self.cluster.close()\n        self.client.close()\n\n        return {model_id: rewards for rewards, model_id in futures}\n</code></pre>"},{"location":"pages/api/swarmrl.training_routines.ensemble_submit/#swarmrl.training_routines.ensemble_submit.EnsembleTraining.__init__","title":"<code>__init__(trainer, simulation_runner_generator, number_of_ensembles, episode_length, n_episodes, n_parallel_jobs=None, load_path=None, cluster=None, output_dir=Path('./ensembled-training'))</code>","text":"<p>Constructor for the ensemble training routine.</p>"},{"location":"pages/api/swarmrl.training_routines.ensemble_submit/#swarmrl.training_routines.ensemble_submit.EnsembleTraining.__init__--parameters","title":"Parameters","text":"<p>trainer : Trainer     The trainer used to train. number_of_ensmbles : int     The number of ensembles to train. episode_length : int     The length of each episode. n_episodes : int     The number of episodes to train for. simulation_runner_generator : callable     A callable function that returns a simulation runner. n_parallel_jobs : int     The number of parallel jobs to run. cluster : JobQueueCluster     The cluster to run the jobs on.     If None, the jobs will be run locally. load_path : Path or str or None (default)     The path to load the models from. output_dir : Path or str or None (default)     The directory to save the models to.</p> Source code in <code>swarmrl/training_routines/ensemble_submit.py</code> <pre><code>def __init__(\n    self,\n    trainer: ContinuousTrainer,\n    simulation_runner_generator: callable,\n    number_of_ensembles: int,\n    episode_length: int,\n    n_episodes: int,\n    n_parallel_jobs: int = None,\n    load_path: Path = None,\n    cluster: JobQueueCluster = None,\n    output_dir: Path = Path(\"./ensembled-training\"),\n) -&gt; None:\n    \"\"\"\n    Constructor for the ensemble training routine.\n\n    Parameters\n    ----------\n    trainer : Trainer\n        The trainer used to train.\n    number_of_ensmbles : int\n        The number of ensembles to train.\n    episode_length : int\n        The length of each episode.\n    n_episodes : int\n        The number of episodes to train for.\n    simulation_runner_generator : callable\n        A callable function that returns a simulation runner.\n    n_parallel_jobs : int\n        The number of parallel jobs to run.\n    cluster : JobQueueCluster\n        The cluster to run the jobs on.\n        If None, the jobs will be run locally.\n    load_path : Path or str or None (default)\n        The path to load the models from.\n    output_dir : Path or str or None (default)\n        The directory to save the models to.\n\n    \"\"\"\n    self.simulation_runner_generator = simulation_runner_generator\n    self.output_dir = Path(output_dir)\n    self.load_path = load_path\n    self.episode_length = episode_length\n    self.n_episodes = n_episodes\n\n    # Update the default parameters.\n    if n_parallel_jobs is None:\n        n_parallel_jobs = number_of_ensembles\n\n    self.trainer = trainer\n    self.number_of_ensembles = number_of_ensembles\n    self.n_parallel_jobs = n_parallel_jobs\n\n    # Use default local cluster if None is given.\n    if cluster is None:\n        cluster = LocalCluster(\n            processes=True,\n            threads_per_worker=2,\n            silence_logs=logging.ERROR,\n            resources={\"espresso\": 1},\n        )\n    self.cluster = cluster\n    self.client = Client(cluster)\n\n    self.cluster.scale(n=self.n_parallel_jobs)\n    webbrowser.open(self.client.dashboard_link)\n\n    # Create the output directory if needed.\n    if not self.output_dir.exists():\n        os.makedirs(self.output_dir)\n</code></pre>"},{"location":"pages/api/swarmrl.training_routines.ensemble_submit/#swarmrl.training_routines.ensemble_submit.EnsembleTraining.train_ensemble","title":"<code>train_ensemble()</code>","text":"<p>Train the ensemble.</p>"},{"location":"pages/api/swarmrl.training_routines.ensemble_submit/#swarmrl.training_routines.ensemble_submit.EnsembleTraining.train_ensemble--returns","title":"Returns","text":"<p>model_performance : dict     A dictionary of the model performance.     structure of the dictionary is: {model_id: rewards}.</p> Source code in <code>swarmrl/training_routines/ensemble_submit.py</code> <pre><code>def train_ensemble(self) -&gt; None:\n    \"\"\"\n    Train the ensemble.\n\n    Returns\n    -------\n    model_performance : dict\n        A dictionary of the model performance.\n        structure of the dictionary is: {model_id: rewards}.\n    \"\"\"\n    futures = []\n    names = [\n        (self.output_dir / f\"ensemble_{i}\").resolve().as_posix()\n        for i in range(self.number_of_ensembles)\n    ]\n\n    for i in range(self.number_of_ensembles // self.n_parallel_jobs):\n        block = self.client.map(\n            self._train_model,\n            names[i * self.n_parallel_jobs : (i + 1) * self.n_parallel_jobs],\n            [self.trainer] * self.n_parallel_jobs,\n            [self.simulation_runner_generator] * self.n_parallel_jobs,\n            [self.load_path] * self.n_parallel_jobs,\n            [self.episode_length] * self.n_parallel_jobs,\n            [self.n_episodes] * self.n_parallel_jobs,\n            resources={\"espresso\": 1},\n        )\n        _ = wait(block)\n        futures += self.client.gather(block)\n        _ = self.client.restart(wait_for_workers=False)\n        _ = self.client.wait_for_workers(self.n_parallel_jobs)\n\n    # shut down the cluster\n    self.cluster.close()\n    self.client.close()\n\n    return {model_id: rewards for rewards, model_id in futures}\n</code></pre>"},{"location":"pages/api/swarmrl.training_routines.genetic_algorithm/","title":"swarmrl.training_routines.genetic_algorithm Module API Reference","text":"<p>Class for the genertic algorithm training routine.</p>"},{"location":"pages/api/swarmrl.training_routines.genetic_algorithm/#swarmrl.training_routines.genetic_algorithm.GeneticTraining","title":"<code>GeneticTraining</code>","text":"<p>Class for the genetic training routine.</p> Source code in <code>swarmrl/training_routines/genetic_algorithm.py</code> <pre><code>class GeneticTraining:\n    \"\"\"\n    Class for the genetic training routine.\n    \"\"\"\n\n    def __init__(\n        self,\n        trainer: ContinuousTrainer,\n        simulation_runner_generator: callable,\n        n_episodes: int = 100,\n        episode_length: int = 20,\n        number_of_generations: int = 10,\n        population_size: int = 10,\n        number_of_parents: int = 2,\n        parent_selection_method: str = \"sum\",\n        output_directory: str = \".\",\n        routine_name: str = \"genetic_algorithm\",\n        parallel_jobs: int = None,\n        cluster: JobQueueCluster = None,\n    ):\n        \"\"\"\n        Constructor for the genetic training routine.\n\n        Parameters\n        ----------\n        n_episodes : int\n            Number of episodes in each lifespan\n        number_of_generations : int (default: 10)\n            Number of generations to run\n        population_size : int (default: 10)\n            Number of individuals in the population\n        number_of_parents : int (default: 2)\n            Number of parents to select for each generation\n        parent_selection_method : str\n            How to reduce the life reward. Either sum or mean.\n        output_directory : str (default: \".\")\n            Output directory of the run.\n        routine_name : str (default: \"genetic_algorithm\")\n            Name of the training routine.\n        cluster : JobQueueCluster\n            The cluster to run the jobs on.\n            If None, the jobs will be run locally.\n        parallel_jobs : int\n            The number of parallel jobs to run.\n            If None, the population size is used.\n\n        Notes\n        -----\n        Currently the client is fixed to run on the local machine. This will be\n        changed to a parameter in the future. The problem lies in espresso not being\n        able to handle multiple threads and us not being able to force Dask to refresh\n        a worker after each training is finished.\n        \"\"\"\n        self.trainer = trainer\n        self.simulation_runner_generator = simulation_runner_generator\n        self.n_episodes = n_episodes\n        self.episode_length = episode_length\n        self.number_of_generations = number_of_generations\n        self.population_size = population_size\n        self.number_of_parents = number_of_parents\n        self.output_directory = Path(f\"{output_directory}/{routine_name}\")\n\n        if parallel_jobs is None:\n            parallel_jobs = population_size\n        self.parallel_jobs = parallel_jobs\n\n        # Use default local cluster if None is given.\n        if cluster is None:\n            cluster = LocalCluster(\n                processes=True,\n                threads_per_worker=2,\n                silence_logs=logging.ERROR,\n                resources={\"espresso\": 1},\n            )\n\n        self.cluster = cluster\n\n        self.client = Client(cluster)\n\n        self.cluster.scale(n=self.parallel_jobs)\n        webbrowser.open(self.client.dashboard_link)\n\n        # Decide on parent splits\n        self.identifiers = range(population_size)\n\n        lazy_splits = np.array_split(np.ones(population_size), number_of_parents)\n        self.split_lengths = [len(split) for split in lazy_splits]\n\n        # set the select function\n        if parent_selection_method == \"sum\":\n            self._select_fn = onp.sum\n        elif parent_selection_method == \"mean\":\n            self._select_fn = onp.mean\n        elif parent_selection_method == \"max\":\n            self._select_fn = onp.max\n\n        # Create the output directory\n        os.mkdir(Path(self.output_directory))\n\n    @staticmethod\n    def _train_network(\n        name: Path,\n        load_directory: str = None,\n        trainer: ContinuousTrainer = None,\n        runner_generator: callable = None,\n        select_fn: callable = None,\n        episode_length: int = None,\n        n_episodes: int = None,\n    ) -&gt; tuple:\n        \"\"\"\n        Train the network.\n\n        Parameters\n        ----------\n        name : Path\n            Name of the network and where to save the data.\n        load_directory : str (default: None)\n            Directory to load the model from. If None, a new model will be created.\n        trainer : ContinuousTrainer\n                Trainer to use for training.\n        runner_generator : callable\n                Function that returns a system_runner.\n        select_fn : callable\n                Function for reducing training rewards to a single\n                number.\n        episode_length : int\n                Length of one episode.\n        n_episodes : int\n                Number of episodes in the lifespan of the child.\n\n        Returns\n        -------\n        reduced_rewards : float\n            The reduced rewards of the agent.\n        model_id : str\n            The id of the model.\n        \"\"\"\n        model_id = name.as_posix().split(\"_\")[-1]\n        os.makedirs(name)\n        os.chdir(name)\n\n        system_runner = runner_generator()  # get the runner\n\n        if load_directory is None:\n            trainer.initialize_models()\n        else:\n            trainer.restore_models(load_directory)\n\n        rewards = trainer.perform_rl_training(\n            system_runner,\n            episode_length=episode_length,\n            n_episodes=n_episodes,\n            load_bar=False,\n        )\n        trainer.export_models()\n\n        return (select_fn(rewards), model_id)\n\n    def _deploy_jobs(\n        self,\n        child_names: List[Path],\n        load_paths: List[Path],\n    ) -&gt; List[float]:\n        \"\"\"\n        Function to send jobs to the cluster.\n\n        Parameters\n        ----------\n        child_names : List[Path]\n            List of paths to save the models to.\n        load_paths : List[Path, None]\n            List of paths to load the models from.\n\n        Returns\n        -------\n        Returns the outcome of the job deployment.\n        \"\"\"\n        futures = []\n\n        for i in range(self.population_size // self.parallel_jobs):\n            block = self.client.map(\n                self._train_network,\n                child_names[i * self.parallel_jobs : (i + 1) * self.parallel_jobs],\n                load_paths[i * self.parallel_jobs : (i + 1) * self.parallel_jobs],\n                [deepcopy(self.trainer)] * self.parallel_jobs,\n                [self.simulation_runner_generator] * self.parallel_jobs,\n                [self._select_fn] * self.parallel_jobs,\n                [self.episode_length] * self.parallel_jobs,\n                [self.n_episodes] * self.parallel_jobs,\n                resources={\"espresso\": 1},\n            )\n            _ = wait(block)\n            futures += self.client.gather(block)\n            # Restart and wait for workers\n            _ = self.client.restart(wait_for_workers=False)\n            _ = self.client.wait_for_workers(self.parallel_jobs)\n\n        return futures\n\n    def _run_generation(\n        self, generation: int, seed: bool = False, parent_ids: list = None\n    ) -&gt; List:\n        \"\"\"\n        Run a generation of the training.\n\n        Parameters\n        ----------\n        generation : int\n            The number of the generation to run.\n        seed : bool (default: False)\n            Whether to seed the generation or not.\n        parent_ids : list (default: None)\n            The ids of the parents to use for the generation. If None, it should\n            be seeded.\n\n        Returns\n        -------\n        generation_outputs : list\n                A list of rewards values form which parents will be chosen.\n        \"\"\"\n        # Create the children directories\n        children_names = [\n            (\n                self.output_directory / f\"_generation_{generation}\" / f\"_child_{i}\"\n            ).resolve()\n            for i in self.identifiers\n        ]\n        # deploy the jobs\n        if seed:\n            generation_outputs = self._deploy_jobs(\n                children_names, [None] * self.population_size\n            )\n\n        else:\n            # get load paths for each parent\n            load_paths = []\n            for i, index in enumerate(parent_ids):\n                load_paths += [\n                    self.output_directory\n                    / f\"_generation_{generation - 1}\"\n                    / f\"_child_{index}\"\n                    / \"Models\"\n                ] * self.split_lengths[i]\n\n            load_paths = [item.resolve().as_posix() for item in load_paths]\n\n            generation_outputs = self._deploy_jobs(children_names, load_paths)\n\n        return generation_outputs\n\n    def _select_parents(self, generation_outputs: np.ndarray) -&gt; list:\n        \"\"\"\n        Select the parents for the next generation.\n\n        Parameters\n        ----------\n        generation_outputs : np.ndarray (n_individuals, )\n            The outputs of the generation.\n\n        Returns\n        -------\n        ids : list\n            The ids of the parents.\n        chosen_reward: float\n            Reward of the chosen child.\n        \"\"\"\n        rewards = [item[0] for item in generation_outputs]\n        ids = [item[1] for item in generation_outputs]\n\n        # First get best parent\n        max_reward_index = np.argmax(np.array(rewards))\n        chosen_id = ids[max_reward_index]\n\n        # Pick mutations\n        if self.number_of_parents == 1:\n            return [chosen_id], rewards[max_reward_index]\n        else:\n            random_ids = onp.random.choice(\n                ids, size=self.number_of_parents - 1, replace=False\n            )\n            return [chosen_id] + list(random_ids), rewards[max_reward_index]\n\n    def train_model(self):\n        \"\"\"\n        Train the model.\n        \"\"\"\n        generation = 0\n        # Seed genetic process\n        seed_outputs = self._run_generation(generation=generation, seed=True)\n        parents, reward = self._select_parents(seed_outputs)\n\n        # Loop over generations\n\n        progress = Progress(\n            \"Generation: {task.fields[generation]}\",\n            BarColumn(),\n            \"Best generation reward: {task.fields[best_reward]:.2f} \",\n            TimeRemainingColumn(),\n        )\n        with progress:\n            task = progress.add_task(\n                \"Genetic training\",\n                total=self.number_of_generations - 1,\n                generation=generation,\n                best_reward=reward,\n            )\n            for _ in range(self.number_of_generations - 1):\n                generation += 1  # Update the generation\n                generation_outputs = self._run_generation(\n                    generation=generation, parent_ids=parents\n                )\n                parents, reward = self._select_parents(generation_outputs)\n                progress.update(\n                    task,\n                    advance=1,\n                    generation=generation,\n                    best_reward=reward,\n                )\n\n        best_model_path = (\n            self.output_directory / f\"_generation_{generation}\" / f\"_child_{parents[0]}\"\n        )\n        print(f\"Best Model: {best_model_path.as_posix()}\")\n        print(f\"Best Reward: {reward:.2f}\")\n\n        # Shutdown the cluster\n        self.cluster.close()\n        self.client.close()\n\n        return best_model_path\n</code></pre>"},{"location":"pages/api/swarmrl.training_routines.genetic_algorithm/#swarmrl.training_routines.genetic_algorithm.GeneticTraining.__init__","title":"<code>__init__(trainer, simulation_runner_generator, n_episodes=100, episode_length=20, number_of_generations=10, population_size=10, number_of_parents=2, parent_selection_method='sum', output_directory='.', routine_name='genetic_algorithm', parallel_jobs=None, cluster=None)</code>","text":"<p>Constructor for the genetic training routine.</p>"},{"location":"pages/api/swarmrl.training_routines.genetic_algorithm/#swarmrl.training_routines.genetic_algorithm.GeneticTraining.__init__--parameters","title":"Parameters","text":"<p>n_episodes : int     Number of episodes in each lifespan number_of_generations : int (default: 10)     Number of generations to run population_size : int (default: 10)     Number of individuals in the population number_of_parents : int (default: 2)     Number of parents to select for each generation parent_selection_method : str     How to reduce the life reward. Either sum or mean. output_directory : str (default: \".\")     Output directory of the run. routine_name : str (default: \"genetic_algorithm\")     Name of the training routine. cluster : JobQueueCluster     The cluster to run the jobs on.     If None, the jobs will be run locally. parallel_jobs : int     The number of parallel jobs to run.     If None, the population size is used.</p>"},{"location":"pages/api/swarmrl.training_routines.genetic_algorithm/#swarmrl.training_routines.genetic_algorithm.GeneticTraining.__init__--notes","title":"Notes","text":"<p>Currently the client is fixed to run on the local machine. This will be changed to a parameter in the future. The problem lies in espresso not being able to handle multiple threads and us not being able to force Dask to refresh a worker after each training is finished.</p> Source code in <code>swarmrl/training_routines/genetic_algorithm.py</code> <pre><code>def __init__(\n    self,\n    trainer: ContinuousTrainer,\n    simulation_runner_generator: callable,\n    n_episodes: int = 100,\n    episode_length: int = 20,\n    number_of_generations: int = 10,\n    population_size: int = 10,\n    number_of_parents: int = 2,\n    parent_selection_method: str = \"sum\",\n    output_directory: str = \".\",\n    routine_name: str = \"genetic_algorithm\",\n    parallel_jobs: int = None,\n    cluster: JobQueueCluster = None,\n):\n    \"\"\"\n    Constructor for the genetic training routine.\n\n    Parameters\n    ----------\n    n_episodes : int\n        Number of episodes in each lifespan\n    number_of_generations : int (default: 10)\n        Number of generations to run\n    population_size : int (default: 10)\n        Number of individuals in the population\n    number_of_parents : int (default: 2)\n        Number of parents to select for each generation\n    parent_selection_method : str\n        How to reduce the life reward. Either sum or mean.\n    output_directory : str (default: \".\")\n        Output directory of the run.\n    routine_name : str (default: \"genetic_algorithm\")\n        Name of the training routine.\n    cluster : JobQueueCluster\n        The cluster to run the jobs on.\n        If None, the jobs will be run locally.\n    parallel_jobs : int\n        The number of parallel jobs to run.\n        If None, the population size is used.\n\n    Notes\n    -----\n    Currently the client is fixed to run on the local machine. This will be\n    changed to a parameter in the future. The problem lies in espresso not being\n    able to handle multiple threads and us not being able to force Dask to refresh\n    a worker after each training is finished.\n    \"\"\"\n    self.trainer = trainer\n    self.simulation_runner_generator = simulation_runner_generator\n    self.n_episodes = n_episodes\n    self.episode_length = episode_length\n    self.number_of_generations = number_of_generations\n    self.population_size = population_size\n    self.number_of_parents = number_of_parents\n    self.output_directory = Path(f\"{output_directory}/{routine_name}\")\n\n    if parallel_jobs is None:\n        parallel_jobs = population_size\n    self.parallel_jobs = parallel_jobs\n\n    # Use default local cluster if None is given.\n    if cluster is None:\n        cluster = LocalCluster(\n            processes=True,\n            threads_per_worker=2,\n            silence_logs=logging.ERROR,\n            resources={\"espresso\": 1},\n        )\n\n    self.cluster = cluster\n\n    self.client = Client(cluster)\n\n    self.cluster.scale(n=self.parallel_jobs)\n    webbrowser.open(self.client.dashboard_link)\n\n    # Decide on parent splits\n    self.identifiers = range(population_size)\n\n    lazy_splits = np.array_split(np.ones(population_size), number_of_parents)\n    self.split_lengths = [len(split) for split in lazy_splits]\n\n    # set the select function\n    if parent_selection_method == \"sum\":\n        self._select_fn = onp.sum\n    elif parent_selection_method == \"mean\":\n        self._select_fn = onp.mean\n    elif parent_selection_method == \"max\":\n        self._select_fn = onp.max\n\n    # Create the output directory\n    os.mkdir(Path(self.output_directory))\n</code></pre>"},{"location":"pages/api/swarmrl.training_routines.genetic_algorithm/#swarmrl.training_routines.genetic_algorithm.GeneticTraining.train_model","title":"<code>train_model()</code>","text":"<p>Train the model.</p> Source code in <code>swarmrl/training_routines/genetic_algorithm.py</code> <pre><code>def train_model(self):\n    \"\"\"\n    Train the model.\n    \"\"\"\n    generation = 0\n    # Seed genetic process\n    seed_outputs = self._run_generation(generation=generation, seed=True)\n    parents, reward = self._select_parents(seed_outputs)\n\n    # Loop over generations\n\n    progress = Progress(\n        \"Generation: {task.fields[generation]}\",\n        BarColumn(),\n        \"Best generation reward: {task.fields[best_reward]:.2f} \",\n        TimeRemainingColumn(),\n    )\n    with progress:\n        task = progress.add_task(\n            \"Genetic training\",\n            total=self.number_of_generations - 1,\n            generation=generation,\n            best_reward=reward,\n        )\n        for _ in range(self.number_of_generations - 1):\n            generation += 1  # Update the generation\n            generation_outputs = self._run_generation(\n                generation=generation, parent_ids=parents\n            )\n            parents, reward = self._select_parents(generation_outputs)\n            progress.update(\n                task,\n                advance=1,\n                generation=generation,\n                best_reward=reward,\n            )\n\n    best_model_path = (\n        self.output_directory / f\"_generation_{generation}\" / f\"_child_{parents[0]}\"\n    )\n    print(f\"Best Model: {best_model_path.as_posix()}\")\n    print(f\"Best Reward: {reward:.2f}\")\n\n    # Shutdown the cluster\n    self.cluster.close()\n    self.client.close()\n\n    return best_model_path\n</code></pre>"},{"location":"pages/api/swarmrl.utils.colloid_utils/","title":"swarmrl.utils.colloid_utils Module API Reference","text":"<p>Various functions for operating on colloids.</p>"},{"location":"pages/api/swarmrl.utils.colloid_utils/#swarmrl.utils.colloid_utils.compute_distance_matrix","title":"<code>compute_distance_matrix(set_a, set_b)</code>","text":"<p>Compute a distance matrix between two sets.</p> <p>Helper function for computing the distance sets of colloids. This is not a commutative operation, if you swap a for b you will recieve a different matrix shape.</p>"},{"location":"pages/api/swarmrl.utils.colloid_utils/#swarmrl.utils.colloid_utils.compute_distance_matrix--parameters","title":"Parameters","text":"<p>set_a : jnp.ndarray     First set of points. set_b : jnp.ndarray     Second set of points.</p> Source code in <code>swarmrl/utils/colloid_utils.py</code> <pre><code>@jax.jit\ndef compute_distance_matrix(set_a, set_b):\n    \"\"\"\n    Compute a distance matrix between two sets.\n\n    Helper function for computing the distance sets of\n    colloids. This is not a commutative operation, if you\n    swap a for b you will recieve a different matrix shape.\n\n    Parameters\n    ----------\n    set_a : jnp.ndarray\n        First set of points.\n    set_b : jnp.ndarray\n        Second set of points.\n    \"\"\"\n\n    def _sub_compute(a, b):\n        return b - a\n\n    distance_fn = jax.vmap(_sub_compute, in_axes=(0, None))\n\n    return distance_fn(set_a, set_b)\n</code></pre>"},{"location":"pages/api/swarmrl.utils.colloid_utils/#swarmrl.utils.colloid_utils.compute_forces","title":"<code>compute_forces(r)</code>","text":"<p>Compute the energy between two colloids.</p> <p>This uses a WCA potential to compute a relative force between two colloids. It is not physical. The method itself implements an energy computation which then uses Jax to compute the gradient of the energy with respect to the distance between the colloids.</p>"},{"location":"pages/api/swarmrl.utils.colloid_utils/#swarmrl.utils.colloid_utils.compute_forces--parameters","title":"Parameters","text":"<p>r : jnp.ndarray (dimension, )     Distance between the two colloids.</p> Source code in <code>swarmrl/utils/colloid_utils.py</code> <pre><code>@jax.jit\ndef compute_forces(r):\n    \"\"\"\n    Compute the energy between two colloids.\n\n    This uses a WCA potential to compute a relative force between\n    two colloids. It is not physical.\n    The method itself implements an energy computation which then uses\n    Jax to compute the gradient of the energy with respect to the\n    distance between the colloids.\n\n    Parameters\n    ----------\n    r : jnp.ndarray (dimension, )\n        Distance between the two colloids.\n    \"\"\"\n\n    def _sub_compute(r):\n        return 1 / jnp.linalg.norm(r) ** 12\n\n    force_fn = jax.grad(_sub_compute)\n\n    return force_fn(r)\n</code></pre>"},{"location":"pages/api/swarmrl.utils.colloid_utils/#swarmrl.utils.colloid_utils.compute_torque","title":"<code>compute_torque(force, direction)</code>","text":"<p>Compute the torque on a rod.</p>"},{"location":"pages/api/swarmrl.utils.colloid_utils/#swarmrl.utils.colloid_utils.compute_torque--parameters","title":"Parameters","text":"Source code in <code>swarmrl/utils/colloid_utils.py</code> <pre><code>@jax.jit\ndef compute_torque(force, direction):\n    \"\"\"\n    Compute the torque on a rod.\n\n    Parameters\n    ----------\n\n    \"\"\"\n    return jnp.cross(direction, force)\n</code></pre>"},{"location":"pages/api/swarmrl.utils.colloid_utils/#swarmrl.utils.colloid_utils.compute_torque_partition_on_rod","title":"<code>compute_torque_partition_on_rod(colloid_positions, rod_positions, rod_directions)</code>","text":"<p>Compute the torque on a rod using a WCA potential.</p> Source code in <code>swarmrl/utils/colloid_utils.py</code> <pre><code>@jax.jit\ndef compute_torque_partition_on_rod(colloid_positions, rod_positions, rod_directions):\n    \"\"\"\n    Compute the torque on a rod using a WCA potential.\n    \"\"\"\n    # (n_colloids, rod_particles, 3)\n    distance_matrix = compute_distance_matrix(colloid_positions, rod_positions)\n    distance_matrix = distance_matrix[:, :, :2]\n\n    # Force on the rod\n    rod_map_fn = jax.vmap(compute_forces, in_axes=(0,))  # map over rod particles\n    colloid_map_fn = jax.vmap(rod_map_fn, in_axes=(0,))  # map over colloids\n\n    # (n_colloids, rod_particles, 3)\n    forces = colloid_map_fn(distance_matrix)\n\n    # Compute torques\n    colloid_rod_map = jax.vmap(compute_torque, in_axes=(0, 0))\n    colloid_only_map = jax.vmap(colloid_rod_map, in_axes=(0, None))\n\n    torques = colloid_only_map(forces, rod_directions)\n    net_rod_torque = torques.sum(axis=1)\n    torque_magnitude = jnp.linalg.norm(net_rod_torque, axis=-1) + 1e-8\n    normalization_factors = torque_magnitude.sum()\n    torque_partition = torque_magnitude / normalization_factors\n\n    return torque_partition\n</code></pre>"},{"location":"pages/api/swarmrl.utils.colloid_utils/#swarmrl.utils.colloid_utils.get_colloid_indices","title":"<code>get_colloid_indices(colloids, p_type)</code>","text":"<p>Get the indices of the colloids in the observable of a specific type.</p>"},{"location":"pages/api/swarmrl.utils.colloid_utils/#swarmrl.utils.colloid_utils.get_colloid_indices--parameters","title":"Parameters","text":"<p>colloids : List[Colloid]         List of colloids from which to get the indices. p_type : int (default=None)         Type of the colloids to get the indices for. If None, the         particle_type attribute of the class is used.</p>"},{"location":"pages/api/swarmrl.utils.colloid_utils/#swarmrl.utils.colloid_utils.get_colloid_indices--returns","title":"Returns","text":"<p>indices : List[int]         List of indices for the colloids of a particular type.</p> Source code in <code>swarmrl/utils/colloid_utils.py</code> <pre><code>def get_colloid_indices(colloids: List[\"Colloid\"], p_type: int) -&gt; List[int]:\n    \"\"\"\n    Get the indices of the colloids in the observable of a specific type.\n\n    Parameters\n    ----------\n    colloids : List[Colloid]\n            List of colloids from which to get the indices.\n    p_type : int (default=None)\n            Type of the colloids to get the indices for. If None, the\n            particle_type attribute of the class is used.\n\n\n    Returns\n    -------\n    indices : List[int]\n            List of indices for the colloids of a particular type.\n    \"\"\"\n    indices = []\n    for i, colloid in enumerate(colloids):\n        if colloid.type == p_type:\n            indices.append(i)\n\n    return indices\n</code></pre>"},{"location":"pages/api/swarmrl.utils.utils/","title":"swarmrl.utils.utils Module API Reference","text":"<p>Utils for the SwarmRL package.</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.calc_ellipsoid_friction_factors_rotation","title":"<code>calc_ellipsoid_friction_factors_rotation(axial_semiaxis, equatorial_semiaxis, dynamic_viscosity)</code>","text":"<p>https://en.wikipedia.org/wiki/Perrin_friction_factors</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.calc_ellipsoid_friction_factors_rotation--returns","title":"Returns","text":"<p>gamma_ax, gamma_eq:     The friction factors for rotation around the axial (symmetry) axis     and for rotation around one of the equatorial axes</p> Source code in <code>swarmrl/utils/utils.py</code> <pre><code>def calc_ellipsoid_friction_factors_rotation(\n    axial_semiaxis, equatorial_semiaxis, dynamic_viscosity\n):\n    \"\"\"\n    https://en.wikipedia.org/wiki/Perrin_friction_factors\n\n    Returns\n    -------\n\n    gamma_ax, gamma_eq:\n        The friction factors for rotation around the axial (symmetry) axis\n        and for rotation around one of the equatorial axes\n    \"\"\"\n    p = axial_semiaxis / equatorial_semiaxis\n    xi = np.sqrt(np.abs(p**2 - 1)) / p\n\n    if p &gt; 1:\n        S = 2 * np.arctanh(xi) / xi\n    else:\n        S = 2 * np.arctan(xi) / xi\n\n    f_ax = 4.0 / 3.0 * (p**2 - 1) / (2 * p**2 - S)\n    f_eq = 4.0 / 3.0 * (p**-2 - p**2) / (2 - S * (2 - p**-2))\n\n    gamma_sphere = (\n        8 * np.pi * dynamic_viscosity * axial_semiaxis * equatorial_semiaxis**2\n    )\n\n    return gamma_sphere * f_ax, gamma_sphere * f_eq\n</code></pre>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.calc_ellipsoid_friction_factors_translation","title":"<code>calc_ellipsoid_friction_factors_translation(axial_semiaxis, equatorial_semiaxis, dynamic_viscosity)</code>","text":"<p>https://link.springer.com/article/10.1007/BF02838005</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.calc_ellipsoid_friction_factors_translation--returns","title":"Returns","text":"<p>gamma_ax, gamma_eq     The friction coefficient for dragging the ellipsoid along its symmetry axis     and along one of the equatorial axes</p> Source code in <code>swarmrl/utils/utils.py</code> <pre><code>def calc_ellipsoid_friction_factors_translation(\n    axial_semiaxis, equatorial_semiaxis, dynamic_viscosity\n):\n    \"\"\"\n    https://link.springer.com/article/10.1007/BF02838005\n\n    Returns\n    -------\n\n    gamma_ax, gamma_eq\n        The friction coefficient for dragging the ellipsoid along its symmetry axis\n        and along one of the equatorial axes\n\n    \"\"\"\n    if axial_semiaxis &gt; equatorial_semiaxis:\n        # prolate spheroid\n        a = axial_semiaxis\n        b = equatorial_semiaxis\n        e = np.sqrt(1 - b**2 / a**2)\n        ll = np.log((1 + e) / (1 - e))\n        gamma_ax = 16 * np.pi * dynamic_viscosity * a * e**3 / ((1 + e**2) * ll - 2 * e)\n        gamma_eq = (\n            32 * np.pi * dynamic_viscosity * a * e**3 / (2 * e + (3 * e**2 - 1) * ll)\n        )\n    else:\n        # oblate spheroid\n        b = axial_semiaxis\n        a = equatorial_semiaxis\n        e = np.sqrt(1 - b**2 / a**2)\n        gamma_ax = (\n            8\n            * np.pi\n            * dynamic_viscosity\n            * a\n            * e**3\n            / (e * np.sqrt(1 - e**2) - (1 - 2 * e**2) * np.arcsin(e))\n        )\n        gamma_eq = (\n            16\n            * np.pi\n            * dynamic_viscosity\n            * a\n            * e**3\n            / (-e * np.sqrt(1 - e**2) + (1 + 2 * e**2) * np.arcsin(e))\n        )\n\n    return gamma_ax, gamma_eq\n</code></pre>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.calc_signed_angle_between_directors","title":"<code>calc_signed_angle_between_directors(my_director, other_director)</code>","text":"<p>In 2D compare two different normalized directors to determine the angle between them</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.calc_signed_angle_between_directors--parameters","title":"Parameters","text":"<p>my_director : np.ndarray         Normalized director in 3D. other_director : np.ndarray         Normalized director in 3D. Returns</p> <p>signed_angle : float     signed float which represents the signed angle of my_director to other_director     with the mathematical sign convention.</p> Source code in <code>swarmrl/utils/utils.py</code> <pre><code>def calc_signed_angle_between_directors(\n    my_director: np.ndarray, other_director: np.ndarray\n) -&gt; float:\n    \"\"\"\n    In 2D compare two different normalized\n    directors to determine the angle between them\n\n    Parameters\n    ----------\n    my_director : np.ndarray\n            Normalized director in 3D.\n    other_director : np.ndarray\n            Normalized director in 3D.\n    Returns\n    ----------\n    signed_angle : float\n        signed float which represents the signed angle of my_director to other_director\n        with the mathematical sign convention.\n    \"\"\"\n\n    # Assert if the directors were really normalized\n    my_director /= jnp.linalg.norm(my_director)\n    other_director /= jnp.linalg.norm(other_director)\n\n    # calculate the angle in which the my_colloid is looking\n    angle = jnp.arccos(jnp.clip(jnp.dot(other_director, my_director), -1.0, 1.0))\n    # use the director in orthogonal direction to determine sign\n    orthogonal_dot = jnp.dot(\n        other_director,\n        jnp.array([-my_director[1], my_director[0], my_director[2]]),\n    )\n    # don't use np.sign instead use np.where because\n    # np.sign(0) =&gt; 0 is not what we want\n    angle *= jnp.where(orthogonal_dot &gt;= 0, 1, -1)\n\n    return angle\n</code></pre>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.create_colloids","title":"<code>create_colloids(n_cols, type_=0, center=np.array([500, 500, 0]), dist=200.0, face_middle=False)</code>","text":"<p>Create a number of colloids in a circle around the center of the box. This method is primarily used for writing tests. It is not used in the actual simulation. The colloids are created in a circle around the center of the box.</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.create_colloids--parameters","title":"Parameters","text":"<p>n_cols : int         Number of colloids to create. type_ : int, optional         Type of the colloids to create. center : np.ndarray, optional         Center of the circle in which the colloids are created. dist : float, optional         Distance of the colloids to the center. face_middle : bool, optional         If True, the colloids face the center of the circle.</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.create_colloids--returns","title":"Returns","text":"<p>colloids : list(Colloid)         List of colloid.</p> Source code in <code>swarmrl/utils/utils.py</code> <pre><code>def create_colloids(\n    n_cols: int,\n    type_: int = 0,\n    center: np.array = np.array([500, 500, 0]),\n    dist: float = 200.0,\n    face_middle: bool = False,\n):\n    \"\"\"\n    Create a number of colloids in a circle around the center of the box.\n    This method is primarily used for writing tests. It is not used in the\n    actual simulation. The colloids are created in a circle around the center\n    of the box.\n\n    Parameters\n    ----------\n    n_cols : int\n            Number of colloids to create.\n    type_ : int, optional\n            Type of the colloids to create.\n    center : np.ndarray, optional\n            Center of the circle in which the colloids are created.\n    dist : float, optional\n            Distance of the colloids to the center.\n    face_middle : bool, optional\n            If True, the colloids face the center of the circle.\n\n    Returns\n    -------\n    colloids : list(Colloid)\n            List of colloid.\n    \"\"\"\n    cols = []\n    for i in range(n_cols):\n        theta = np.random.random(1)[0] * 2 * np.pi\n        position = center + dist * np.array([np.cos(theta), np.sin(theta), 0])\n        if face_middle:\n            direction = np.array(center - position)\n        else:\n            direction = np.random.random(3)\n        direction[-1] = 0\n        direction = direction / np.linalg.norm(direction)\n        cols.append(Colloid(pos=position, director=direction, type=type_, id=i))\n    return cols\n</code></pre>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.gather_n_dim_indices","title":"<code>gather_n_dim_indices(reference_array, indices)</code>","text":"<p>Gather entries from an n_dim array using an n_dim index array</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.gather_n_dim_indices--parameters","title":"Parameters","text":"<p>reference_array : np.ndarray         Array that you want to gather the indices of. indices : np.ndarray         Indices in the same shape as the array without the last dimension.</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.gather_n_dim_indices--returns","title":"Returns","text":"<p>reduced_array : np.ndarray         Shape is the reference array with the last dimension reduced to 1.         This array is the initial reference array with the desired indices chosen         out.</p> Source code in <code>swarmrl/utils/utils.py</code> <pre><code>def gather_n_dim_indices(reference_array: np.ndarray, indices: np.ndarray):\n    \"\"\"\n    Gather entries from an n_dim array using an n_dim index array\n\n    Parameters\n    ----------\n    reference_array : np.ndarray\n            Array that you want to gather the indices of.\n    indices : np.ndarray\n            Indices in the same shape as the array without the last dimension.\n\n    Returns\n    -------\n    reduced_array : np.ndarray\n            Shape is the reference array with the last dimension reduced to 1.\n            This array is the initial reference array with the desired indices chosen\n            out.\n    \"\"\"\n    indices = indices.astype(int)\n    reference_shape = reference_array.shape\n\n    multiplier = (\n        np.linspace(0, len(indices.flatten()) - 1, len(indices.flatten()), dtype=int)\n        * reference_shape[-1]\n    )\n\n    indices = indices.flatten() + multiplier\n\n    gathered_array = reference_array.flatten()[indices]\n\n    return gathered_array.reshape(reference_shape[0], reference_shape[1])\n</code></pre>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.record_trajectory","title":"<code>record_trajectory(particle_type, features, actions, log_probs, rewards)</code>","text":"<p>Record trajectory if required.</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.record_trajectory--parameters","title":"Parameters","text":"<p>particle_type : str         Type of the particle saved. Important for the multi-species training. rewards : np.ndarray (n_timesteps, n_particles, 1)         Rewards collected during the simulation to be used in training. log_probs : np.ndarray (n_timesteps, n_particles, 1)         log_probs used for debugging. features : np.ndarray (n_timesteps, n_particles, n_dimensions)         Features to store in the array. actions : np.ndarray (n_timesteps, n_particles, 1)         A numpy array of actions</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.record_trajectory--returns","title":"Returns","text":"<p>Dumps a hidden file to disc which is often removed after reading.</p> Source code in <code>swarmrl/utils/utils.py</code> <pre><code>def record_trajectory(\n    particle_type: str,\n    features: np.ndarray,\n    actions: np.ndarray,\n    log_probs: np.ndarray,\n    rewards: np.ndarray,\n):\n    \"\"\"\n    Record trajectory if required.\n\n    Parameters\n    ----------\n    particle_type : str\n            Type of the particle saved. Important for the multi-species training.\n    rewards : np.ndarray (n_timesteps, n_particles, 1)\n            Rewards collected during the simulation to be used in training.\n    log_probs : np.ndarray (n_timesteps, n_particles, 1)\n            log_probs used for debugging.\n    features : np.ndarray (n_timesteps, n_particles, n_dimensions)\n            Features to store in the array.\n    actions : np.ndarray (n_timesteps, n_particles, 1)\n            A numpy array of actions\n\n    Returns\n    -------\n    Dumps a hidden file to disc which is often removed after reading.\n    \"\"\"\n    try:\n        data = np.load(f\".traj_data_{particle_type}.npy\", allow_pickle=True)\n        feature_data = data.item().get(\"features\")\n        action_data = data.item().get(\"actions\")\n        log_probs_data = data.item().get(\"log_probs\")\n        reward_data = data.item().get(\"rewards\")\n\n        feature_data = np.append(feature_data, np.array([features]), axis=0)\n        action_data = np.append(action_data, np.array([actions]), axis=0)\n        log_probs_data = np.append(log_probs_data, np.array([log_probs]), axis=0)\n        reward_data = np.append(reward_data, np.array([rewards]), axis=0)\n\n        os.remove(f\".traj_data_{particle_type}.npy\")\n\n    except FileNotFoundError:\n        feature_data = np.array([features])\n        action_data = np.array([actions])\n        log_probs_data = np.array([log_probs])\n        reward_data = np.array([rewards])\n\n    np.save(\n        f\".traj_data_{particle_type}.npy\",\n        {\n            \"features\": feature_data,\n            \"actions\": action_data,\n            \"log_probs\": log_probs_data,\n            \"rewards\": reward_data,\n        },\n        allow_pickle=True,\n    )\n</code></pre>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.save_memory","title":"<code>save_memory(memory)</code>","text":"<p>Records the training data if required.</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.save_memory--parameters","title":"Parameters:","text":"<p>memory : a dictionary containing the data from the method where it is called from.     The data is specified in the method.     It has to contain a key \"file_name\" which is the name of the file to be saved.     To handle multiple particle types: one can specify the file name in the     initialisation of the method.</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.save_memory--returns","title":"Returns","text":"<p>Dumps a  file to disc to evaluate training.</p> Source code in <code>swarmrl/utils/utils.py</code> <pre><code>def save_memory(memory: dict):\n    \"\"\"\n    Records the training data if required.\n\n    Parameters:\n    ----------\n    memory : a dictionary containing the data from the method where it is called from.\n        The data is specified in the method.\n        It has to contain a key \"file_name\" which is the name of the file to be saved.\n        To handle multiple particle types: one can specify the file name in the\n        initialisation of the method.\n\n    Returns\n    -------\n    Dumps a  file to disc to evaluate training.\n    \"\"\"\n    empty_memory = {key: [] for key in memory.keys()}\n    empty_memory[\"file_name\"] = memory[\"file_name\"]\n    try:\n        reloaded_dict = np.load(memory[\"file_name\"], allow_pickle=True).item()\n        for key, _ in reloaded_dict.items():\n            reloaded_dict[key].append(memory[key])\n        np.save(memory[\"file_name\"], reloaded_dict, allow_pickle=True)\n    except FileNotFoundError:\n        for key, _ in empty_memory.items():\n            empty_memory[key].append(memory[key])\n        np.save(memory[\"file_name\"], empty_memory, allow_pickle=True)\n    return empty_memory\n</code></pre>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.setup_sim_folder","title":"<code>setup_sim_folder(outfolder_base, name, ask_if_exists=True, delete_existing=True)</code>","text":"<p>Create a simulation folder. Depending on flags, delete previous folders of the same name Parameters</p> <p>outfolder_base     Folder in which to create the new simulation folder name     Name of the new folder ask_if_exists     Flag to determine if the program stops to await user input on     how to handle if the folder already exists (true, default)     or to just delete it (false) delete_existing     Whether to delete the existing folder</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.setup_sim_folder--returns","title":"Returns","text":"Source code in <code>swarmrl/utils/utils.py</code> <pre><code>def setup_sim_folder(\n    outfolder_base: str,\n    name: str,\n    ask_if_exists: bool = True,\n    delete_existing: bool = True,\n):\n    \"\"\"\n    Create a simulation folder.\n    Depending on flags, delete previous folders of the same name\n    Parameters\n    ----------\n    outfolder_base\n        Folder in which to create the new simulation folder\n    name\n        Name of the new folder\n    ask_if_exists\n        Flag to determine if the program stops to await user input on\n        how to handle if the folder already exists (true, default)\n        or to just delete it (false)\n    delete_existing\n        Whether to delete the existing folder\n\n    Returns\n    -------\n\n    \"\"\"\n    folder_name = f\"{outfolder_base}/{name}\"\n    if os.path.isdir(folder_name):\n        if (\n            ask_if_exists\n            and input(\n                f\"Directory for sim '{name}' already exists in '{outfolder_base}'. \"\n                \"Delete previous and create new? (yes/N) \"\n            )\n            != \"yes\"\n        ):\n            print(\"aborting\")\n            exit()\n        elif delete_existing:\n            shutil.rmtree(folder_name)\n            print(f\"removed {folder_name} and all its contents\")\n\n    os.makedirs(folder_name, exist_ok=True)\n    print(f\"outdir {folder_name} created\")\n\n    return folder_name\n</code></pre>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.setup_swarmrl_logger","title":"<code>setup_swarmrl_logger(filename, loglevel_terminal=logging.INFO, loglevel_file=logging.DEBUG)</code>","text":"<p>Configure the swarmrl logger. This logger is used internally for logging, but you can also use it for your own log messages. Parameters</p> <p>filename     Name of the file where logs get written to loglevel_terminal     Loglevel of the terminal output. The values correspond to     https://docs.python.org/3/library/logging.html#logging-levels.     You can pass an integer (or logging predefined values such as logging.INFO)     or a string that corresponds to the loglevels of the link above. loglevel_file     Loglevel of the file output. Returns</p> <pre><code>The logger\n</code></pre> Source code in <code>swarmrl/utils/utils.py</code> <pre><code>def setup_swarmrl_logger(\n    filename: str,\n    loglevel_terminal: typing.Union[int, str] = logging.INFO,\n    loglevel_file: typing.Union[int, str] = logging.DEBUG,\n) -&gt; logging.Logger:\n    \"\"\"\n    Configure the swarmrl logger. This logger is used internally for logging,\n    but you can also use it for your own log messages.\n    Parameters\n    ----------\n    filename\n        Name of the file where logs get written to\n    loglevel_terminal\n        Loglevel of the terminal output. The values correspond to\n        https://docs.python.org/3/library/logging.html#logging-levels.\n        You can pass an integer (or logging predefined values such as logging.INFO)\n        or a string that corresponds to the loglevels of the link above.\n    loglevel_file\n        Loglevel of the file output.\n    Returns\n    -------\n        The logger\n    \"\"\"\n\n    def get_numeric_level(loglevel: typing.Union[int, str]):\n        if isinstance(loglevel, str):\n            numeric_level = getattr(logging, loglevel.upper(), None)\n        elif isinstance(loglevel, int):\n            numeric_level = loglevel\n        else:\n            raise ValueError(\n                f\"Invalid log level: {loglevel}. Must be either str or int\"\n            )\n        return numeric_level\n\n    logger = logging.getLogger(swarmrl._ROOT_NAME)\n    logger.setLevel(logging.INFO)\n    formatter = logging.Formatter(\n        fmt=\"[%(levelname)-10s] %(asctime)s %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n    )\n    file_handler = logging.FileHandler(filename)\n    file_handler.setFormatter(formatter)\n    file_handler.setLevel(get_numeric_level(loglevel_file))\n    stream_handler = logging.StreamHandler()\n    stream_handler.setFormatter(formatter)\n    stream_handler.setLevel(get_numeric_level(loglevel_terminal))\n    logger.addHandler(file_handler)\n    logger.addHandler(stream_handler)\n\n    return logger\n</code></pre>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.write_params","title":"<code>write_params(folder_name, sim_name, params, write_espresso_version=False)</code>","text":"<p>Writes parameters human-readable and to pickle</p>"},{"location":"pages/api/swarmrl.utils.utils/#swarmrl.utils.utils.write_params--parameters","title":"Parameters","text":"<p>folder_name     Folder to save to sim_name     Name of the simulation, used to create the two file names params : dict     The parameters to be saved. Should have a string representation for txt output      and be serializable by pickle write_espresso_version : bool     If True, the espresso version will be printed to the txt file</p> Source code in <code>swarmrl/utils/utils.py</code> <pre><code>def write_params(\n    folder_name: str,\n    sim_name: str,\n    params: typing.Any,\n    write_espresso_version: bool = False,\n):\n    \"\"\"\n    Writes parameters human-readable and to pickle\n\n    Parameters\n    ----------\n    folder_name\n        Folder to save to\n    sim_name\n        Name of the simulation, used to create the two file names\n    params : dict\n        The parameters to be saved. Should have a string representation for txt output\n         and be serializable by pickle\n    write_espresso_version : bool\n        If True, the espresso version will be printed to the txt file\n\n    \"\"\"\n\n    fname_base = f\"{folder_name}/params_{sim_name}\"\n    with open(fname_base + \".txt\", \"w\") as txt_file:\n        if write_espresso_version:\n            from espressomd import version\n\n            txt_file.write(\n                f\"Espresso version {version.friendly()} branch {version.git_branch()} \"\n                f\"at commit {version.git_commit()}\\n\"\n            )\n        txt_file.write(str(params))\n\n    with open(fname_base + \".pick\", \"wb\") as pick_file:\n        pickle.dump(params, pick_file)\n</code></pre>"},{"location":"pages/api/swarmrl.value_functions.expected_returns/","title":"swarmrl.value_functions.expected_returns Module API Reference","text":"<p>Module for the expected returns value function.</p>"},{"location":"pages/api/swarmrl.value_functions.expected_returns/#swarmrl.value_functions.expected_returns.ExpectedReturns","title":"<code>ExpectedReturns</code>","text":"<p>Class for the expected returns.</p> Source code in <code>swarmrl/value_functions/expected_returns.py</code> <pre><code>class ExpectedReturns:\n    \"\"\"\n    Class for the expected returns.\n    \"\"\"\n\n    def __init__(self, gamma: float = 0.99, standardize: bool = True):\n        \"\"\"\n        Constructor for the Expected returns class\n\n        Parameters\n        ----------\n        gamma : float\n                A decay factor for the values of the task each time step.\n        standardize : bool\n                If True, standardize the results of the calculation.\n\n        Notes\n        -----\n        See https://www.tensorflow.org/tutorials/reinforcement_learning/actor_critic\n        for more information.\n        \"\"\"\n        self.gamma = gamma\n        self.standardize = standardize\n\n        # Set by us to stabilize division operations.\n        self.eps = np.finfo(np.float32).eps.item()\n\n    @partial(jax.jit, static_argnums=(0,))\n    def __call__(self, rewards: np.ndarray):\n        \"\"\"\n        Call function for the expected returns.\n        Parameters\n        ----------\n        rewards : np.ndarray (n_time_steps, n_particles, dimension)\n                A numpy array of rewards to use in the calculation.\n\n        Returns\n        -------\n        expected_returns : np.ndarray (n_time_steps, n_particles)\n                Expected returns for the rewards.\n        \"\"\"\n        logger.debug(f\"{self.gamma=}\")\n        expected_returns = np.zeros_like(rewards)\n        n_particles = rewards.shape[1]\n\n        final_time = len(rewards) + 1\n        logger.debug(rewards)\n\n        for t, reward in enumerate(rewards):\n            gamma_array = self.gamma ** np.linspace(\n                t + 1, final_time, int(final_time - (t + 1)), dtype=int\n            )\n            gamma_array = np.transpose(\n                np.repeat(gamma_array[None, :], n_particles, axis=0)\n            )\n\n            proceeding_rewards = rewards[t:, :]\n\n            returns = proceeding_rewards * gamma_array\n            expected_returns = expected_returns.at[t, :].set(returns.sum(axis=0))\n\n        logger.debug(f\"{expected_returns=}\")\n\n        if self.standardize:\n            mean_vector = np.mean(expected_returns, axis=0)\n            std_vector = np.std(expected_returns, axis=0) + self.eps\n\n            expected_returns = (expected_returns - mean_vector) / std_vector\n\n        return expected_returns\n</code></pre>"},{"location":"pages/api/swarmrl.value_functions.expected_returns/#swarmrl.value_functions.expected_returns.ExpectedReturns.__call__","title":"<code>__call__(rewards)</code>","text":"<p>Call function for the expected returns. Parameters</p> <p>rewards : np.ndarray (n_time_steps, n_particles, dimension)         A numpy array of rewards to use in the calculation.</p>"},{"location":"pages/api/swarmrl.value_functions.expected_returns/#swarmrl.value_functions.expected_returns.ExpectedReturns.__call__--returns","title":"Returns","text":"<p>expected_returns : np.ndarray (n_time_steps, n_particles)         Expected returns for the rewards.</p> Source code in <code>swarmrl/value_functions/expected_returns.py</code> <pre><code>@partial(jax.jit, static_argnums=(0,))\ndef __call__(self, rewards: np.ndarray):\n    \"\"\"\n    Call function for the expected returns.\n    Parameters\n    ----------\n    rewards : np.ndarray (n_time_steps, n_particles, dimension)\n            A numpy array of rewards to use in the calculation.\n\n    Returns\n    -------\n    expected_returns : np.ndarray (n_time_steps, n_particles)\n            Expected returns for the rewards.\n    \"\"\"\n    logger.debug(f\"{self.gamma=}\")\n    expected_returns = np.zeros_like(rewards)\n    n_particles = rewards.shape[1]\n\n    final_time = len(rewards) + 1\n    logger.debug(rewards)\n\n    for t, reward in enumerate(rewards):\n        gamma_array = self.gamma ** np.linspace(\n            t + 1, final_time, int(final_time - (t + 1)), dtype=int\n        )\n        gamma_array = np.transpose(\n            np.repeat(gamma_array[None, :], n_particles, axis=0)\n        )\n\n        proceeding_rewards = rewards[t:, :]\n\n        returns = proceeding_rewards * gamma_array\n        expected_returns = expected_returns.at[t, :].set(returns.sum(axis=0))\n\n    logger.debug(f\"{expected_returns=}\")\n\n    if self.standardize:\n        mean_vector = np.mean(expected_returns, axis=0)\n        std_vector = np.std(expected_returns, axis=0) + self.eps\n\n        expected_returns = (expected_returns - mean_vector) / std_vector\n\n    return expected_returns\n</code></pre>"},{"location":"pages/api/swarmrl.value_functions.expected_returns/#swarmrl.value_functions.expected_returns.ExpectedReturns.__init__","title":"<code>__init__(gamma=0.99, standardize=True)</code>","text":"<p>Constructor for the Expected returns class</p>"},{"location":"pages/api/swarmrl.value_functions.expected_returns/#swarmrl.value_functions.expected_returns.ExpectedReturns.__init__--parameters","title":"Parameters","text":"<p>gamma : float         A decay factor for the values of the task each time step. standardize : bool         If True, standardize the results of the calculation.</p>"},{"location":"pages/api/swarmrl.value_functions.expected_returns/#swarmrl.value_functions.expected_returns.ExpectedReturns.__init__--notes","title":"Notes","text":"<p>See https://www.tensorflow.org/tutorials/reinforcement_learning/actor_critic for more information.</p> Source code in <code>swarmrl/value_functions/expected_returns.py</code> <pre><code>def __init__(self, gamma: float = 0.99, standardize: bool = True):\n    \"\"\"\n    Constructor for the Expected returns class\n\n    Parameters\n    ----------\n    gamma : float\n            A decay factor for the values of the task each time step.\n    standardize : bool\n            If True, standardize the results of the calculation.\n\n    Notes\n    -----\n    See https://www.tensorflow.org/tutorials/reinforcement_learning/actor_critic\n    for more information.\n    \"\"\"\n    self.gamma = gamma\n    self.standardize = standardize\n\n    # Set by us to stabilize division operations.\n    self.eps = np.finfo(np.float32).eps.item()\n</code></pre>"},{"location":"pages/api/swarmrl.value_functions.generalized_advantage_estimate/","title":"swarmrl.value_functions.generalized_advantage_estimate Module API Reference","text":"<p>Module for the expected returns value function.</p>"},{"location":"pages/api/swarmrl.value_functions.generalized_advantage_estimate/#swarmrl.value_functions.generalized_advantage_estimate.GAE","title":"<code>GAE</code>","text":"<p>Class for the expected returns.</p> Source code in <code>swarmrl/value_functions/generalized_advantage_estimate.py</code> <pre><code>class GAE:\n    \"\"\"\n    Class for the expected returns.\n    \"\"\"\n\n    def __init__(self, gamma: float = 0.99, lambda_: float = 0.95):\n        \"\"\"\n        Constructor for the generalized advantage estimate  class\n\n        Parameters\n        ----------\n        gamma : float\n                A decay factor for the values of the task each time step.\n        lambda_ : float\n                A decay factor that describes the amount of bias included in the\n                advantage calculation.\n\n        Notes\n        -----\n        See https://arxiv.org/pdf/1506.02438.pdf for more information.\n        \"\"\"\n        self.gamma = gamma\n        self.lambda_ = lambda_\n\n        # Set by us to stabilize division operations.\n        self.eps = np.finfo(np.float32).eps.item()\n\n    @partial(jit, static_argnums=(0,))\n    def __call__(self, rewards: np.ndarray, values: np.ndarray):\n        \"\"\"\n        Call function for the advantage.\n        Parameters\n        ----------\n        rewards : np.ndarray (n_time_steps, n_particles)\n                A numpy array of rewards to use in the calculation.\n        values : np.ndarray (n_time_steps, n_particles)\n                The prediction of the critic for the episode.\n        Returns\n        -------\n        advantages : np.ndarray (n_time_steps, n_particles)\n                Expected returns for the rewards.\n        \"\"\"\n        gae = 0\n        advantages = np.zeros_like(rewards)\n        for t in reversed(range(len(rewards))):\n            if t != len(rewards) - 1:\n                delta = rewards[t] + self.gamma * values[t + 1] - values[t]\n            else:\n                delta = rewards[t] - values[t]\n\n            gae = delta + self.gamma * self.lambda_ * gae\n            advantages = advantages.at[t].set(gae)\n\n        returns = advantages + values\n\n        advantages = (advantages - np.mean(advantages)) / (\n            np.std(advantages) + self.eps\n        )\n        return advantages, returns\n</code></pre>"},{"location":"pages/api/swarmrl.value_functions.generalized_advantage_estimate/#swarmrl.value_functions.generalized_advantage_estimate.GAE.__call__","title":"<code>__call__(rewards, values)</code>","text":"<p>Call function for the advantage. Parameters</p> <p>rewards : np.ndarray (n_time_steps, n_particles)         A numpy array of rewards to use in the calculation. values : np.ndarray (n_time_steps, n_particles)         The prediction of the critic for the episode. Returns</p> <p>advantages : np.ndarray (n_time_steps, n_particles)         Expected returns for the rewards.</p> Source code in <code>swarmrl/value_functions/generalized_advantage_estimate.py</code> <pre><code>@partial(jit, static_argnums=(0,))\ndef __call__(self, rewards: np.ndarray, values: np.ndarray):\n    \"\"\"\n    Call function for the advantage.\n    Parameters\n    ----------\n    rewards : np.ndarray (n_time_steps, n_particles)\n            A numpy array of rewards to use in the calculation.\n    values : np.ndarray (n_time_steps, n_particles)\n            The prediction of the critic for the episode.\n    Returns\n    -------\n    advantages : np.ndarray (n_time_steps, n_particles)\n            Expected returns for the rewards.\n    \"\"\"\n    gae = 0\n    advantages = np.zeros_like(rewards)\n    for t in reversed(range(len(rewards))):\n        if t != len(rewards) - 1:\n            delta = rewards[t] + self.gamma * values[t + 1] - values[t]\n        else:\n            delta = rewards[t] - values[t]\n\n        gae = delta + self.gamma * self.lambda_ * gae\n        advantages = advantages.at[t].set(gae)\n\n    returns = advantages + values\n\n    advantages = (advantages - np.mean(advantages)) / (\n        np.std(advantages) + self.eps\n    )\n    return advantages, returns\n</code></pre>"},{"location":"pages/api/swarmrl.value_functions.generalized_advantage_estimate/#swarmrl.value_functions.generalized_advantage_estimate.GAE.__init__","title":"<code>__init__(gamma=0.99, lambda_=0.95)</code>","text":"<p>Constructor for the generalized advantage estimate  class</p>"},{"location":"pages/api/swarmrl.value_functions.generalized_advantage_estimate/#swarmrl.value_functions.generalized_advantage_estimate.GAE.__init__--parameters","title":"Parameters","text":"<p>gamma : float         A decay factor for the values of the task each time step. lambda_ : float         A decay factor that describes the amount of bias included in the         advantage calculation.</p>"},{"location":"pages/api/swarmrl.value_functions.generalized_advantage_estimate/#swarmrl.value_functions.generalized_advantage_estimate.GAE.__init__--notes","title":"Notes","text":"<p>See https://arxiv.org/pdf/1506.02438.pdf for more information.</p> Source code in <code>swarmrl/value_functions/generalized_advantage_estimate.py</code> <pre><code>def __init__(self, gamma: float = 0.99, lambda_: float = 0.95):\n    \"\"\"\n    Constructor for the generalized advantage estimate  class\n\n    Parameters\n    ----------\n    gamma : float\n            A decay factor for the values of the task each time step.\n    lambda_ : float\n            A decay factor that describes the amount of bias included in the\n            advantage calculation.\n\n    Notes\n    -----\n    See https://arxiv.org/pdf/1506.02438.pdf for more information.\n    \"\"\"\n    self.gamma = gamma\n    self.lambda_ = lambda_\n\n    # Set by us to stabilize division operations.\n    self.eps = np.finfo(np.float32).eps.item()\n</code></pre>"}]}